{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LM_SpeechBrain",
      "provenance": [],
      "collapsed_sections": [
        "IMorxeqKBtKZ",
        "XtIB4vdfcje_",
        "ydbRPEAkqMFa",
        "FrmKmiHPq6Qb",
        "_n83Q3J-tN-t"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "872fb3ed20674a3a9c409d077542cab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e09fbc16dae4d18a84d50317d8799ca",
              "IPY_MODEL_170bb14e5be14b1a8e4e46d89485f5d4",
              "IPY_MODEL_54731b5252ef4af4aed3edde975df8a9"
            ],
            "layout": "IPY_MODEL_5a7624be2c5148028a688a6795074116"
          }
        },
        "5e09fbc16dae4d18a84d50317d8799ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5060962daabc40e09fa3176b608d15d3",
            "placeholder": "​",
            "style": "IPY_MODEL_ad809b8f352d4e26a9d7a2ec7ec04006",
            "value": "100%"
          }
        },
        "170bb14e5be14b1a8e4e46d89485f5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56e5326fbbbc416cb77af46e53d8bad7",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9960aeca74c846b7a80aa7d0aafaa3d9",
            "value": 3
          }
        },
        "54731b5252ef4af4aed3edde975df8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_180ea5cbae1d4509b3b282155173df8f",
            "placeholder": "​",
            "style": "IPY_MODEL_7043c6acf064449ab5ef5b70357804da",
            "value": " 3/3 [00:00&lt;00:00, 57.48it/s]"
          }
        },
        "5a7624be2c5148028a688a6795074116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5060962daabc40e09fa3176b608d15d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad809b8f352d4e26a9d7a2ec7ec04006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56e5326fbbbc416cb77af46e53d8bad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9960aeca74c846b7a80aa7d0aafaa3d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "180ea5cbae1d4509b3b282155173df8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7043c6acf064449ab5ef5b70357804da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMzC_sb0FhlB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 1 - BaseLine TrnsformerLM + medium data"
      ],
      "metadata": {
        "id": "j7rRARMEAodZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1: Setup & Import**"
      ],
      "metadata": {
        "id": "ffrXtx-dYlAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SpeechBrain"
      ],
      "metadata": {
        "id": "rVS8tKKyhJiY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3769a4d9-9424-481c-b33a-d2a24f6b33e9",
        "id": "J0zFiMx2ygjP"
      },
      "source": [
        "%%time\n",
        "#%%capture\n",
        "# Local installation\n",
        "import os\n",
        "%cd /content/\n",
        "if not os.path.exists('/content/speechbrain/'):\n",
        "    !git clone https://github.com/speechbrain/speechbrain/\n",
        "%cd /content/speechbrain/\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'speechbrain'...\n",
            "remote: Enumerating objects: 55503, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 55503 (delta 18), reused 44 (delta 12), pack-reused 55437\u001b[K\n",
            "Receiving objects: 100% (55503/55503), 61.60 MiB | 15.47 MiB/s, done.\n",
            "Resolving deltas: 100% (32144/32144), done.\n",
            "/content/speechbrain\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Ignoring SoundFile: markers 'sys_platform == \"win32\"' don't match your environment\n",
            "Collecting black==19.10b0\n",
            "  Downloading black-19.10b0-py36-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting click==8.0.4\n",
            "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting flake8==3.7.9\n",
            "  Downloading flake8-3.7.9-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting pycodestyle==2.5.0\n",
            "  Downloading pycodestyle-2.5.0-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting pytest==5.4.1\n",
            "  Downloading pytest-5.4.1-py3-none-any.whl (246 kB)\n",
            "\u001b[K     |████████████████████████████████| 246 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting yamllint==1.23.0\n",
            "  Downloading yamllint-1.23.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting huggingface_hub>=0.0.6\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting hyperpyyaml>=0.0.1\n",
            "  Downloading HyperPyYAML-1.0.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (21.3)\n",
            "Collecting pre-commit>=2.3.0\n",
            "  Downloading pre_commit-2.19.0-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 48.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.4.1)\n",
            "Collecting sentencepiece>=0.1.91\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 40.3 MB/s \n",
            "\u001b[?25hCollecting torch<=1.10.1,>=1.8.0\n",
            "  Downloading torch-1.10.1-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.3 MB/s eta 0:00:38tcmalloc: large alloc 1147494400 bytes == 0x3a258000 @  0x7fc370b80615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 16 kB/s \n",
            "\u001b[?25hCollecting torchaudio<=0.10.1,>=0.8.0\n",
            "  Downloading torchaudio-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 54.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.42.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.64.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->-r lint-requirements.txt (line 1)) (21.4.0)\n",
            "Collecting pathspec<1,>=0.6\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting toml>=0.9.4\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting typed-ast>=1.4.0\n",
            "  Downloading typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 56.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->-r lint-requirements.txt (line 1)) (1.4.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->-r lint-requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click==8.0.4->-r lint-requirements.txt (line 2)) (4.11.4)\n",
            "Collecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting pyflakes<2.2.0,>=2.1.0\n",
            "  Downloading pyflakes-2.1.1-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting entrypoints<0.4.0,>=0.3.0\n",
            "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.1->-r lint-requirements.txt (line 5)) (1.11.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.1->-r lint-requirements.txt (line 5)) (0.2.5)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.1->-r lint-requirements.txt (line 5)) (8.13.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from yamllint==1.23.0->-r lint-requirements.txt (line 6)) (3.13)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (3.7.0)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 57.3 MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml>=0.17.8\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->-r requirements.txt (line 6)) (3.0.9)\n",
            "Collecting virtualenv>=20.0.8\n",
            "  Downloading virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 24.9 MB/s \n",
            "\u001b[?25hCollecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting identify>=1.0.0\n",
            "  Downloading identify-2.5.1-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting cfgv>=2.0.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click==8.0.4->-r lint-requirements.txt (line 2)) (3.8.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 62.6 MB/s \n",
            "\u001b[?25hCollecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit>=2.3.0->-r requirements.txt (line 7)) (1.15.0)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 69.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (2022.5.18.1)\n",
            "Building wheels for collected packages: hyperpyyaml\n",
            "  Building wheel for hyperpyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hyperpyyaml: filename=HyperPyYAML-1.0.1-py3-none-any.whl size=15192 sha256=9f675052ed77f87593f037de1db82cf554a6d11392543483047af9e8c914213d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/87/65/266d722c3932f81f16332ce842e972be8421e3a9cd3771766b\n",
            "Successfully built hyperpyyaml\n",
            "Installing collected packages: ruamel.yaml.clib, platformdirs, distlib, virtualenv, typed-ast, torch, toml, ruamel.yaml, pyyaml, pyflakes, pycodestyle, pluggy, pathspec, nodeenv, mccabe, identify, entrypoints, click, cfgv, yamllint, torchaudio, sentencepiece, pytest, pre-commit, hyperpyyaml, huggingface-hub, flake8, black\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: entrypoints\n",
            "    Found existing installation: entrypoints 0.4\n",
            "    Uninstalling entrypoints-0.4:\n",
            "      Successfully uninstalled entrypoints-0.4\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.11.0+cu113\n",
            "    Uninstalling torchaudio-0.11.0+cu113:\n",
            "      Successfully uninstalled torchaudio-0.11.0+cu113\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.10.1 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.10.1 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed black-19.10b0 cfgv-3.3.1 click-8.0.4 distlib-0.3.4 entrypoints-0.3 flake8-3.7.9 huggingface-hub-0.7.0 hyperpyyaml-1.0.1 identify-2.5.1 mccabe-0.6.1 nodeenv-1.6.0 pathspec-0.9.0 platformdirs-2.5.2 pluggy-0.13.1 pre-commit-2.19.0 pycodestyle-2.5.0 pyflakes-2.1.1 pytest-5.4.1 pyyaml-6.0 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 sentencepiece-0.1.96 toml-0.10.2 torch-1.10.1 torchaudio-0.10.1 typed-ast-1.5.4 virtualenv-20.14.1 yamllint-1.23.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/speechbrain\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch<=1.11,>=1.7 in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (21.3)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (0.10.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.1.0)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (0.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (4.64.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (0.1.96)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.11,>=1.7->speechbrain==0.5.11) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain==0.5.11) (3.7.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain==0.5.11) (4.11.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain==0.5.11) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain==0.5.11) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->speechbrain==0.5.11) (3.0.9)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.8 in /usr/local/lib/python3.7/dist-packages (from hyperpyyaml->speechbrain==0.5.11) (0.17.21)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.17.8->hyperpyyaml->speechbrain==0.5.11) (0.2.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->speechbrain==0.5.11) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain==0.5.11) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain==0.5.11) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain==0.5.11) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain==0.5.11) (1.24.3)\n",
            "Installing collected packages: speechbrain\n",
            "  Running setup.py develop for speechbrain\n",
            "Successfully installed speechbrain\n",
            "CPU times: user 2.91 s, sys: 454 ms, total: 3.36 s\n",
            "Wall time: 2min 46s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc692e8-cc2d-44a8-9953-5bb119282029",
        "id": "IxH9gV_jygjP"
      },
      "source": [
        "%%time\n",
        "#%%capture\n",
        "# to avoid the error No  module find error\n",
        "# import speechbrain as sb\n",
        "# For pip installation\n",
        "!pip install speechbrain"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting speechbrain\n",
            "  Downloading speechbrain-0.5.11-py3-none-any.whl (408 kB)\n",
            "\u001b[K     |████████████████████████████████| 408 kB 33.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.7.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.21.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.1.96)\n",
            "Requirement already satisfied: torch<=1.11,>=1.7 in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from speechbrain) (21.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from speechbrain) (4.64.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.1.0)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.11,>=1.7->speechbrain) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (3.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (4.11.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->speechbrain) (3.0.9)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.8 in /usr/local/lib/python3.7/dist-packages (from hyperpyyaml->speechbrain) (0.17.21)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.17.8->hyperpyyaml->speechbrain) (0.2.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->speechbrain) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2022.5.18.1)\n",
            "Installing collected packages: speechbrain\n",
            "Successfully installed speechbrain-0.5.11\n",
            "CPU times: user 43.6 ms, sys: 19.6 ms, total: 63.2 ms\n",
            "Wall time: 4.65 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce1356f1-44b0-4995-e640-539d77cf5c06",
        "id": "7ToOxd0izgTA"
      },
      "source": [
        "%%time\n",
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.2.2-py3-none-any.whl (346 kB)\n",
            "\u001b[K     |████████████████████████████████| 346 kB 31.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.7.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Collecting dill<0.3.5\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 73.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 68.8 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 76.3 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 53.8 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 45.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, dill, aiohttp, xxhash, responses, multiprocess, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.13\n",
            "    Uninstalling multiprocess-0.70.13:\n",
            "      Successfully uninstalled multiprocess-0.70.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.2.2 dill-0.3.4 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 multiprocess-0.70.12.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n",
            "CPU times: user 191 ms, sys: 61.3 ms, total: 252 ms\n",
            "Wall time: 20.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "D4-KhBoICqft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from IPython.display import display, Audio\n",
        "import datetime\n",
        "import gc\n",
        "import re\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\"\"\"\n",
        "import hashlib\n",
        "from wget import download\n",
        "import torch\n",
        "import torchaudio\n",
        "from huggingface_hub import notebook_login\n",
        "\"\"\"\n",
        "0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R81GUkECtFs",
        "outputId": "31953e62-bc27-416e-dd5a-627989932e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2: Prepare Data**"
      ],
      "metadata": {
        "id": "IMorxeqKBtKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data"
      ],
      "metadata": {
        "id": "PmR2Cq5ROgX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "data_link = \"https://drive.google.com/file/d/1vQbu1XmenVtNYSvqZmiwAo2jzFWZCsI8/view?usp=sharing\"\n",
        "file_id= data_link.split('/')[-2]\n",
        "fn = 'medium_data.csv'\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=''$file_id' -O '$fn'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9fb3d5e-b6f4-4d7a-9e55-548e0f24d94d",
        "id": "ieLAx_WUOgX0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2022-06-03 08:45:08--  https://docs.google.com/uc?export=download&id=1vQbu1XmenVtNYSvqZmiwAo2jzFWZCsI8\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.10.102, 142.251.10.139, 142.251.10.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.10.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-14-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/uvtr3ctibqcjv1k6qa37l6bfn5eaavos/1654245900000/17304979608001708681/*/1vQbu1XmenVtNYSvqZmiwAo2jzFWZCsI8?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-06-03 08:45:09--  https://doc-14-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/uvtr3ctibqcjv1k6qa37l6bfn5eaavos/1654245900000/17304979608001708681/*/1vQbu1XmenVtNYSvqZmiwAo2jzFWZCsI8?e=download\n",
            "Resolving doc-14-b0-docs.googleusercontent.com (doc-14-b0-docs.googleusercontent.com)... 142.251.10.132, 2404:6800:4003:c0f::84\n",
            "Connecting to doc-14-b0-docs.googleusercontent.com (doc-14-b0-docs.googleusercontent.com)|142.251.10.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1428382 (1.4M) [text/csv]\n",
            "Saving to: ‘medium_data.csv’\n",
            "\n",
            "medium_data.csv     100%[===================>]   1.36M  --.-KB/s    in 0.008s  \n",
            "\n",
            "2022-06-03 08:45:10 (171 MB/s) - ‘medium_data.csv’ saved [1428382/1428382]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#medium_data = pd.read_csv('../input/medium-articles-dataset/medium_data.csv') # Kaggle\n",
        "medium_data = pd.read_csv('medium_data.csv') # Colab\n",
        "medium_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T14:50:49.294905Z",
          "iopub.execute_input": "2022-05-31T14:50:49.295657Z",
          "iopub.status.idle": "2022-05-31T14:50:49.349944Z",
          "shell.execute_reply.started": "2022-05-31T14:50:49.295603Z",
          "shell.execute_reply": "2022-05-31T14:50:49.348937Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "1f2b5d88-fea7-4a3a-d574-8369378a5bb5",
        "id": "ZlYbLrrTOgX0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                                url  \\\n",
              "0   1  https://towardsdatascience.com/a-beginners-gui...   \n",
              "1   2  https://towardsdatascience.com/hands-on-graph-...   \n",
              "2   3  https://towardsdatascience.com/how-to-use-ggpl...   \n",
              "3   4  https://towardsdatascience.com/databricks-how-...   \n",
              "4   5  https://towardsdatascience.com/a-step-by-step-...   \n",
              "\n",
              "                                               title  \\\n",
              "0  A Beginner’s Guide to Word Embedding with Gens...   \n",
              "1  Hands-on Graph Neural Networks with PyTorch & ...   \n",
              "2                       How to Use ggplot2 in Python   \n",
              "3  Databricks: How to Save Files in CSV on Your L...   \n",
              "4  A Step-by-Step Implementation of Gradient Desc...   \n",
              "\n",
              "                                  subtitle   image  claps responses  \\\n",
              "0                                      NaN   1.png    850         8   \n",
              "1                                      NaN   2.png   1100        11   \n",
              "2         A Grammar of Graphics for Python   3.png    767         1   \n",
              "3  When I work on Python projects dealing…  4.jpeg    354         0   \n",
              "4          One example of building neural…  5.jpeg    211         3   \n",
              "\n",
              "   reading_time           publication        date  \n",
              "0             8  Towards Data Science  2019-05-30  \n",
              "1             9  Towards Data Science  2019-05-30  \n",
              "2             5  Towards Data Science  2019-05-30  \n",
              "3             4  Towards Data Science  2019-05-30  \n",
              "4             4  Towards Data Science  2019-05-30  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9474b16-f215-48cc-bf78-9889da1743f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>subtitle</th>\n",
              "      <th>image</th>\n",
              "      <th>claps</th>\n",
              "      <th>responses</th>\n",
              "      <th>reading_time</th>\n",
              "      <th>publication</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>https://towardsdatascience.com/a-beginners-gui...</td>\n",
              "      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.png</td>\n",
              "      <td>850</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>https://towardsdatascience.com/hands-on-graph-...</td>\n",
              "      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.png</td>\n",
              "      <td>1100</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>https://towardsdatascience.com/how-to-use-ggpl...</td>\n",
              "      <td>How to Use ggplot2 in Python</td>\n",
              "      <td>A Grammar of Graphics for Python</td>\n",
              "      <td>3.png</td>\n",
              "      <td>767</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>https://towardsdatascience.com/databricks-how-...</td>\n",
              "      <td>Databricks: How to Save Files in CSV on Your L...</td>\n",
              "      <td>When I work on Python projects dealing…</td>\n",
              "      <td>4.jpeg</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>https://towardsdatascience.com/a-step-by-step-...</td>\n",
              "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
              "      <td>One example of building neural…</td>\n",
              "      <td>5.jpeg</td>\n",
              "      <td>211</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9474b16-f215-48cc-bf78-9889da1743f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9474b16-f215-48cc-bf78-9889da1743f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9474b16-f215-48cc-bf78-9889da1743f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"remv\"></a>\n",
        "#### Preprocess Data\n",
        "Removing unwanted characters and words in titles\n",
        "\n",
        "Looking at titles, we can see there are some of unwanted characters and words in it which can not be useful for us to predict infact it might decrease our model accuracy so we have to remove it."
      ],
      "metadata": {
        "id": "HKMg1EZsOgX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocess(line):\n",
        "    # line: string\n",
        "    preprocess_line = line.lower()\n",
        "    preprocess_line = preprocess_line.replace(u'\\xa0',u' ')\n",
        "    preprocess_line = preprocess_line.replace('\\u200a',' ')\n",
        "    preprocess_line = re.sub(\"[^A-Za-zА-Яа-я0-9\\'\\s]\",'',preprocess_line)\n",
        "    return preprocess_line\n",
        "text_preprocess(\"Hands-on Graph Neural 'Network's with PyTorch & .\")    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-OBH7lN2Et4c",
        "outputId": "11396a5e-8c81-4b85-9593-0c56ef09a989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"handson graph neural 'network's with pytorch  \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#medium_data['title'] = medium_data['title'].apply(lambda x: x.replace(u'\\xa0',u' '))\n",
        "#medium_data['title'] = medium_data['title'].apply(lambda x: x.replace('\\u200a',' '))\n",
        "#medium_data['title'] = medium_data['title'].apply(lambda x: x.lower())\n",
        "medium_data['title'] = medium_data['title'].apply(lambda x: text_preprocess(x))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T14:51:04.377174Z",
          "iopub.execute_input": "2022-05-31T14:51:04.377769Z",
          "iopub.status.idle": "2022-05-31T14:51:04.38892Z",
          "shell.execute_reply.started": "2022-05-31T14:51:04.377717Z",
          "shell.execute_reply": "2022-05-31T14:51:04.387839Z"
        },
        "trusted": true,
        "id": "lWmGjq3sOgX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medium_data['title'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-Q_uUetGyMv",
        "outputId": "52f98be6-9476-48b3-c766-89e51eab9da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    a beginners guide to word embedding with gensi...\n",
              "1    handson graph neural networks with pytorch  py...\n",
              "2                         how to use ggplot2 in python\n",
              "3    databricks how to save files in csv on your lo...\n",
              "4    a stepbystep implementation of gradient descen...\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medium_data['title'].to_csv('medium_data.txt', index=False, header=None )"
      ],
      "metadata": {
        "id": "hS8uenWEOgX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"token\"></a>\n",
        "#### Tokenezation\n",
        "\n",
        "Tokenzaion is the process in which we provide an unique id to all the words and make a word index or we can say vocabulary."
      ],
      "metadata": {
        "id": "jGdTmACFOgX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### --model_type=unigram"
      ],
      "metadata": {
        "id": "ZWNNSiP9JCrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# by example https://colab.research.google.com/github/google/sentencepiece/blob/master/python/sentencepiece_python_module_example.ipynb#scrollTo=ee9W6wGnVteW\n",
        "# by End-to-End ASR SpeechBrain\n",
        "#sp.load(\"/content/speechbrain/templates/speech_recognition/Tokenizer/save/1000_unigram.model\")\n",
        "\n",
        "#import torch\n",
        "import sentencepiece as spm\n",
        "sp = spm.SentencePieceProcessor()\n"
      ],
      "metadata": {
        "id": "q2NYgQD8OgX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spm.SentencePieceTrainer.train('--input=botchan.txt --vocab_size=2000 --model_prefix=m --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]')\n",
        "#spm.SentencePieceTrainer.train('--input=medium_data.txt --vocab_size=9000 --model_prefix=m --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]')\n",
        "#spm.SentencePieceTrainer.train('--input=medium_data.txt --vocab_size=7000 --model_prefix=tokenizer --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]')\n",
        "#RuntimeError: Internal: src/trainer_interface.cc(590) [(trainer_spec_.vocab_size()) == (model_proto->pieces_size())] Vocabulary size too high (7000). Please set it to a value <= 6310.\n",
        "spm.SentencePieceTrainer.train('--model_type=unigram --input=medium_data.txt --vocab_size=6310 --model_prefix=tokenizer --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]')\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('tokenizer.model')\n",
        "\n",
        "# <unk>=0, <s>=1, </s>=2, <sep>=3, <cls>=4\n",
        "print('bos=', sp.bos_id())\n",
        "print('eos=', sp.eos_id())\n",
        "print('unk=', sp.unk_id())\n",
        "print('pad=', sp.pad_id())  # disabled by default\n",
        "\n",
        "for id in range(4):\n",
        "    print(sp.id_to_piece(id), sp.is_control(id))\n",
        "vocab_size = sp.vocab_size()\n",
        "print(f\"vocab_size={vocab_size}\")\n",
        "vocab = {sp.IdToPiece(i): i for i in range(sp.GetPieceSize())}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbab1103-a8dd-46bb-e19c-dfe94812d3a5",
        "id": "A_HPxp5nOgX1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bos= 2\n",
            "eos= 3\n",
            "unk= 1\n",
            "pad= 0\n",
            "[PAD] True\n",
            "[UNK] False\n",
            "[BOS] True\n",
            "[EOS] True\n",
            "vocab_size=6310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp.id_to_piece(0), sp.id_to_piece(1), sp.id_to_piece(199), sp.id_to_piece(999), sp.decode_ids([999])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83d09d31-663b-4115-dccf-d83dd66e0aaa",
        "id": "pdw1LiwjOgX3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[PAD]', '[UNK]', '▁every', '▁source', 'source')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(vocab.items())[:20], list(vocab.items())[-20:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L2ml6LzH8hg",
        "outputId": "5e8e6ff6-39e9-4a51-ec63-2c6b6e3b21f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('[PAD]', 0),\n",
              "  ('[UNK]', 1),\n",
              "  ('[BOS]', 2),\n",
              "  ('[EOS]', 3),\n",
              "  ('▁the', 4),\n",
              "  ('▁to', 5),\n",
              "  ('▁a', 6),\n",
              "  ('s', 7),\n",
              "  ('▁', 8),\n",
              "  ('ing', 9),\n",
              "  ('▁of', 10),\n",
              "  ('strong', 11),\n",
              "  ('▁and', 12),\n",
              "  ('▁how', 13),\n",
              "  ('▁in', 14),\n",
              "  ('▁your', 15),\n",
              "  ('▁for', 16),\n",
              "  ('▁you', 17),\n",
              "  ('▁with', 18),\n",
              "  ('▁is', 19)],\n",
              " [('dm', 6290),\n",
              "  ('▁attracti', 6291),\n",
              "  ('ee', 6292),\n",
              "  ('same', 6293),\n",
              "  ('nager', 6294),\n",
              "  ('ios', 6295),\n",
              "  ('cious', 6296),\n",
              "  ('▁agen', 6297),\n",
              "  ('ishing', 6298),\n",
              "  ('strongho', 6299),\n",
              "  ('▁tu', 6300),\n",
              "  ('alg', 6301),\n",
              "  ('▁debi', 6302),\n",
              "  ('▁batt', 6303),\n",
              "  ('▁highe', 6304),\n",
              "  ('ark', 6305),\n",
              "  ('▁kn', 6306),\n",
              "  ('ru', 6307),\n",
              "  ('wo', 6308),\n",
              "  ('▁rai', 6309)])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### --model_type=word"
      ],
      "metadata": {
        "id": "4TRlQwr-I3CP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "blank_index: 0\n",
        "bos_index: 1\n",
        "eos_index: 2\n",
        "unk_index: 0\n",
        "pad_index: 3\n",
        "```\n",
        "по идее blank_id= unk_id или pad_id\n",
        "\n",
        "Connectionist Temporal Classification (CTC)\n",
        "CTC is the simplest speech recognition system available in SpeechBrain.\n",
        "\n",
        "For each time step, it outputs a prediction. CTC adds a special token called **blank**. That allows the network to output nothing when not sure about what to emit. The CTC cost function uses dynamic programming to align over all the possible alignments."
      ],
      "metadata": {
        "id": "V_3oRK88YMsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "import sentencepiece as spm\n",
        "\n",
        "spm.SentencePieceTrainer.train('--model_type=word --input=medium_data.txt --model_prefix=tokenizer_8583_word \\\n",
        "--vocab_size=8583 --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 \\\n",
        "--pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]')\n",
        "# RuntimeError: Please set it to a value <= 8583\n",
        "# #--control_symbols=<cls>\\\n",
        "# #--blank_id=4\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('tokenizer_word.model')\n",
        "print('unk=', sp.unk_id())\n",
        "print('bos=', sp.bos_id())\n",
        "print('eos=', sp.eos_id())\n",
        "print('pad=', sp.pad_id())  # disabled by default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1nYnNwXI99_",
        "outputId": "72ec42bb-13f3-408a-b4eb-90b3197b3a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "unk= 1\n",
            "bos= 2\n",
            "eos= 3\n",
            "pad= 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = sp.vocab_size()\n",
        "print(f\"vocab_size={vocab_size}\")\n",
        "vocab = {sp.IdToPiece(i): i for i in range(sp.GetPieceSize())}\n",
        "print(list(vocab.items())[:10])\n",
        "print(list(vocab.items())[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQWMGCZrJf2Y",
        "outputId": "bbe2303b-16a5-4df5-b1e5-4dc469506741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab_size=8583\n",
            "[('[PAD]', 0), ('[UNK]', 1), ('[BOS]', 2), ('[EOS]', 3), ('▁to', 4), ('▁the', 5), ('▁a', 6), ('▁of', 7), ('▁and', 8), ('▁how', 9)]\n",
            "[('▁yourselfstrong', 8573), ('▁youtuber', 8574), ('▁ytb', 8575), ('▁zalando', 8576), ('▁zealand', 8577), ('▁zillow', 8578), ('▁zip', 8579), ('▁zipline', 8580), ('▁zmodule', 8581), ('▁zone', 8582)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test Tokenizer"
      ],
      "metadata": {
        "id": "W0oUxK7YPADC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "medium_data['title'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lqpdIuztHp-l",
        "outputId": "3318530a-034c-4fe3-8bf5-04b04051d919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a beginners guide to word embedding with gensim word2vec model'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Encode as pieces\n",
        "print(sp.encode_as_pieces('THE CITY OF MONTREAL'))\n",
        "print(sp.encode_as_ids('THE CITY OF MONTREAL'))\n",
        "\n",
        "# Encode as ids\n",
        "print(sp.encode_as_pieces(medium_data['title'][0]))\n",
        "print(sp.encode_as_ids(medium_data['title'][0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7dece34-417f-485b-fa2a-3eb210a14667",
        "id": "Xdw3682_OgX4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁THE▁CITY▁OF▁MONTREAL']\n",
            "[1]\n",
            "['▁a', '▁beginners', '▁guide', '▁to', '▁word', '▁embedding', '▁with', '▁gensim', '▁word2vec', '▁model']\n",
            "[6, 271, 66, 4, 464, 1568, 14, 2866, 8515, 99]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sp.decode_ids([244, 177, 3, 1, 97]))\n",
        "print(sp.encode_as_pieces(\"beginer's guide\"))\n",
        "# Decode from pieces\n",
        "print(sp.decode_pieces(['▁THIS', '▁IS', '▁A', '▁T', 'EST']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-3noyj_cA1t",
        "outputId": "184e7003-a739-4cb3-af43-00f09900adaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "brand tensorflow ⁇  intelligence\n",
            "[\"▁beginer's\", '▁guide']\n",
            "▁THIS▁IS▁A▁TEST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data: train val, test"
      ],
      "metadata": {
        "id": "tO6uStdDQ-qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "lines = medium_data['title'].values\n",
        "#train_texts, test_texts = train_test_split(lines[:11], test_size=0.2, shuffle=True )\n",
        "train_texts, test_texts = train_test_split(lines, test_size=0.2, shuffle=True )\n",
        "valid_texts, test_texts = train_test_split(test_texts, test_size=0.5 )\n",
        "#train_texts, val_texts, test_texts"
      ],
      "metadata": {
        "id": "c5FSDGXRVZVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save train, val, test texts"
      ],
      "metadata": {
        "id": "8KV5iu4DiDXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/speechbrain/templates/speech_recognition/LM/data/\"\n",
        "def write_text_lines(lines, file_name):\n",
        "    with open(file_name,'w') as f:\n",
        "        for line in lines:\n",
        "            f.write(line + '\\n')\n",
        "write_text_lines(train_texts, data_folder + \"train_01.txt\")\n",
        "write_text_lines(valid_texts, data_folder + \"valid_01.txt\")\n",
        "write_text_lines(test_texts, data_folder + \"test_01.txt\")"
      ],
      "metadata": {
        "id": "IXQMzaZRiLoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9dd095YBrQ4"
      },
      "source": [
        "## **Step 3: Tokenizer** \n",
        "An important decision to make when designing a speech recognizer concerns the basic tokens that our system has to predict (e.g, characters, phonemes, sub-words, words).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tokenizer_ru.yaml vocab_size =1000"
      ],
      "metadata": {
        "id": "AdmKKXdFBrQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/speechbrain/templates/speech_recognition/Tokenizer/tokenizer_ru.yaml\n",
        "# ############################################################################\n",
        "# Training: Russian Dataset\n",
        "# by original:\n",
        "# Tokenizer: subword BPE tokenizer with unigram 1K\n",
        "# Training: Mini-LibriSpeech\n",
        "# Authors:  Abdel Heba 2021\n",
        "#           Mirco Ravanelli 2021\n",
        "# ############################################################################\n",
        "#vocab_size: 5000\n",
        "vocab_size: 8583\n",
        "\n",
        "\n",
        "# Set up folders for reading from and writing to\n",
        "data_folder: ../data\n",
        "data_folder_dataset: !ref <data_folder>/buriy_audiobooks_2_val\n",
        "output_folder: ./save\n",
        "\n",
        "# Path where data-specification files are stored\n",
        "train_annotation: ../train_ru.json\n",
        "valid_annotation: ../valid_ru.json\n",
        "test_annotation: ../test_ru.json\n",
        "lm_train_data: ../LM/data/train_ru.txt\n",
        "lm_valid_data: ../LM/data/valid_ru.txt\n",
        "lm_test_data: ../LM/data/test_ru.txt\n",
        "\n",
        "\n",
        "# Tokenizer parameters\n",
        "token_type: unigram  # [\"unigram\", \"bpe\", \"char\"]\n",
        "#token_type: bpe  # [\"unigram\", \"bpe\", \"char\"]\n",
        "#token_output: 1000  # index(blank/eos/bos/unk) = 0\n",
        "\n",
        "character_coverage: 1.0\n",
        "annotation_read: words # field to read\n",
        "\n",
        "blank_index: 0\n",
        "bos_index: 1\n",
        "eos_index: 2\n",
        "unk_index: 0\n",
        "pad_index: 3\n",
        "\n",
        "# --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]\n",
        "# https://colab.research.google.com/github/google/sentencepiece/blob/master/python/sentencepiece_python_module_example.ipynb#scrollTo=PKn1f3eih_We\n",
        "# Sentencepiece python module example\n",
        "\n",
        "# Tokenizer object\n",
        "tokenizer: !name:speechbrain.tokenizers.SentencePiece.SentencePiece\n",
        "   unk_id: !ref <unk_index>\n",
        "   pad_id: !ref <pad_index>\n",
        "   bos_id: !ref <bos_index>\n",
        "   eos_id: !ref <eos_index>\n",
        "   model_dir: !ref <output_folder>\n",
        "   #vocab_size: !ref <token_output>\n",
        "   vocab_size: !ref <vocab_size>\n",
        "   annotation_train: !ref <train_annotation>\n",
        "   annotation_read: !ref <annotation_read>\n",
        "   model_type: !ref <token_type> # [\"unigram\", \"bpe\", \"char\"]\n",
        "   character_coverage: !ref <character_coverage>\n",
        "   annotation_list_to_check: [!ref <train_annotation>, !ref <valid_annotation>]\n",
        "   annotation_format: json\n",
        "   \n",
        "   \n",
        "   #default bos_id=- 1, eos_id=- 1, pad_id=- 1, unk_id=0,\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78bc7ee-5bf8-4aad-edcb-7303e75af447",
        "id": "7Ph7HoxXBrQ5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/speechbrain/templates/speech_recognition/Tokenizer/tokenizer_ru.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer/train_ru.py"
      ],
      "metadata": {
        "id": "I0ZJevgxBrQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/speechbrain/templates/speech_recognition/Tokenizer/train_ru.py\n",
        "#!/usr/bin/env/python3\n",
        "\"\"\"Script for training a BPE tokenizer on the top of CSV or JSON annotation files.\n",
        "The tokenizer converts words into sub-word units that can be used to train a\n",
        "language (LM) or an acoustic model (AM).\n",
        "When doing a speech recognition experiment you have to make\n",
        "sure that the acoustic and language models are trained with\n",
        "the same tokenizer. Otherwise, a token mismatch is introduced\n",
        "and beamsearch will produce bad results when combining AM and LM.\n",
        "\n",
        "To run this recipe, do the following:\n",
        "> python train_ru.py tokenizer_ru.yaml\n",
        "\n",
        "\n",
        "Authors\n",
        " * Abdel Heba 2021\n",
        " * Mirco Ravanelli 2021\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import speechbrain as sb\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "#from mini_librispeech_prepare import prepare_mini_librispeech\n",
        "from prepare_ru_dataset import prepare_ru_dataset\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Load hyperparameters file with command-line overrides\n",
        "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
        "    with open(hparams_file) as fin:\n",
        "        hparams = load_hyperpyyaml(fin, overrides)\n",
        "\n",
        "    # Create experiment directory\n",
        "    sb.create_experiment_directory(\n",
        "        experiment_directory=hparams[\"output_folder\"],\n",
        "        hyperparams_to_save=hparams_file,\n",
        "        overrides=overrides,\n",
        "    )\n",
        "\n",
        "    # Data preparation, to be run on only one process.\n",
        "    prepare_ru_dataset(\n",
        "        data_folder=hparams[\"data_folder\"],\n",
        "        data_folder_dataset=hparams[\"data_folder_dataset\"],\n",
        "        save_json_train=hparams[\"train_annotation\"],\n",
        "        save_json_valid=hparams[\"valid_annotation\"],\n",
        "        save_json_test=hparams[\"test_annotation\"],\n",
        "        save_LM_train = hparams[\"lm_train_data\"],\n",
        "        save_LM_valid = hparams[\"lm_valid_data\"],\n",
        "        save_LM_test = hparams[\"lm_test_data\"],\n",
        "        split_ratio=[80, 10, 10],\n",
        "\n",
        "    )\n",
        "\n",
        "    # Train tokenizer\n",
        "    hparams[\"tokenizer\"]()\n",
        "    \n",
        "    #spm.SentencePieceTrainer.train('--input=botchan.txt --vocab_size=2000 --model_prefix=m --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9efe0541-ddb7-416f-a78d-60fde2509160",
        "id": "EH0nwI_pBrQ5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/speechbrain/templates/speech_recognition/Tokenizer/train_ru.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Tokenizer"
      ],
      "metadata": {
        "id": "bdCPKspdBrQ5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f45ac62-adc0-4e4f-a540-3cb45bd9e1f1",
        "id": "N0OPDYRYBrQ5"
      },
      "source": [
        "%%time\n",
        "%cd /content/speechbrain/templates/speech_recognition/Tokenizer\n",
        "#!python train.py tokenizer.yaml\n",
        "! python train_ru.py tokenizer_ru.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/speechbrain/templates/speech_recognition/Tokenizer\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: ./save\n",
            "Downloading https://azureopendatastorage.blob.core.windows.net/openstt/ru_open_stt_opus/archives/buriy_audiobooks_2_val.tar.gz to ../data/buriy_audiobooks_2_val.tar.gz\n",
            "buriy_audiobooks_2_val.tar.gz: 496MB [02:51, 2.90MB/s]               \n",
            "prepare_ru_dataset - Creating ../train_ru.json, ../valid_ru.json, and ../test_ru.json\n",
            "prepare_ru_dataset - Transcription files read!\n",
            "prepare_ru_dataset - ../train_ru.json successfully created!\n",
            "prepare_ru_dataset - ../valid_ru.json successfully created!\n",
            "prepare_ru_dataset - ../test_ru.json successfully created!\n",
            "prepare_ru_dataset - ../LM/data/train_ru.txt successfully created!\n",
            "prepare_ru_dataset - ../LM/data/valid_ru.txt successfully created!\n",
            "prepare_ru_dataset - ../LM/data/test_ru.txt successfully created!\n",
            "speechbrain.tokenizers.SentencePiece - Train tokenizer with type:unigram\n",
            "speechbrain.tokenizers.SentencePiece - Extract words sequences from:../train_ru.json\n",
            "speechbrain.tokenizers.SentencePiece - Text file created at: ../train_ru.txt\n",
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=../train_ru.txt --model_prefix=./save/1000_unigram --model_type=unigram --bos_id=1 --eos_id=2 --pad_id=3 --unk_id=0 --max_sentencepiece_length=10 --character_coverage=1.0 --add_dummy_prefix=True --vocab_size=1000\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: ../train_ru.txt\n",
            "  input_format: \n",
            "  model_prefix: ./save/1000_unigram\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 1000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 1\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 10\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: 3\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(178) LOG(INFO) Loading corpus: ../train_ru.txt\n",
            "trainer_interface.cc(385) LOG(INFO) Loaded all 6280 sentences\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
            "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(466) LOG(INFO) all chars count=203196\n",
            "trainer_interface.cc(487) LOG(INFO) Alphabet size=34\n",
            "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 6280 sentences.\n",
            "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
            "unigram_model_trainer.cc(194) LOG(INFO) Initialized 31855 seed sentencepieces\n",
            "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 6280\n",
            "trainer_interface.cc(537) LOG(INFO) Done! 12757\n",
            "unigram_model_trainer.cc(489) LOG(INFO) Using 12757 sentences for EM training\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=10503 obj=12.8049 num_tokens=25198 num_tokens/piece=2.39912\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=9268 obj=11.4016 num_tokens=25440 num_tokens/piece=2.74493\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=6948 obj=11.5124 num_tokens=27318 num_tokens/piece=3.93178\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=6929 obj=11.3865 num_tokens=27355 num_tokens/piece=3.9479\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=5195 obj=11.8458 num_tokens=30113 num_tokens/piece=5.79654\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=5193 obj=11.6986 num_tokens=30118 num_tokens/piece=5.79973\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=3894 obj=12.2656 num_tokens=33306 num_tokens/piece=8.55316\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=3893 obj=12.1207 num_tokens=33311 num_tokens/piece=8.55664\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=2919 obj=12.6819 num_tokens=36537 num_tokens/piece=12.517\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=2919 obj=12.5496 num_tokens=36540 num_tokens/piece=12.518\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=2189 obj=13.1519 num_tokens=39676 num_tokens/piece=18.1252\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=2189 obj=13.0371 num_tokens=39677 num_tokens/piece=18.1256\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1641 obj=13.6225 num_tokens=42781 num_tokens/piece=26.0701\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1641 obj=13.511 num_tokens=42785 num_tokens/piece=26.0725\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1230 obj=14.1189 num_tokens=45751 num_tokens/piece=37.1959\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1230 obj=14.0029 num_tokens=45754 num_tokens/piece=37.1984\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1100 obj=14.2139 num_tokens=46869 num_tokens/piece=42.6082\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1100 obj=14.17 num_tokens=46872 num_tokens/piece=42.6109\n",
            "trainer_interface.cc(615) LOG(INFO) Saving model: ./save/1000_unigram.model\n",
            "trainer_interface.cc(626) LOG(INFO) Saving vocabs: ./save/1000_unigram.vocab\n",
            "speechbrain.tokenizers.SentencePiece - ==== Loading Tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer path: ./save/1000_unigram.model\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer vocab_size: 1000\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer type: unigram\n",
            "speechbrain.tokenizers.SentencePiece - ==== Accuracy checking for recovering text from tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - recover words from: ../train_ru.json\n",
            "speechbrain.tokenizers.SentencePiece - Wrong recover words: 6\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer vocab size: 1000\n",
            "speechbrain.tokenizers.SentencePiece - accuracy recovering words: 0.994\n",
            "speechbrain.tokenizers.SentencePiece - ==== Accuracy checking for recovering text from tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - recover words from: ../valid_ru.json\n",
            "speechbrain.tokenizers.SentencePiece - Wrong recover words: 6\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer vocab size: 1000\n",
            "speechbrain.tokenizers.SentencePiece - accuracy recovering words: 0.994\n",
            "CPU times: user 1.93 s, sys: 258 ms, total: 2.19 s\n",
            "Wall time: 3min 11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Look json-files & LM.txt-files & Tokenize text"
      ],
      "metadata": {
        "id": "N9FRR2BPBrQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sentencepiece as spm\n",
        "tokenize = spm.SentencePieceProcessor()\n",
        "tokenize.load(\"/content/speechbrain/templates/speech_recognition/Tokenizer/save/1000_unigram.model\")\n",
        "\n",
        "import json\n",
        "with open('/content/speechbrain/templates/speech_recognition/train_ru.json') as json_file:\n",
        "#with open('/content/train.json') as json_file:\n",
        "  t = json.load(json_file)\n",
        "  len_train = len(t.keys())\n",
        "  lst = list(t.items())\n",
        "  print(lst[:3])\n",
        "  print(lst[0][1][\"words\"])\n",
        "  print(tokenize.encode_as_pieces(lst[0][1][\"words\"]))\n",
        "\n",
        "with open('/content/speechbrain/templates/speech_recognition/valid_ru.json') as json_file:\n",
        "  v = json.load(json_file)\n",
        "  len_valid = len(v.keys())\n",
        "  lst = list(v.items())\n",
        "  print(lst[:3])\n",
        "  print(lst[0][1][\"words\"])\n",
        "  print(tokenize.encode_as_pieces(lst[0][1][\"words\"]))\n",
        "with open('/content/speechbrain/templates/speech_recognition/test_ru.json') as json_file:\n",
        "  t1 = json.load(json_file)\n",
        "  len_test = len(t1.keys())\n",
        "  lst = list(t1.items())\n",
        "  print(lst[:3])\n",
        "  print(lst[0][1][\"words\"])\n",
        "  print(tokenize.encode_as_pieces(lst[0][1][\"words\"]))\n",
        "\n",
        "print(f\"Records: train - {len_train}, valid - {len_valid}, test - {len_test},\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a748fd-1187-4199-fddc-f3d805fe1234",
        "id": "tZDaF8IXBrQ6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('f-6b-34a185db879f', {'wav': '{data_root}/f/6b/34a185db879f.wav', 'length': 0.93, 'words': 'ОТЛИ НЕ ЗНАЛ КАК'}), ('7-dd-805174e632e8', {'wav': '{data_root}/7/dd/805174e632e8.wav', 'length': 1.72, 'words': 'В КАКОМ СОСТОЯНИИ БЫЛ РЕБЁНОК'}), ('2-18-6d369c00387d', {'wav': '{data_root}/2/18/6d369c00387d.wav', 'length': 1.23, 'words': 'БАХИЛ У ЗАМОРИНА'})]\n",
            "ОТЛИ НЕ ЗНАЛ КАК\n",
            "['▁ОТ', 'ЛИ', '▁НЕ', '▁ЗНАЛ', '▁КАК']\n",
            "[('3-de-c15cd75a4b38', {'wav': '{data_root}/3/de/c15cd75a4b38.wav', 'length': 1.5, 'words': 'БИРК МЕЛЬКОМ ГЛЯНУЛ'}), ('d-7f-d5bef45ef029', {'wav': '{data_root}/d/7f/d5bef45ef029.wav', 'length': 2.04, 'words': 'Я ПРЕДСТАВИЛ СЕБЯ В ТАКОМ ВОТ КЛАСТЕРЕ'}), ('f-a4-30ebb41d6f39', {'wav': '{data_root}/f/a4/30ebb41d6f39.wav', 'length': 1.32, 'words': 'ТО БЛЕКЛО ЗАСВЕТИЛОСЬ'})]\n",
            "БИРК МЕЛЬКОМ ГЛЯНУЛ\n",
            "['▁Б', 'И', 'Р', 'К', '▁М', 'ЕЛЬ', 'КОМ', '▁Г', 'ЛЯ', 'НУЛ']\n",
            "[('8-55-81c7c26d7c33', {'wav': '{data_root}/8/55/81c7c26d7c33.wav', 'length': 1.83, 'words': 'ПОЛИЦЕЙСКАЯ ОРГАНИЗАЦИЯ'}), ('8-8c-b8b625eb85c4', {'wav': '{data_root}/8/8c/b8b625eb85c4.wav', 'length': 0.75, 'words': 'БОЧКА С ВОДОЙ'}), ('0-e4-e3e0a09643d0', {'wav': '{data_root}/0/e4/e3e0a09643d0.wav', 'length': 2.58, 'words': 'ОЛЕСЕЧКА ПОЖАЛУЙСТА НАМЕКНИ'})]\n",
            "ПОЛИЦЕЙСКАЯ ОРГАНИЗАЦИЯ\n",
            "['▁ПОЛИЦЕЙСК', 'АЯ', '▁', 'ОР', 'ГА', 'НИ', 'ЗА', 'Ц', 'ИЯ']\n",
            "Records: train - 6280, valid - 785, test - 785,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -3 /content/speechbrain/templates/speech_recognition/LM/data/train_ru.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b401fc-988d-4651-a981-c51e054715ce",
        "id": "zf6aFdfFBrQ6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ОТЛИ НЕ ЗНАЛ КАК\n",
            "В КАКОМ СОСТОЯНИИ БЫЛ РЕБЁНОК\n",
            "БАХИЛ У ЗАМОРИНА\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SentencePiece"
      ],
      "metadata": {
        "id": "p4Nm36voBrQ6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6da8a8c-4dd1-44dc-fdf3-381ef4dd5331",
        "id": "a7l08ZONBrQ6"
      },
      "source": [
        "import torch\n",
        "import sentencepiece as spm\n",
        "sp = spm.SentencePieceProcessor()\n",
        "#sp.load(\"/content/speechbrain/templates/speech_recognition/Tokenizer/save/1000_unigram.model\")\n",
        "sp.load(\"/content/speechbrain/templates/speech_recognition/Tokenizer/save/1000_unigram.model\")\n",
        "\n",
        "# Encode as pieces\n",
        "print(sp.encode_as_pieces('THE CITY OF MONTREAL'))\n",
        "print(sp.encode_as_ids('THE CITY OF MONTREAL'))\n",
        "\n",
        "# Encode as ids\n",
        "print(sp.encode_as_pieces('ИЗ СТОРОНЫ В СТОРОНУ ОЩУЩЕНИЕ КОТОРОГО ОН НИКОГДА'))\n",
        "print(sp.encode_as_ids('ИЗ СТОРОНЫ В СТОРОНУ ОЩУЩЕНИЕ КОТОРОГО ОН НИКОГДА'))\n",
        "\n",
        "print(sp.encode_as_pieces('ТЕПЕРЬ ЕГО ИМЯ ДАЖЕ ВОЙДЁТ'))\n",
        "print(sp.encode_as_pieces('ЧЕЛОВЕК ДОЛЖЕН БЫЛ ИСПУГАТЬСЯ ПОДОБНОЙ НЕПОНЯТНОСТИ И ЗАБЫВ ПРО КОСТЕР БЕЖАТЬ БЛИЖЕ К ЛЮДЯМ'))\n",
        "print(sp.encode_as_pieces('ВАС НАЙДУТСЯ ЖЕЛАЮЩИЕ ПОМОГАТЬ НЕСЧАСТНЫМ МОЛОДЫМ ЛЮДЯМ НЕ ПОЛУЧАЯ ЗА ЭТО НИКАКИХ ВИРРОВ ЭТО'))\n",
        "print(sp.pad_id() , sp.unk_id(), sp.bos_id(), sp.eos_id())\n",
        "print(sp.vocab_size() )\n",
        "vocab = {sp.IdToPiece(i): i for i in range(sp.GetPieceSize())}\n",
        "print(list(vocab)[:40])\n",
        "print(list(vocab)[-40:])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁', 'THE', '▁', 'CITY', '▁', 'OF', '▁', 'MONTREAL']\n",
            "[4, 0, 4, 0, 4, 0, 4, 0]\n",
            "['▁ИЗ', '▁С', 'ТО', 'РО', 'НЫ', '▁В', '▁СТОРОНУ', '▁О', 'Щ', 'УЩЕ', 'НИЕ', '▁КОТОР', 'ОГО', '▁ОН', '▁НИКОГДА']\n",
            "[71, 7, 63, 53, 154, 9, 662, 49, 67, 446, 188, 214, 109, 45, 598]\n",
            "['▁ТЕПЕРЬ', '▁ЕГО', '▁ИМ', 'Я', '▁ДАЖЕ', '▁ВО', 'ЙДЁТ']\n",
            "['▁ЧЕЛОВЕК', '▁ДОЛЖЕН', '▁БЫЛ', '▁ИСПУГ', 'АТЬСЯ', '▁ПОД', 'ОБ', 'НОЙ', '▁НЕ', 'ПО', 'НЯ', 'Т', 'НОСТИ', '▁И', '▁ЗА', 'БЫ', 'В', '▁ПРО', '▁КО', 'С', 'ТЕР', '▁Б', 'Е', 'Ж', 'АТЬ', '▁Б', 'ЛИ', 'ЖЕ', '▁К', '▁', 'ЛЮ', 'Д', 'Я', 'М']\n",
            "['▁ВАС', '▁НА', 'Й', 'ДУ', 'Т', 'СЯ', '▁ЖЕ', 'ЛА', 'Ю', 'ЩИЕ', '▁ПОМОГ', 'АТЬ', '▁НЕ', 'С', 'ЧА', 'СТ', 'НЫМ', '▁МО', 'ЛО', 'Д', 'ЫМ', '▁', 'ЛЮ', 'Д', 'Я', 'М', '▁НЕ', '▁ПОЛУ', 'ЧА', 'Я', '▁ЗА', '▁ЭТО', '▁НИКАК', 'ИХ', '▁В', 'И', 'Р', 'РО', 'В', '▁ЭТО']\n",
            "3 0 1 2\n",
            "1000\n",
            "['<unk>', '<s>', '</s>', '<pad>', '▁', 'Е', 'И', '▁С', 'А', '▁В', 'В', 'С', '▁И', 'У', 'Л', '▁НА', 'О', '▁НЕ', 'М', '▁ПО', 'Д', 'Я', 'Р', 'Н', 'Т', '▁У', 'Х', '▁ЗА', 'К', 'З', 'Ы', 'ЛИ', 'Б', '▁ЧТО', '▁Я', 'Ш', 'ЛА', 'НО', 'Й', 'КА']\n",
            "['▁МОЛОДО', '▁КОРОТК', 'ДЁРНУЛ', '▁СТРЕМИ', '▁ПЬЯН', '▁ОБРАТИЛ', '▁ТЁМНЫ', 'РОСТРАНСТВ', 'ЗАБОТ', '▁ПРИХОДИ', 'ДЕМОНСТРИР', 'СОГЛАСИЛСЯ', '▁ВЗДОХНУЛ', '▁ГОСУДАР', '▁НОРМАЛЬНО', '▁ОБЪЕКТ', '▁ОПРЕДЕЛИ', '▁РЕЗУЛЬТАТ', '▁СПАСИБО', '▁УЛЫБНУЛСЯ', '▁УТВЕРЖДА', '▁СИТУАЦИ', '▁ФИЛИПП', 'ВРЕМЕННО', '▁МАЛЕНЬКО', '▁СОТРУДНИ', '▁СОЛНЦА', '▁ОЧЕРЕДН', '▁ПОМЕЩЕНИ', '▁РАССТОЯНИ', '▁СПРЯТА', '▁СЧИТАЕТ', '▁РАСПОЛОЖ', 'ПОЖАЛУЙСТА', '▁ОСНОВАНИ', '▁ВНУТРИ', '▁ВИНОВАТ', '▁ЧЕМОДАН', 'Ъ', 'Ж']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIVLfSbiBrQ6"
      },
      "source": [
        "## **Step 4: Train a Language Model - Transformer**\n",
        "A Language Model (LM) can be used within a speech recognizer in different ways. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TransformerLM.yaml"
      ],
      "metadata": {
        "id": "I0ZG1WrZBrQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/speechbrain/templates/speech_recognition/LM/TransformerLM_ru.yaml\n",
        "# This is the Transformer LM that is used according to the Huggingface repository\n",
        "# Visit the HuggingFace model corresponding to the pretrained_lm_tokenizer_path\n",
        "# For more details about the model!\n",
        "# NB: It has to match the pre-trained TransformerLM!!\n",
        "vocab_size: 8583\n",
        "\n",
        "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
        "seed: 2223\n",
        "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
        "output_folder: !ref results/Transformer/<seed>\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "\n",
        "\n",
        "data_root: ../data\n",
        "data_folder: ../data\n",
        "data_folder_dataset: !ref <data_folder>/buriy_audiobooks_2_val\n",
        "#output_folder: ./save\n",
        "\n",
        "# Path where data-specification files are stored\n",
        "lm_train_data: data/train_01.txt\n",
        "lm_valid_data: data/valid_01.txt\n",
        "lm_test_data: data/test_01.txt\n",
        "\n",
        "# If you plan to train a system on an HPC cluster with a big dataset,\n",
        "# we strongly suggest doing the following:\n",
        "# 1- Compress the dataset in a single tar or zip file.\n",
        "# 2- Copy your dataset locally (i.e., the local disk of the computing node).\n",
        "# 3- Uncompress the dataset in the local folder.\n",
        "# 4- Set lm_{train,valid,test}_data with the local path.\n",
        "# Reading data from the local disk of the compute node (e.g. $SLURM_TMPDIR with SLURM-based clusters) is very important.\n",
        "# It allows you to read the data much faster without slowing down the shared filesystem.\n",
        "\n",
        "\n",
        "# The train logger writes training statistics to a file, as well as stdout.\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "# Training parameters\n",
        "number_of_epochs: 20\n",
        "#batch_size: 80\n",
        "#batch_size: 8\n",
        "batch_size: 4\n",
        "#lr: 0.001 # RNNLM\n",
        "#accu_steps: 1 # Gradient accumulation to simulate large batch training # RNNLM\n",
        "lr: 0.1 #10 # TrnasformerLM\n",
        "#lr: 100000\n",
        "lr_opt: 0.001\n",
        "accu_steps: 8 # Gradient accumulation to simulate large batch training\n",
        "ckpt_interval_minutes: 15 # save checkpoint every N min\n",
        "\n",
        "# Dataloader options\n",
        "train_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "    shuffle: True\n",
        "\n",
        "valid_dataloader_opts:\n",
        "    batch_size: 1\n",
        "\n",
        "test_dataloader_opts:\n",
        "    batch_size: 1\n",
        "\n",
        "# Outputs\n",
        "output_neurons: !ref <vocab_size>\n",
        "blank_index: 0\n",
        "bos_index: 2\n",
        "eos_index: 3\n",
        "unk_index: 1\n",
        "pad_index: 0\n",
        "\n",
        "#unk= 1\n",
        "#bos= 2\n",
        "#eos= 3\n",
        "#pad= 0\n",
        "\n",
        "# model params\n",
        "d_model: 768\n",
        "\n",
        "# Functions\n",
        "model: !new:speechbrain.lobes.models.transformer.TransformerLM.TransformerLM # yamllint disable-line rule:line-length\n",
        "    vocab: !ref <output_neurons>\n",
        "    d_model: !ref <d_model>\n",
        "    nhead: 12\n",
        "    num_encoder_layers: 12\n",
        "    num_decoder_layers: 0\n",
        "    d_ffn: 3072\n",
        "    dropout: 0.0\n",
        "    activation: !name:torch.nn.GELU\n",
        "    normalize_before: False\n",
        "\n",
        "modules:\n",
        "    model: !ref <model>\n",
        "#lm_model: !new:speechbrain.lobes.models.transformer.TransformerLM.TransformerLM\n",
        "#    vocab: !ref <vocab_size>\n",
        "#    d_model: 768 # The number of expected features in the encoder/decoder inputs (default=512).\n",
        "#    nhead: 12\n",
        "#    num_encoder_layers: 12\n",
        "#    num_decoder_layers: 0\n",
        "#    d_ffn: 3072\n",
        "#    dropout: 0.0\n",
        "#    activation: !name:torch.nn.GELU\n",
        "#    normalize_before: False\n",
        "\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        model: !ref <model>\n",
        "        scheduler: !ref <lr_annealing>\n",
        "        counter: !ref <epoch_counter>\n",
        "\n",
        "log_softmax: !new:speechbrain.nnet.activations.Softmax\n",
        "    apply_log: True\n",
        "\n",
        "optimizer: !name:torch.optim.Adam\n",
        "    #lr: 0\n",
        "    #lr: !ref <lr_opt>\n",
        "    lr: !ref <lr>\n",
        "    betas: (0.9, 0.98)\n",
        "    eps: 0.000000001\n",
        "#optimizer: !name:torch.optim.SGD\n",
        "    #lr: !ref <lr_opt>\n",
        "    #momentum: 0.9\n",
        "    \n",
        "\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.NoamScheduler\n",
        "    lr_initial: !ref <lr>\n",
        "    #n_warmup_steps: 250000\n",
        "    #n_warmup_steps: 15 # batch_size:80 -> steps 79\n",
        "    #n_warmup_steps: 80  # batch_size:8 -> steps 785\n",
        "    n_warmup_steps: 160  # batch_size:4 -> steps 1570\n",
        "    model_size: !ref <d_model>\n",
        "  \n",
        "\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <number_of_epochs>\n",
        "\n",
        "compute_cost: !name:speechbrain.nnet.losses.nll_loss\n",
        "\n",
        "tokenizer: !new:sentencepiece.SentencePieceProcessor\n",
        "\n",
        "# Tokenizer model (you must use the same tokenizer for LM and ASR training)\n",
        "#tokenizer_file: ../Tokenizer/save/5000_unigram.model\n",
        "#tokenizer_file: ../Tokenizer/save/1000_unigram.model\n",
        "#tokenizer_file: !ref ../Tokenizer/save/<vocab_size>_unigram.model\n",
        "tokenizer_file: !ref /content/tokenizer_<vocab_size>_word.model\n",
        "\n",
        "# Pretrain the tokenizer\n",
        "pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
        "    collect_in: !ref <save_folder>\n",
        "    loadables:\n",
        "        tokenizer: !ref <tokenizer>\n",
        "    paths:\n",
        "        tokenizer: !ref <tokenizer_file>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f1c712e-26dd-43a1-bb70-4139adcf9f21",
        "id": "Dto4kOFSBrQ7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/speechbrain/templates/speech_recognition/LM/TransformerLM_ru.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train_transformer_ru.py v_02 - main"
      ],
      "metadata": {
        "id": "l1ZfWESvBrQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/speechbrain/templates/speech_recognition/LM/train_transformer_ru.py\n",
        "#!/usr/bin/env python3\n",
        "# by  ASR Transformer transformerLM librispeech\n",
        "\"\"\"Recipe for training a Transformer ASR system with librispeech.\n",
        "The system employs an encoder, a decoder, and an attention mechanism\n",
        "between them. Decoding is performed with (CTC/Att joint) beamsearch coupled with a neural\n",
        "language model.\n",
        "To run this recipe, do the following:\n",
        "> python train.py hparams/transformer.yaml\n",
        "> python train.py hparams/conformer.yaml\n",
        "With the default hyperparameters, the system employs a convolutional frontend and a transformer.\n",
        "The decoder is based on a Transformer decoder. Beamsearch coupled with a Transformer\n",
        "language model is used  on the top of decoder probabilities.\n",
        "The neural network is trained on both CTC and negative-log likelihood\n",
        "targets and sub-word units estimated with Byte Pairwise Encoding (BPE)\n",
        "are used as basic recognition tokens. Training is performed on the full\n",
        "LibriSpeech dataset (960 h).\n",
        "The best model is the average of the checkpoints from last 5 epochs.\n",
        "The experiment file is flexible enough to support a large variety of\n",
        "different systems. By properly changing the parameter files, you can try\n",
        "different encoders, decoders, tokens (e.g, characters instead of BPE),\n",
        "training split (e.g, train-clean 100 rather than the full one), and many\n",
        "other possible variations.\n",
        "Authors\n",
        " * Jianyuan Zhong 2020\n",
        " * Mirco Ravanelli 2020\n",
        " * Peter Plantinga 2020\n",
        " * Samuele Cornell 2020, 2021, 2022\n",
        " * Titouan Parcollet 2021, 2022\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import speechbrain as sb\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import speechbrain as sb\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "from datasets import load_dataset\n",
        "#from prepare_ru_dataset import prepare_ru_dataset\n",
        "from speechbrain.utils.distributed import run_on_main\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Define training procedure\n",
        "class LM1(sb.core.Brain):\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Forward computations from the sentence batches to the output probabilities.\"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        tokens_bos, _ = batch.tokens_bos\n",
        "        #logits = self.hparams.model(tokens_bos)\n",
        "        logits = self.hparams.model(tokens_bos)\n",
        "        pred = self.hparams.log_softmax(logits)\n",
        "        return pred\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the loss given predictions and targets.\"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        tokens_eos, tokens_len = batch.tokens_eos\n",
        "        loss = self.hparams.compute_cost(\n",
        "            predictions, tokens_eos, length=tokens_len\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "    def fit_batch(self, batch):\n",
        "        \"\"\"Train the parameters given a single batch in input\"\"\"\n",
        "        predictions = self.compute_forward(batch, sb.Stage.TRAIN)\n",
        "        loss = self.compute_objectives(predictions, batch, sb.Stage.TRAIN)\n",
        "\n",
        "        (loss / self.hparams.accu_steps).backward()\n",
        "\n",
        "        if self.step % self.hparams.accu_steps == 0:\n",
        "            # gradient clipping & early stop if loss is not fini\n",
        "            self.check_gradients(loss)\n",
        "\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            if isinstance(\n",
        "                self.hparams.lr_annealing, sb.nnet.schedulers.NoamScheduler\n",
        "            ) or isinstance(\n",
        "                self.hparams.lr_annealing,\n",
        "                sb.nnet.schedulers.CyclicCosineScheduler,\n",
        "            ):\n",
        "                self.hparams.lr_annealing(self.optimizer)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
        "        stage_stats = {\"loss\": stage_loss}\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_stats = stage_stats\n",
        "\n",
        "        if stage == sb.Stage.VALID and sb.utils.distributed.if_main_process():\n",
        "            if not (\n",
        "                isinstance(\n",
        "                    self.hparams.lr_annealing, sb.nnet.schedulers.NoamScheduler\n",
        "                )\n",
        "                or isinstance(\n",
        "                    self.hparams.lr_annealing,\n",
        "                    sb.nnet.schedulers.CyclicCosineScheduler,\n",
        "                )\n",
        "            ):\n",
        "                old_lr, new_lr = self.hparams.lr_annealing(stage_loss)\n",
        "                sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
        "            else:\n",
        "                old_lr = self.hparams.lr_annealing.current_lr\n",
        "\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"epoch\": epoch, \"lr\": old_lr},\n",
        "                train_stats=self.train_stats,\n",
        "                valid_stats=stage_stats,\n",
        "            )\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta=stage_stats, min_keys=[\"loss\"],\n",
        "            )\n",
        "class LM(sb.core.Brain):\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Forward computations from the sentence batches to the output probabilities.\"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        tokens_bos, _ = batch.tokens_bos\n",
        "        logits = self.hparams.model(tokens_bos)\n",
        "        pred = self.hparams.log_softmax(logits)\n",
        "        return pred\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the loss given predictions and targets.\"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        tokens_eos, tokens_len = batch.tokens_eos\n",
        "        loss = self.hparams.compute_cost(\n",
        "            predictions, tokens_eos, length=tokens_len\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "    def fit_batch(self, batch):\n",
        "        \"\"\"Train the parameters given a single batch in input\"\"\"\n",
        "        predictions = self.compute_forward(batch, sb.Stage.TRAIN)\n",
        "        loss = self.compute_objectives(predictions, batch, sb.Stage.TRAIN)\n",
        "\n",
        "        (loss / self.hparams.accu_steps).backward()\n",
        "\n",
        "        if self.step % self.hparams.accu_steps == 0:\n",
        "            # gradient clipping & early stop if loss is not fini\n",
        "            self.check_gradients(loss)\n",
        "\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            if isinstance(\n",
        "                self.hparams.lr_annealing, sb.nnet.schedulers.NoamScheduler\n",
        "            ) or isinstance(\n",
        "                self.hparams.lr_annealing,\n",
        "                sb.nnet.schedulers.CyclicCosineScheduler,\n",
        "            ):\n",
        "                self.hparams.lr_annealing(self.optimizer)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
        "        stage_stats = {\"loss\": stage_loss}\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_stats = stage_stats\n",
        "\n",
        "        if stage == sb.Stage.VALID and sb.utils.distributed.if_main_process():\n",
        "            if not (\n",
        "                isinstance(\n",
        "                    self.hparams.lr_annealing, sb.nnet.schedulers.NoamScheduler\n",
        "                )\n",
        "                or isinstance(\n",
        "                    self.hparams.lr_annealing,\n",
        "                    sb.nnet.schedulers.CyclicCosineScheduler,\n",
        "                )\n",
        "            ):\n",
        "                old_lr, new_lr = self.hparams.lr_annealing(stage_loss)\n",
        "                sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
        "            else:\n",
        "                old_lr = self.hparams.lr_annealing.current_lr\n",
        "\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"epoch\": epoch, \"lr\": old_lr},\n",
        "                train_stats=self.train_stats,\n",
        "                valid_stats=stage_stats,\n",
        "            )\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta=stage_stats, min_keys=[\"loss\"],\n",
        "            )\n",
        "\n",
        "def dataio_prepare(hparams):\n",
        "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
        "    It also defines the data processing pipeline through user-defined functions.\"\"\"\n",
        "    data_folder = hparams[\"data_folder\"]\n",
        "    \n",
        "    # Prepare datasets\n",
        "    datasets = load_dataset(\n",
        "        \"text\",\n",
        "        data_files={\n",
        "            \"train\": hparams[\"lm_train_data\"],\n",
        "            \"valid\": hparams[\"lm_valid_data\"],\n",
        "            \"test\": hparams[\"lm_test_data\"],\n",
        "        },\n",
        "    )\n",
        "\n",
        "    # Convert huggingface's dataset to DynamicItemDataset via a magical function\n",
        "    train_data = sb.dataio.dataset.DynamicItemDataset.from_arrow_dataset(\n",
        "        datasets[\"train\"]\n",
        "    )\n",
        "    valid_data = sb.dataio.dataset.DynamicItemDataset.from_arrow_dataset(\n",
        "        datasets[\"valid\"]\n",
        "    )\n",
        "    test_data = sb.dataio.dataset.DynamicItemDataset.from_arrow_dataset(\n",
        "        datasets[\"test\"]\n",
        "    )\n",
        "    \n",
        "    datasets = [train_data, valid_data, test_data]\n",
        "    \n",
        "    tokenizer = hparams[\"tokenizer\"]\n",
        "    # for local file:\n",
        "    ####################################################\n",
        "    #!!!! skip in Tutorial\n",
        "    tokenizer.load(hparams[\"tokenizer_file\"])\n",
        "    ####################################################\n",
        "    #print(tokenizer.encode_as_pieces('ТЕПЕРЬ ЕГО ИМЯ ДАЖЕ ВОЙДЁТ'))\n",
        "\n",
        "\n",
        "    # 3. Define text pipeline:\n",
        "    # TODO: implement text augmentations pipelines\n",
        "    @sb.utils.data_pipeline.takes(\"text\")\n",
        "    @sb.utils.data_pipeline.provides(\"text\", \"tokens_bos\", \"tokens_eos\")\n",
        "    def text_pipeline(text):\n",
        "        yield text\n",
        "        tokens_list = tokenizer.encode_as_ids(text)\n",
        "        tokens_bos = torch.LongTensor([hparams[\"bos_index\"]] + (tokens_list))\n",
        "        yield tokens_bos\n",
        "        tokens_eos = torch.LongTensor(tokens_list + [hparams[\"eos_index\"]])\n",
        "        yield tokens_eos\n",
        "\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, text_pipeline)\n",
        "\n",
        "    # 4. Set output:\n",
        "    sb.dataio.dataset.set_output_keys(\n",
        "        datasets, [\"id\", \"text\", \"tokens_bos\", \"tokens_eos\"],\n",
        "    )\n",
        "    return train_data, valid_data, test_data\n",
        "    \n",
        "    \"\"\"\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, text_pipeline)\n",
        "\n",
        "    # 4. Set output:\n",
        "    sb.dataio.dataset.set_output_keys(\n",
        "        #datasets, [\"id\", \"sig\", \"wrd\", \"tokens_bos\", \"tokens_eos\", \"tokens\"],\n",
        "        datasets, [\"id\", \"wrd\", \"tokens_bos\", \"tokens_eos\", \"tokens\"],\n",
        "    )\n",
        "\n",
        "    return \n",
        "        train_data,\n",
        "        valid_data,\n",
        "        test_data,\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # CLI:\n",
        "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
        "    with open(hparams_file) as fin:\n",
        "        hparams = load_hyperpyyaml(fin, overrides)\n",
        "\n",
        "    # If distributed_launch=True then\n",
        "    # create ddp_group with the right communication protocol\n",
        "    sb.utils.distributed.ddp_init_group(run_opts)\n",
        "\n",
        "    # 1.  # Dataset prep (parsing Librispeech)\n",
        "    #from librispeech_prepare import prepare_librispeech  # noqa\n",
        "\n",
        "    # Create experiment directory\n",
        "    sb.create_experiment_directory(\n",
        "        experiment_directory=hparams[\"output_folder\"],\n",
        "        hyperparams_to_save=hparams_file,\n",
        "        overrides=overrides,\n",
        "    )\n",
        "\n",
        "    # multi-gpu (ddp) save data preparation\n",
        "    \"\"\"run_on_main(\n",
        "        #prepare_librispeech,\n",
        "        prepare_ru_dataset,\n",
        "          kwargs={\n",
        "            \"data_folder\": hparams[\"data_folder\"],\n",
        "            \"tr_splits\": hparams[\"train_splits\"],\n",
        "            \"dev_splits\": hparams[\"dev_splits\"],\n",
        "            \"te_splits\": hparams[\"test_splits\"],\n",
        "            \"save_folder\": hparams[\"data_folder\"],\n",
        "            \"merge_lst\": hparams[\"train_splits\"],\n",
        "            \"merge_name\": hparams[\"train_csv\"],\n",
        "            \"skip_prep\": hparams[\"skip_prep\"],\n",
        "        },\n",
        "        \n",
        "    )\"\"\"\n",
        "\n",
        "     # Data preparation, to be run on only one process.\n",
        "    \"\"\"\n",
        "    prepare_ru_dataset(\n",
        "        data_folder=hparams[\"data_folder\"],\n",
        "        data_folder_dataset=hparams[\"data_folder_dataset\"],\n",
        "        save_json_train=hparams[\"train_annotation\"],\n",
        "        save_json_valid=hparams[\"valid_annotation\"],\n",
        "        save_json_test=hparams[\"test_annotation\"],\n",
        "        save_LM_train = hparams[\"lm_train_data\"],\n",
        "        save_LM_valid = hparams[\"lm_valid_data\"],\n",
        "        save_LM_test = hparams[\"lm_test_data\"],\n",
        "        split_ratio=[80, 10, 10],\n",
        "\n",
        "    )\n",
        "    \"\"\"\n",
        "    train_data, valid_data, test_data = dataio_prepare(hparams)\n",
        "\n",
        "    # here we create the datasets objects as well as tokenization and encoding\n",
        "    #train_data, valid_data, test_datasets, tokenizer = dataio_prepare(hparams)\n",
        "    # Initialize the Brain object to prepare for LM training.\n",
        "    \n",
        "    # here we create the dataloader objects as well as tokenization and encoding\n",
        "    train_data, valid_data, test_data = dataio_prepare(hparams)\n",
        "\n",
        "    # We download the tokenizer from HuggingFace (or elsewhere depending on\n",
        "    # the path given in the YAML file).\n",
        "    run_on_main(hparams[\"pretrainer\"].collect_files)\n",
        "    hparams[\"pretrainer\"].load_collected(device=run_opts[\"device\"])\n",
        "\n",
        "    lm_brain = LM(\n",
        "        modules=hparams[\"modules\"],\n",
        "        opt_class=hparams[\"optimizer\"],\n",
        "        hparams=hparams,\n",
        "        run_opts=run_opts,\n",
        "        checkpointer=hparams[\"checkpointer\"],\n",
        "    )\n",
        "\n",
        "    lm_brain.fit(\n",
        "        lm_brain.hparams.epoch_counter,\n",
        "        train_data,\n",
        "        valid_data,\n",
        "        train_loader_kwargs=hparams[\"train_dataloader_opts\"],\n",
        "        valid_loader_kwargs=hparams[\"valid_dataloader_opts\"],\n",
        "    )\n",
        "\n",
        "    # evaluation\n",
        "    test_stats = lm_brain.evaluate(\n",
        "        test_data,\n",
        "        min_key=\"loss\",\n",
        "        test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf99243c-2092-4e47-853d-e7a737694458",
        "id": "octr_j2UBrQ8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/speechbrain/templates/speech_recognition/LM/train_transformer_ru.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train LM"
      ],
      "metadata": {
        "id": "vbFax-f6BrRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train LM p1"
      ],
      "metadata": {
        "id": "O5EWCF8Ei0IJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "%cd /content/speechbrain/templates/speech_recognition/LM\n",
        "if torch.cuda.is_available(): \n",
        "    !python train_transformer_ru.py TransformerLM_ru.yaml --number_of_epochs=1 --batch_size=32\n",
        "else:\n",
        "  !python train_transformer_ru.py TransformerLM_ru.yaml --number_of_epochs=1 --batch_size=32 --device='cpu'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db140dc7-e795-4fb8-e0bd-136b051ad509",
        "id": "yvqvSGHRBrRC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/speechbrain/templates/speech_recognition/LM\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/Transformer/2223\n",
            "datasets.builder - Using custom data configuration default-5e0c31baa5aaf381\n",
            "datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-5e0c31baa5aaf381/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
            "100% 3/3 [00:00<00:00, 670.20it/s]\n",
            "datasets.builder - Using custom data configuration default-5e0c31baa5aaf381\n",
            "datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-5e0c31baa5aaf381/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
            "100% 3/3 [00:00<00:00, 1103.76it/s]\n",
            "speechbrain.pretrained.fetching - Fetch tokenizer_8583_word.model: Using existing file/symlink in results/Transformer/2223/save/tokenizer.ckpt.\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: tokenizer\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 98.8M trainable parameters in LM\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n",
            "100% 163/163 [12:55<00:00,  4.76s/it, train_loss=11.8]\n",
            "100% 651/651 [00:51<00:00, 12.57it/s]\n",
            "speechbrain.utils.train_logger - epoch: 1, lr: 3.39e-05 - train loss: 11.81 - valid loss: 8.92\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-24-19+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/Transformer/2223/save/CKPT+2022-06-03+08-24-19+00\n",
            "100% 651/651 [00:51<00:00, 12.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Train LM p2"
      ],
      "metadata": {
        "id": "9flOBE_3idsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/speechbrain/templates/speech_recognition/LM\n",
        "if torch.cuda.is_available(): \n",
        "    !python train_transformer_ru.py TransformerLM_ru.yaml #--device='cpu'\n",
        "else:\n",
        "  !python train_transformer_ru.py TransformerLM_ru.yaml --number_of_epochs=5 --batch_size=32 --device='cpu'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RInQjWK3iMWP",
        "outputId": "327dc7a7-24e4-480d-9da5-9ca691d82d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/speechbrain/templates/speech_recognition/LM\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/Transformer/2223\n",
            "datasets.builder - Using custom data configuration default-5e0c31baa5aaf381\n",
            "datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-5e0c31baa5aaf381/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
            "100% 3/3 [00:00<00:00, 698.43it/s]\n",
            "datasets.builder - Using custom data configuration default-5e0c31baa5aaf381\n",
            "datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-5e0c31baa5aaf381/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
            "100% 3/3 [00:00<00:00, 1149.86it/s]\n",
            "speechbrain.pretrained.fetching - Fetch tokenizer_8583_word.model: Using existing file/symlink in results/Transformer/2223/save/tokenizer.ckpt.\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: tokenizer\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 98.8M trainable parameters in LM\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/Transformer/2223/save/CKPT+2022-06-03+08-24-19+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n",
            " 75% 123/163 [10:01<03:15,  4.89s/it, train_loss=9.17]\n",
            "speechbrain.core - Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"train_transformer_ru.py\", line 342, in <module>\n",
            "    valid_loader_kwargs=hparams[\"valid_dataloader_opts\"],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/speechbrain/core.py\", line 1034, in fit\n",
            "    loss = self.fit_batch(batch)\n",
            "  File \"train_transformer_ru.py\", line 141, in fit_batch\n",
            "    (loss / self.hparams.accu_steps).backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 307, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 156, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train LM p3 GPU"
      ],
      "metadata": {
        "id": "vjWg9H49ueoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "%cd /content/speechbrain/templates/speech_recognition/LM\n",
        "if torch.cuda.is_available(): \n",
        "    !python train_transformer_ru.py TransformerLM_ru.yaml --number_of_epochs=1 --batch_size=32\n",
        "else:\n",
        "  !python train_transformer_ru.py TransformerLM_ru.yaml --number_of_epochs=1 --batch_size=32 --device='cpu'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe63b53b-9b7d-475f-e84a-a6428f198166",
        "id": "c3xjFunqueou"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/speechbrain/templates/speech_recognition/LM\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/Transformer/2223\n",
            "datasets.builder - Using custom data configuration default-cb19e2977b364852\n",
            "datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-cb19e2977b364852/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
            "100% 3/3 [00:00<00:00, 945.59it/s]\n",
            "datasets.builder - Using custom data configuration default-cb19e2977b364852\n",
            "datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-cb19e2977b364852/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
            "100% 3/3 [00:00<00:00, 1110.88it/s]\n",
            "speechbrain.pretrained.fetching - Fetch tokenizer_8583_word.model: Linking to local file in /content/tokenizer_8583_word.model.\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: tokenizer\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 98.8M trainable parameters in LM\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n",
            "100% 163/163 [00:15<00:00, 10.57it/s, train_loss=13.5]\n",
            "100% 651/651 [00:05<00:00, 109.78it/s]\n",
            "speechbrain.utils.train_logger - epoch: 1, lr: 3.39e-05 - train loss: 13.48 - valid loss: 11.08\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-51-32+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/Transformer/2223/save/CKPT+2022-06-03+08-51-32+00\n",
            "100% 651/651 [00:07<00:00, 86.70it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train LM p4 GPU"
      ],
      "metadata": {
        "id": "f8og6Ok1w0z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "%cd /content/speechbrain/templates/speech_recognition/LM\n",
        "if torch.cuda.is_available(): \n",
        "    !python train_transformer_ru.py TransformerLM_ru.yaml --number_of_epochs=20 --batch_size=32\n",
        "else:\n",
        "  !python train_transformer_ru.py TransformerLM_ru.yaml --number_of_epochs=20 --batch_size=32 --device='cpu'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a32f655f-c5e8-4002-856a-a83406a46a7b",
        "id": "6rbSRyXkw0z0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/speechbrain/templates/speech_recognition/LM\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/Transformer/2223\n",
            "datasets.builder - Using custom data configuration default-cb19e2977b364852\n",
            "datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-cb19e2977b364852/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
            "100% 3/3 [00:00<00:00, 434.54it/s]\n",
            "datasets.builder - Using custom data configuration default-cb19e2977b364852\n",
            "datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-cb19e2977b364852/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n",
            "100% 3/3 [00:00<00:00, 1184.61it/s]\n",
            "speechbrain.pretrained.fetching - Fetch tokenizer_8583_word.model: Using existing file/symlink in results/Transformer/2223/save/tokenizer.ckpt.\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: tokenizer\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 98.8M trainable parameters in LM\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/Transformer/2223/save/CKPT+2022-06-03+08-51-32+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n",
            "100% 163/163 [00:15<00:00, 10.25it/s, train_loss=8.66]\n",
            "100% 651/651 [00:06<00:00, 106.94it/s]\n",
            "speechbrain.utils.train_logger - epoch: 2, lr: 6.95e-05 - train loss: 8.66 - valid loss: 7.77\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-52-36+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-51-32+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 3\n",
            "100% 163/163 [00:16<00:00, 10.17it/s, train_loss=8.39]\n",
            "100% 651/651 [00:06<00:00, 107.16it/s]\n",
            "speechbrain.utils.train_logger - epoch: 3, lr: 1.05e-04 - train loss: 8.39 - valid loss: 7.25\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-53-02+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-52-36+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 4\n",
            "100% 163/163 [00:16<00:00,  9.86it/s, train_loss=7.59]\n",
            "100% 651/651 [00:06<00:00, 106.38it/s]\n",
            "speechbrain.utils.train_logger - epoch: 4, lr: 1.41e-04 - train loss: 7.59 - valid loss: 6.91\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-53-29+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-53-02+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 5\n",
            "100% 163/163 [00:16<00:00,  9.65it/s, train_loss=6.73]\n",
            "100% 651/651 [00:06<00:00, 107.15it/s]\n",
            "speechbrain.utils.train_logger - epoch: 5, lr: 1.77e-04 - train loss: 6.73 - valid loss: 6.88\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-53-57+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-53-29+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 6\n",
            "100% 163/163 [00:17<00:00,  9.33it/s, train_loss=6.68]\n",
            "100% 651/651 [00:06<00:00, 107.20it/s]\n",
            "speechbrain.utils.train_logger - epoch: 6, lr: 2.12e-04 - train loss: 6.68 - valid loss: 6.96\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-54-25+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 7\n",
            "100% 163/163 [00:17<00:00,  9.34it/s, train_loss=6.67]\n",
            "100% 651/651 [00:06<00:00, 107.96it/s]\n",
            "speechbrain.utils.train_logger - epoch: 7, lr: 2.48e-04 - train loss: 6.67 - valid loss: 7.03\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-54-52+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-54-25+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 8\n",
            "100% 163/163 [00:17<00:00,  9.45it/s, train_loss=6.66]\n",
            "100% 651/651 [00:06<00:00, 108.09it/s]\n",
            "speechbrain.utils.train_logger - epoch: 8, lr: 2.83e-04 - train loss: 6.66 - valid loss: 7.06\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-55-20+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-54-52+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 9\n",
            "100% 163/163 [00:17<00:00,  9.35it/s, train_loss=6.66]\n",
            "100% 651/651 [00:06<00:00, 106.13it/s]\n",
            "speechbrain.utils.train_logger - epoch: 9, lr: 2.70e-04 - train loss: 6.66 - valid loss: 7.08\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-55-48+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-55-20+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 10\n",
            "100% 163/163 [00:17<00:00,  9.37it/s, train_loss=6.68]\n",
            "100% 651/651 [00:06<00:00, 105.81it/s]\n",
            "speechbrain.utils.train_logger - epoch: 10, lr: 2.56e-04 - train loss: 6.68 - valid loss: 7.12\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-56-16+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-55-48+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 11\n",
            "100% 163/163 [00:17<00:00,  9.36it/s, train_loss=6.66]\n",
            "100% 651/651 [00:05<00:00, 108.90it/s]\n",
            "speechbrain.utils.train_logger - epoch: 11, lr: 2.44e-04 - train loss: 6.66 - valid loss: 7.14\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-56-44+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-56-16+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 12\n",
            "100% 163/163 [00:17<00:00,  9.43it/s, train_loss=6.65]\n",
            "100% 651/651 [00:05<00:00, 108.62it/s]\n",
            "speechbrain.utils.train_logger - epoch: 12, lr: 2.33e-04 - train loss: 6.65 - valid loss: 7.17\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-57-11+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-56-44+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 13\n",
            "100% 163/163 [00:17<00:00,  9.36it/s, train_loss=6.65]\n",
            "100% 651/651 [00:06<00:00, 106.29it/s]\n",
            "speechbrain.utils.train_logger - epoch: 13, lr: 2.24e-04 - train loss: 6.65 - valid loss: 7.18\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-57-39+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-57-11+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 14\n",
            "100% 163/163 [00:17<00:00,  9.40it/s, train_loss=6.65]\n",
            "100% 651/651 [00:09<00:00, 67.26it/s] \n",
            "speechbrain.utils.train_logger - epoch: 14, lr: 2.16e-04 - train loss: 6.65 - valid loss: 7.19\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-58-11+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-57-39+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 15\n",
            "100% 163/163 [00:17<00:00,  9.36it/s, train_loss=6.64]\n",
            "100% 651/651 [00:06<00:00, 106.86it/s]\n",
            "speechbrain.utils.train_logger - epoch: 15, lr: 2.09e-04 - train loss: 6.64 - valid loss: 7.21\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-58-39+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-58-11+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 16\n",
            "100% 163/163 [00:17<00:00,  9.35it/s, train_loss=6.64]\n",
            "100% 651/651 [00:09<00:00, 66.27it/s]\n",
            "speechbrain.utils.train_logger - epoch: 16, lr: 2.02e-04 - train loss: 6.64 - valid loss: 7.23\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-59-10+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-58-39+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 17\n",
            "100% 163/163 [00:17<00:00,  9.47it/s, train_loss=6.65]\n",
            "100% 651/651 [00:06<00:00, 106.34it/s]\n",
            "speechbrain.utils.train_logger - epoch: 17, lr: 1.96e-04 - train loss: 6.65 - valid loss: 7.26\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-59-38+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-59-10+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 18\n",
            "100% 163/163 [00:17<00:00,  9.20it/s, train_loss=6.64]\n",
            "100% 651/651 [00:06<00:00, 101.04it/s]\n",
            "speechbrain.utils.train_logger - epoch: 18, lr: 1.90e-04 - train loss: 6.64 - valid loss: 7.26\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+09-00-07+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+08-59-38+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 19\n",
            "100% 163/163 [00:17<00:00,  9.43it/s, train_loss=6.64]\n",
            "100% 651/651 [00:06<00:00, 106.13it/s]\n",
            "speechbrain.utils.train_logger - epoch: 19, lr: 1.85e-04 - train loss: 6.64 - valid loss: 7.29\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+09-00-35+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+09-00-07+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 20\n",
            "100% 163/163 [00:17<00:00,  9.46it/s, train_loss=6.64]\n",
            "100% 651/651 [00:06<00:00, 106.76it/s]\n",
            "speechbrain.utils.train_logger - epoch: 20, lr: 1.81e-04 - train loss: 6.64 - valid loss: 7.31\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+09-01-03+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/Transformer/2223/save/CKPT+2022-06-03+09-00-35+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/Transformer/2223/save/CKPT+2022-06-03+08-53-57+00\n",
            "100% 651/651 [00:06<00:00, 106.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save pretrained models: Tokenizer, LM  "
      ],
      "metadata": {
        "id": "qBcXESrNBrRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b7971f-7530-494e-9231-8cfe8c64862a",
        "id": "3osffa6tBrRC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/Colab Notebooks/_My_Projects/Language_modeling/'\n",
        "!cp /content/tokenizer_8583_word.model '$save_path'\n",
        "!cp /content/tokenizer_8583_word.vocab '$save_path'"
      ],
      "metadata": {
        "id": "yXIHLGfUygsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GCTU7elAzr2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/Colab Notebooks/_My_Projects/Language_modeling/'\n",
        "from_path ='/content/speechbrain/templates/speech_recognition/LM/results/Transformer/2223/save/CKPT+2022-06-03+09-01-03+00/model.ckpt'\n",
        "!cp '$from_path' '$save_path'"
      ],
      "metadata": {
        "id": "ojA1Gd6Bz47w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upload_file(\n",
        "      path_or_fileobj=os.path.join(from_path+'/save', 'tokenizer.ckpt'),\n",
        "      path_in_repo= 'tokenizer.ckpt',\n",
        "      repo_id=user_name+'/'+ repo_name, \n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9cb02e69-3b0a-4612-a94e-ca953e115b4c",
        "id": "O_jf-40KzsBY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://huggingface.co/AndyGo/speechbrain-asr-transformer-transformerlm-buriy-audiobooks-2-val/blob/main/tokenizer.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "!mkdir /content/HF\n",
        "%cd /content/HF/\n",
        "!git init\n",
        "!git lfs install\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211,
          "referenced_widgets": [
            "b7491ded902d4d9bab9c8534b590cada",
            "4d27cd5a79d54e3aad28e6e51d8b1232",
            "0151ff38686d4e95b46b15166df5ca0f",
            "c8862e6d9e344bddbed90cb1e5df9ccf",
            "0fb9a888ba5446bc87edbe872daeae2f",
            "b00b1ee32d06408a83a34cee5167f1bc",
            "4166b073ce8947b49bcb88cdde05849f",
            "6e7d58d0debe47e5a3c64a9412d350a9",
            "043a77ceebbc4259ae17cb76b0bd2a4f",
            "8d65cb92bdb847b18be448400fc6cb77",
            "d734c7d27fdc45c49884cbadaff16165",
            "c187ff89731643a9aee35282a396df12",
            "48b2bc061522410e9d180a8b72976369",
            "1987efa5bd284ecdbb9635fdaeac9375",
            "31a220053bfb4ababaae11b35784e905",
            "55d714109efa4404bab686a30cc5c866",
            "2f784f994fd14c3bb6b5ee7174c15c55",
            "e720807075f84402a023be9eed81cfdc",
            "fd9d047cad9a4f11a69304ea3f5475c4",
            "eed7cfeeef3f47cfad3062f7e81b8150",
            "79461cd67ca44c8eaef6d87c2f4a2c7f",
            "7aad6a27b4e145c8903d40e07d39c22f",
            "32c2705ab081417098483afc3f6d39f5",
            "bc9c4308f7cf4c04832af67ee9dd71ab",
            "5620afb8d1724b39bc154234450790e0",
            "d876540bf55c4240b04518594a46e461",
            "1fc9a1918e33480fb539b47a879e7d7b",
            "2b467f80bee54a7ea713607de933d106",
            "47da43afe94e43298c33750cbbfd26dc",
            "a13b1d9700be42c4ab6c18934751f33d",
            "476e238b9d5146eea58c798d4e4e6dd5",
            "76204a040c5f468ea8e4f24fdb6c3fc8"
          ]
        },
        "outputId": "73e0769c-aae4-4392-c594-1a813eb39668",
        "id": "MBKl0Fp4BrRC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/huggingface_hub/hf_api.py:587: FutureWarning: HfApi.login: This method is deprecated in favor of `set_access_token` and will be removed in v0.7.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
            "\n",
            "git config --global credential.helper store\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save_path = \"/content/drive/MyDrive/Colab Notebooks/_ODS_Study/ODS_NLP_spring_2022/_Project/_Experiments/Exp_03_TransformerLM_Transforner\"\n",
        "save_path = \"/content/drive/MyDrive/ODS_Project/Exp_03\"\n",
        "from_path = '/content/speechbrain/templates/speech_recognition/LM/results/Transformer/2223'\n",
        "variant='03_05'\n",
        "epoch_start=41; epochs=20\n",
        "def save_logs(save_path, from_path, variant, epoch_start, epochs):\n",
        "    timezone_offset = +3.0 # локальное время от международного\n",
        "    tzinfo = datetime.timezone(datetime.timedelta(hours=timezone_offset))\n",
        "    current_datetime = datetime.datetime.now(tzinfo).strftime(\"%Y_%m_%d__%H_%M_%S\")\n",
        "    \n",
        "    loc_str = f\"v{variant}_eps_{epoch_start:03d}-{epoch_start+epochs-1:03d}_{current_datetime}\"\n",
        "    !cp -r '$from_path'/train_log.txt '$save_path'/LM_train_log_'$loc_str'.txt\n",
        "    !cp -r '$from_path'/log.txt '$save_path'/LM_log_'$loc_str'.txt\n",
        "    #!cp -r '$from_path'/wer.txt '$save_path'/wer_'$loc_str'.txt\n",
        "save_logs(save_path, from_path, variant, epoch_start=epoch_start, epochs=epochs)"
      ],
      "metadata": {
        "id": "_Sv_vvhEBrRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from huggingface_hub import upload_file\n",
        "curr_names = ['model.ckpt', 'normalize.ckpt']\n",
        "new_names = ['asr.ckpt', 'normalize.ckpt']\n",
        "user_name=\"AndyGo\"\n",
        "repo_name= \"speechbrain-asr-transformer-transformerlm-buriy-audiobooks-2-val\"\n",
        "#save_path = \"/content/drive/MyDrive/Colab Notebooks/_ODS_Study/ODS_NLP_spring_2022/_Project/_Experiments/Exp_03_TransformerLM_Transforner\"\n",
        "save_path = \"/content/drive/MyDrive/ODS_Project/Exp_03\"\n",
        "from_path = '/content/speechbrain/templates/speech_recognition/LM/results/Transformer/2223'\n",
        "variant='03_05'\n",
        "def upload_models_2_HF(save_path, from_path, \n",
        "                     curr_names = ['model.ckpt'], new_names = ['lm.ckpt'],\n",
        "                     user_name=\"AndyGo\", repo_name= \"speechbrain-asr-transformer-transformerlm-buriy-audiobooks-2-val\"):\n",
        "  from_dir = glob.glob(from_path+'/save/CKPT*')\n",
        "  #print(from_dir)\n",
        "  from_dir= sorted(from_dir)[-1]\n",
        "  #print(from_dir)\n",
        "  saved = []\n",
        "  for i, curr_name in enumerate(curr_names):\n",
        "    saved.append(upload_file(\n",
        "      path_or_fileobj=os.path.join(from_dir,curr_name),\n",
        "      path_in_repo=new_names[i], \n",
        "      repo_id=user_name+'/'+ repo_name, \n",
        "      ) )\n",
        "  return saved\n",
        "upload_models_2_HF(save_path, from_path)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c0b233d-e20a-4cf0-fc0a-9b133c9e3a24",
        "id": "4FzGELE5BrRD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://huggingface.co/AndyGo/speechbrain-asr-transformer-transformerlm-buriy-audiobooks-2-val/blob/main/lm.ckpt']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upload_file(\n",
        "      path_or_fileobj=os.path.join(from_path+'/save', 'tokenizer.ckpt'),\n",
        "      path_in_repo= 'tokenizer.ckpt',\n",
        "      repo_id=user_name+'/'+ repo_name, \n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9cb02e69-3b0a-4612-a94e-ca953e115b4c",
        "id": "eSaGjEFoBrRD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://huggingface.co/AndyGo/speechbrain-asr-transformer-transformerlm-buriy-audiobooks-2-val/blob/main/tokenizer.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_name = '1000_unigram.model'\n",
        "fr_path_tokenuzer= '/content/speechbrain/templates/speech_recognition/Tokenizer/save/'+ f_name\n",
        "\n",
        "upload_file(\n",
        "      path_or_fileobj=fr_path_tokenuzer,\n",
        "      path_in_repo= f_name,\n",
        "      repo_id=user_name+'/'+ repo_name, \n",
        "      )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "18b5f232-d728-4433-9019-8f11e8a636c0",
        "id": "eidKXKe3BrRD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://huggingface.co/AndyGo/speechbrain-asr-transformer-transformerlm-buriy-audiobooks-2-val/blob/main/1000_unigram.model'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### restore Language Model"
      ],
      "metadata": {
        "id": "xGJ5vrIM0f9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c3e4db4-3451-4cd4-ce2f-753edbf4a5de",
        "id": "CEqHxokd1C2l"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/Colab Notebooks/_My_Projects/Language_modeling/'\n",
        "to_path ='/content/'\n",
        "!cp '$save_path'model.ckpt '$to_path'"
      ],
      "metadata": {
        "id": "C2VYI7Ij0iy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 2 CRDNNLM"
      ],
      "metadata": {
        "id": "8H7Rjy7TBG6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1. Setup & Import "
      ],
      "metadata": {
        "id": "u-GX_cvtBYCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SpeechBrain"
      ],
      "metadata": {
        "id": "V-FGoJW0BYCI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "591b0a87-b685-4eb6-ce39-ad08506f607e",
        "id": "TV3CSrP0BYCJ"
      },
      "source": [
        "%%time\n",
        "#%%capture\n",
        "# Local installation\n",
        "import os\n",
        "%cd /content/\n",
        "if not os.path.exists('/content/speechbrain/'):\n",
        "    !git clone https://github.com/speechbrain/speechbrain/\n",
        "%cd /content/speechbrain/\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e ."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'speechbrain'...\n",
            "remote: Enumerating objects: 56387, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 56387 (delta 16), reused 21 (delta 14), pack-reused 56359\u001b[K\n",
            "Receiving objects: 100% (56387/56387), 61.79 MiB | 23.35 MiB/s, done.\n",
            "Resolving deltas: 100% (32702/32702), done.\n",
            "/content/speechbrain\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Ignoring SoundFile: markers 'sys_platform == \"win32\"' don't match your environment\n",
            "Collecting black==19.10b0\n",
            "  Downloading black-19.10b0-py36-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting click==8.0.4\n",
            "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting flake8==3.7.9\n",
            "  Downloading flake8-3.7.9-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting pycodestyle==2.5.0\n",
            "  Downloading pycodestyle-2.5.0-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting pytest==5.4.1\n",
            "  Downloading pytest-5.4.1-py3-none-any.whl (246 kB)\n",
            "\u001b[K     |████████████████████████████████| 246 kB 20.5 MB/s \n",
            "\u001b[?25hCollecting yamllint==1.23.0\n",
            "  Downloading yamllint-1.23.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting huggingface_hub>=0.0.6\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting hyperpyyaml>=0.0.1\n",
            "  Downloading HyperPyYAML-1.0.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (21.3)\n",
            "Collecting pre-commit>=2.3.0\n",
            "  Downloading pre_commit-2.19.0-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.4.1)\n",
            "Collecting sentencepiece>=0.1.91\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<=1.11.1,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchaudio<=0.11.1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.11.0+cu113)\n",
            "Requirement already satisfied: tqdm>=4.42.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.64.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->-r lint-requirements.txt (line 1)) (21.4.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->-r lint-requirements.txt (line 1)) (1.4.4)\n",
            "Collecting pathspec<1,>=0.6\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->-r lint-requirements.txt (line 1)) (2022.6.2)\n",
            "Collecting toml>=0.9.4\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting typed-ast>=1.4.0\n",
            "  Downloading typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click==8.0.4->-r lint-requirements.txt (line 2)) (4.11.4)\n",
            "Collecting entrypoints<0.4.0,>=0.3.0\n",
            "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pyflakes<2.2.0,>=2.1.0\n",
            "  Downloading pyflakes-2.1.1-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.1->-r lint-requirements.txt (line 5)) (1.11.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.1->-r lint-requirements.txt (line 5)) (0.2.5)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.1->-r lint-requirements.txt (line 5)) (8.13.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from yamllint==1.23.0->-r lint-requirements.txt (line 6)) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (4.1.1)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (3.7.1)\n",
            "Collecting ruamel.yaml>=0.17.8\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->-r requirements.txt (line 6)) (3.0.9)\n",
            "Collecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting cfgv>=2.0.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting identify>=1.0.0\n",
            "  Downloading identify-2.5.1-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting virtualenv>=20.0.8\n",
            "  Downloading virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 15.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click==8.0.4->-r lint-requirements.txt (line 2)) (3.8.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 30.7 MB/s \n",
            "\u001b[?25hCollecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 38.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit>=2.3.0->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (1.24.3)\n",
            "Building wheels for collected packages: hyperpyyaml\n",
            "  Building wheel for hyperpyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hyperpyyaml: filename=HyperPyYAML-1.0.1-py3-none-any.whl size=15192 sha256=51321e1ff5d29eba90c1b45e45d414ca99844235fc147263ff38447dd79a50f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/87/65/266d722c3932f81f16332ce842e972be8421e3a9cd3771766b\n",
            "Successfully built hyperpyyaml\n",
            "Installing collected packages: ruamel.yaml.clib, platformdirs, distlib, virtualenv, typed-ast, toml, ruamel.yaml, pyyaml, pyflakes, pycodestyle, pluggy, pathspec, nodeenv, mccabe, identify, entrypoints, click, cfgv, yamllint, sentencepiece, pytest, pre-commit, hyperpyyaml, huggingface-hub, flake8, black\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: entrypoints\n",
            "    Found existing installation: entrypoints 0.4\n",
            "    Uninstalling entrypoints-0.4:\n",
            "      Successfully uninstalled entrypoints-0.4\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed black-19.10b0 cfgv-3.3.1 click-8.0.4 distlib-0.3.4 entrypoints-0.3 flake8-3.7.9 huggingface-hub-0.7.0 hyperpyyaml-1.0.1 identify-2.5.1 mccabe-0.6.1 nodeenv-1.6.0 pathspec-0.9.0 platformdirs-2.5.2 pluggy-0.13.1 pre-commit-2.19.0 pycodestyle-2.5.0 pyflakes-2.1.1 pytest-5.4.1 pyyaml-6.0 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 sentencepiece-0.1.96 toml-0.10.2 typed-ast-1.5.4 virtualenv-20.14.1 yamllint-1.23.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/speechbrain\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.4.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (0.1.96)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.0.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.1.0)\n",
            "Requirement already satisfied: torch<=1.11,>=1.7 in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (0.11.0+cu113)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.11,>=1.7->speechbrain==0.5.11) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain==0.5.11) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain==0.5.11) (4.11.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain==0.5.11) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain==0.5.11) (3.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->speechbrain==0.5.11) (3.0.9)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.8 in /usr/local/lib/python3.7/dist-packages (from hyperpyyaml->speechbrain==0.5.11) (0.17.21)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.17.8->hyperpyyaml->speechbrain==0.5.11) (0.2.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->speechbrain==0.5.11) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain==0.5.11) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain==0.5.11) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain==0.5.11) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain==0.5.11) (3.0.4)\n",
            "Installing collected packages: speechbrain\n",
            "  Running setup.py develop for speechbrain\n",
            "Successfully installed speechbrain\n",
            "CPU times: user 668 ms, sys: 122 ms, total: 790 ms\n",
            "Wall time: 1min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "646ec037-75a9-48cf-994a-1d01d9351674",
        "id": "Jy4iLD_EBYCJ"
      },
      "source": [
        "%%time\n",
        "#%%capture\n",
        "# to avoid the error No  module find error\n",
        "# import speechbrain as sb\n",
        "# For pip installation\n",
        "!pip install speechbrain"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting speechbrain\n",
            "  Downloading speechbrain-0.5.11-py3-none-any.whl (408 kB)\n",
            "\u001b[K     |████████████████████████████████| 408 kB 13.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.1.96)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from speechbrain) (21.3)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.11.0+cu113)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from speechbrain) (4.64.0)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.4.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.7.0)\n",
            "Requirement already satisfied: torch<=1.11,>=1.7 in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.11,>=1.7->speechbrain) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (3.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (4.11.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->speechbrain) (3.0.9)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.8 in /usr/local/lib/python3.7/dist-packages (from hyperpyyaml->speechbrain) (0.17.21)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.17.8->hyperpyyaml->speechbrain) (0.2.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->speechbrain) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (3.0.4)\n",
            "Installing collected packages: speechbrain\n",
            "Successfully installed speechbrain-0.5.11\n",
            "CPU times: user 44.5 ms, sys: 18.9 ms, total: 63.4 ms\n",
            "Wall time: 4.54 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b4455b-3894-4aad-969f-5e56223802f0",
        "id": "4tVvJUGcBYCK"
      },
      "source": [
        "%%time\n",
        "!pip install datasets"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n",
            "\u001b[K     |████████████████████████████████| 362 kB 15.6 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 57.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.7.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 59.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 58.5 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 47.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.3.2 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n",
            "CPU times: user 194 ms, sys: 41.4 ms, total: 236 ms\n",
            "Wall time: 17.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "yPfNxI5eBYCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install wget\n",
        "#from wget import download\n",
        "import os\n",
        "import hashlib\n",
        "\n",
        "from IPython.display import display, Audio\n",
        "import torch\n",
        "import torchaudio\n",
        "import datetime\n",
        "import gc\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from huggingface_hub import notebook_login\n",
        "#from huggingface_hub import upload_file\n"
      ],
      "metadata": {
        "id": "5qA__nlkBYCK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd /content/\n",
        "#!git clone https://github.com/snakers4/open_stt"
      ],
      "metadata": {
        "id": "ZU_WJzAIBYCK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2: Prepare Data**"
      ],
      "metadata": {
        "id": "oSXlUkVFcje8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data"
      ],
      "metadata": {
        "id": "1iM4CDD0cje8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "data_link = \"https://drive.google.com/file/d/1vQbu1XmenVtNYSvqZmiwAo2jzFWZCsI8/view?usp=sharing\"\n",
        "file_id= data_link.split('/')[-2]\n",
        "fn = 'medium_data.csv'\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=''$file_id' -O '$fn'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3cd43f-44d8-4a06-d88d-2f754cedf02e",
        "id": "nknHO9lFcje9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2022-06-19 10:29:32--  https://docs.google.com/uc?export=download&id=1vQbu1XmenVtNYSvqZmiwAo2jzFWZCsI8\n",
            "Resolving docs.google.com (docs.google.com)... 142.250.145.100, 142.250.145.113, 142.250.145.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.145.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-14-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/m5l4qnga2dbhge4tqr3ur3008j0fu73p/1655634525000/17304979608001708681/*/1vQbu1XmenVtNYSvqZmiwAo2jzFWZCsI8?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-06-19 10:29:33--  https://doc-14-b0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/m5l4qnga2dbhge4tqr3ur3008j0fu73p/1655634525000/17304979608001708681/*/1vQbu1XmenVtNYSvqZmiwAo2jzFWZCsI8?e=download\n",
            "Resolving doc-14-b0-docs.googleusercontent.com (doc-14-b0-docs.googleusercontent.com)... 172.217.218.132, 2a00:1450:4013:c08::84\n",
            "Connecting to doc-14-b0-docs.googleusercontent.com (doc-14-b0-docs.googleusercontent.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1428382 (1.4M) [text/csv]\n",
            "Saving to: ‘medium_data.csv’\n",
            "\n",
            "medium_data.csv     100%[===================>]   1.36M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-06-19 10:29:34 (134 MB/s) - ‘medium_data.csv’ saved [1428382/1428382]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#medium_data = pd.read_csv('../input/medium-articles-dataset/medium_data.csv') # Kaggle\n",
        "medium_data = pd.read_csv('medium_data.csv') # Colab\n",
        "medium_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T14:50:49.294905Z",
          "iopub.execute_input": "2022-05-31T14:50:49.295657Z",
          "iopub.status.idle": "2022-05-31T14:50:49.349944Z",
          "shell.execute_reply.started": "2022-05-31T14:50:49.295603Z",
          "shell.execute_reply": "2022-05-31T14:50:49.348937Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "974083f9-110c-4eda-ab5c-38931ef04925",
        "id": "hiMaWbHtcje9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                                url  \\\n",
              "0   1  https://towardsdatascience.com/a-beginners-gui...   \n",
              "1   2  https://towardsdatascience.com/hands-on-graph-...   \n",
              "2   3  https://towardsdatascience.com/how-to-use-ggpl...   \n",
              "3   4  https://towardsdatascience.com/databricks-how-...   \n",
              "4   5  https://towardsdatascience.com/a-step-by-step-...   \n",
              "\n",
              "                                               title  \\\n",
              "0  A Beginner’s Guide to Word Embedding with Gens...   \n",
              "1  Hands-on Graph Neural Networks with PyTorch & ...   \n",
              "2                       How to Use ggplot2 in Python   \n",
              "3  Databricks: How to Save Files in CSV on Your L...   \n",
              "4  A Step-by-Step Implementation of Gradient Desc...   \n",
              "\n",
              "                                  subtitle   image  claps responses  \\\n",
              "0                                      NaN   1.png    850         8   \n",
              "1                                      NaN   2.png   1100        11   \n",
              "2         A Grammar of Graphics for Python   3.png    767         1   \n",
              "3  When I work on Python projects dealing…  4.jpeg    354         0   \n",
              "4          One example of building neural…  5.jpeg    211         3   \n",
              "\n",
              "   reading_time           publication        date  \n",
              "0             8  Towards Data Science  2019-05-30  \n",
              "1             9  Towards Data Science  2019-05-30  \n",
              "2             5  Towards Data Science  2019-05-30  \n",
              "3             4  Towards Data Science  2019-05-30  \n",
              "4             4  Towards Data Science  2019-05-30  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1de736b-a82a-4edf-a7ae-bde6915f06cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>subtitle</th>\n",
              "      <th>image</th>\n",
              "      <th>claps</th>\n",
              "      <th>responses</th>\n",
              "      <th>reading_time</th>\n",
              "      <th>publication</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>https://towardsdatascience.com/a-beginners-gui...</td>\n",
              "      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.png</td>\n",
              "      <td>850</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>https://towardsdatascience.com/hands-on-graph-...</td>\n",
              "      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.png</td>\n",
              "      <td>1100</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>https://towardsdatascience.com/how-to-use-ggpl...</td>\n",
              "      <td>How to Use ggplot2 in Python</td>\n",
              "      <td>A Grammar of Graphics for Python</td>\n",
              "      <td>3.png</td>\n",
              "      <td>767</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>https://towardsdatascience.com/databricks-how-...</td>\n",
              "      <td>Databricks: How to Save Files in CSV on Your L...</td>\n",
              "      <td>When I work on Python projects dealing…</td>\n",
              "      <td>4.jpeg</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>https://towardsdatascience.com/a-step-by-step-...</td>\n",
              "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
              "      <td>One example of building neural…</td>\n",
              "      <td>5.jpeg</td>\n",
              "      <td>211</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1de736b-a82a-4edf-a7ae-bde6915f06cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1de736b-a82a-4edf-a7ae-bde6915f06cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1de736b-a82a-4edf-a7ae-bde6915f06cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"remv\"></a>\n",
        "#### Preprocess Data\n",
        "Removing unwanted characters and words in titles\n",
        "\n",
        "Looking at titles, we can see there are some of unwanted characters and words in it which can not be useful for us to predict infact it might decrease our model accuracy so we have to remove it."
      ],
      "metadata": {
        "id": "hsLwGzlRcje-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocess(line):\n",
        "    # line: string\n",
        "    preprocess_line = line.lower()\n",
        "    preprocess_line = preprocess_line.replace(u'\\xa0',u' ')\n",
        "    preprocess_line = preprocess_line.replace('\\u200a',' ')\n",
        "    preprocess_line = re.sub(\"[^A-Za-zА-Яа-я0-9\\'\\s]\",'',preprocess_line)\n",
        "    return preprocess_line\n",
        "text_preprocess(\"Hands-on Graph Neural 'Network's with PyTorch & .\")    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "094e5383-a52a-4fa9-c6f4-d3ad4883e57d",
        "id": "QLgd7Qv5cje-"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"handson graph neural 'network's with pytorch  \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medium_data['title'] = medium_data['title'].apply(lambda x: text_preprocess(x))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-31T14:51:04.377174Z",
          "iopub.execute_input": "2022-05-31T14:51:04.377769Z",
          "iopub.status.idle": "2022-05-31T14:51:04.38892Z",
          "shell.execute_reply.started": "2022-05-31T14:51:04.377717Z",
          "shell.execute_reply": "2022-05-31T14:51:04.387839Z"
        },
        "trusted": true,
        "id": "RAPeUsUmcje-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medium_data['title'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc33089-8909-4649-c924-86cf16ac6f08",
        "id": "bGCnQUIWcje-"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    a beginners guide to word embedding with gensi...\n",
              "1    handson graph neural networks with pytorch  py...\n",
              "2                         how to use ggplot2 in python\n",
              "3    databricks how to save files in csv on your lo...\n",
              "4    a stepbystep implementation of gradient descen...\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medium_data['title'].to_csv('medium_data.txt', index=False, header=None )"
      ],
      "metadata": {
        "id": "hetGQJHvcje-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"token\"></a>\n",
        "#### Tokenezation\n",
        "\n",
        "Tokenzaion is the process in which we provide an unique id to all the words and make a word index or we can say vocabulary."
      ],
      "metadata": {
        "id": "SjqpqOxucje_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### --model_type=unigram - not use"
      ],
      "metadata": {
        "id": "XtIB4vdfcje_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# by example https://colab.research.google.com/github/google/sentencepiece/blob/master/python/sentencepiece_python_module_example.ipynb#scrollTo=ee9W6wGnVteW\n",
        "# by End-to-End ASR SpeechBrain\n",
        "#sp.load(\"/content/speechbrain/templates/speech_recognition/Tokenizer/save/1000_unigram.model\")\n",
        "\n",
        "#import torch\n",
        "import sentencepiece as spm\n",
        "sp = spm.SentencePieceProcessor()\n"
      ],
      "metadata": {
        "id": "yGa3ALtAcje_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spm.SentencePieceTrainer.train('--input=botchan.txt --vocab_size=2000 --model_prefix=m --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]')\n",
        "#spm.SentencePieceTrainer.train('--input=medium_data.txt --vocab_size=9000 --model_prefix=m --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]')\n",
        "#spm.SentencePieceTrainer.train('--input=medium_data.txt --vocab_size=7000 --model_prefix=tokenizer --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]')\n",
        "#RuntimeError: Internal: src/trainer_interface.cc(590) [(trainer_spec_.vocab_size()) == (model_proto->pieces_size())] Vocabulary size too high (7000). Please set it to a value <= 6310.\n",
        "#spm.SentencePieceTrainer.train('--model_type=unigram --input=medium_data.txt --vocab_size=6310 --model_prefix=tokenizer --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]')\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('tokenizer.model')\n",
        "\n",
        "# <unk>=0, <s>=1, </s>=2, <sep>=3, <cls>=4\n",
        "print('bos=', sp.bos_id())\n",
        "print('eos=', sp.eos_id())\n",
        "print('unk=', sp.unk_id())\n",
        "print('pad=', sp.pad_id())  # disabled by default\n",
        "\n",
        "for id in range(4):\n",
        "    print(sp.id_to_piece(id), sp.is_control(id))\n",
        "vocab_size = sp.vocab_size()\n",
        "print(f\"vocab_size={vocab_size}\")\n",
        "vocab = {sp.IdToPiece(i): i for i in range(sp.GetPieceSize())}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e8574f-8d32-4101-86fd-9c6b3a0e5ee4",
        "id": "aYXzbg13cje_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-8605e0e9fe78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#spm.SentencePieceTrainer.train('--input=medium_data.txt --vocab_size=7000 --model_prefix=tokenizer --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#RuntimeError: Internal: src/trainer_interface.cc(590) [(trainer_spec_.vocab_size()) == (model_proto->pieces_size())] Vocabulary size too high (7000). Please set it to a value <= 6310.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mspm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--model_type=unigram --input=medium_data.txt --vocab_size=6310 --model_prefix=tokenizer --pad_id=0 --unk_id=1 --bos_id=0 --eos_id=0 --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizer.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(arg, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m       \u001b[0;34m\"\"\"Train Sentencepiece model. Accept both kwargs and legacy string arg.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSentencePieceTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_TrainFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36m_TrainFromString\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_TrainFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_sentencepiece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceTrainer__TrainFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Internal: src/trainer_interface.cc(676) [insert_id(trainer_spec_.eos_id(), trainer_spec_.eos_piece())] "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp.id_to_piece(0), sp.id_to_piece(1), sp.id_to_piece(199), sp.id_to_piece(999), sp.decode_ids([999])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83d09d31-663b-4115-dccf-d83dd66e0aaa",
        "id": "q0hOv15McjfA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[PAD]', '[UNK]', '▁every', '▁source', 'source')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(vocab.items())[:20], list(vocab.items())[-20:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8e6ff6-39e9-4a51-ec63-2c6b6e3b21f1",
        "id": "wq6MRXaqcjfA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('[PAD]', 0),\n",
              "  ('[UNK]', 1),\n",
              "  ('[BOS]', 2),\n",
              "  ('[EOS]', 3),\n",
              "  ('▁the', 4),\n",
              "  ('▁to', 5),\n",
              "  ('▁a', 6),\n",
              "  ('s', 7),\n",
              "  ('▁', 8),\n",
              "  ('ing', 9),\n",
              "  ('▁of', 10),\n",
              "  ('strong', 11),\n",
              "  ('▁and', 12),\n",
              "  ('▁how', 13),\n",
              "  ('▁in', 14),\n",
              "  ('▁your', 15),\n",
              "  ('▁for', 16),\n",
              "  ('▁you', 17),\n",
              "  ('▁with', 18),\n",
              "  ('▁is', 19)],\n",
              " [('dm', 6290),\n",
              "  ('▁attracti', 6291),\n",
              "  ('ee', 6292),\n",
              "  ('same', 6293),\n",
              "  ('nager', 6294),\n",
              "  ('ios', 6295),\n",
              "  ('cious', 6296),\n",
              "  ('▁agen', 6297),\n",
              "  ('ishing', 6298),\n",
              "  ('strongho', 6299),\n",
              "  ('▁tu', 6300),\n",
              "  ('alg', 6301),\n",
              "  ('▁debi', 6302),\n",
              "  ('▁batt', 6303),\n",
              "  ('▁highe', 6304),\n",
              "  ('ark', 6305),\n",
              "  ('▁kn', 6306),\n",
              "  ('ru', 6307),\n",
              "  ('wo', 6308),\n",
              "  ('▁rai', 6309)])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### --model_type=word"
      ],
      "metadata": {
        "id": "iKpj1M5JcjfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "blank_index: 0\n",
        "bos_index: 1\n",
        "eos_index: 2\n",
        "unk_index: 0\n",
        "pad_index: 3\n",
        "```\n",
        "по идее blank_id= unk_id или pad_id\n",
        "\n",
        "Connectionist Temporal Classification (CTC)\n",
        "CTC is the simplest speech recognition system available in SpeechBrain.\n",
        "\n",
        "For each time step, it outputs a prediction. CTC adds a special token called **blank**. That allows the network to output nothing when not sure about what to emit. The CTC cost function uses dynamic programming to align over all the possible alignments."
      ],
      "metadata": {
        "id": "mmXKOxPwcjfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/github/google/sentencepiece/blob/master/python/sentencepiece_python_module_example.ipynb#scrollTo=2CLaMlHUh4Dk\n",
        "```\n",
        "By default, UNK/BOS/EOS/PAD tokens and their ids are defined as follows:\n",
        "\n",
        "|token|UNK|BOS|EOS|PAD| ---|--- |surface|<unk>|<s>|</s>|<pad>| |id|0|1|2|undefined (-1)|\n",
        "```"
      ],
      "metadata": {
        "id": "Ot38FOxYSJHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "import sentencepiece as spm\n",
        "\n",
        "#spm.SentencePieceTrainer.train('--model_type=word --input=medium_data.txt --model_prefix=tokenizer_8583_word\\\n",
        "spm.SentencePieceTrainer.train('--model_type=word --input=medium_data.txt --model_prefix=tokenizer_8581_word\\\n",
        " --vocab_size=8581 --pad_id=-1 --bos_id=-1 --eos_id=-1 ')# \\\n",
        " #--pad_piece=[PAD] --unk_piece=[UNK]') # --bos_piece=[BOS] --eos_piece=[EOS]')\n",
        "# RuntimeError: Please set it to a value <= 8583 ==> --vocab_size\n",
        "# #--control_symbols=<cls>\\\n",
        "# #--blank_id=4\n",
        "#--vocab_size=8583 --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 \\   # --bos_id=0 --eos_id=0 \\\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('tokenizer_8581_word.model')\n",
        "\n",
        "print('unk=', sp.unk_id(), sp.id_to_piece(sp.unk_id()))\n",
        "#sp.\n",
        "print('bos=', sp.bos_id()) #,sp.id_to_piece(sp.bos_id()))\n",
        "print('eos=', sp.eos_id()) #, sp.id_to_piece(sp.eos_id()) if sp.eos_id()!=2 else False)\n",
        "print('pad=', sp.pad_id()) #, sp.id_to_piece(sp.pad_id()))  # disabled by default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de41d269-3b61-4a65-cc6b-43634063ee62",
        "id": "E4IJJjFmcjfA"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "unk= 0 <unk>\n",
            "bos= -1\n",
            "eos= -1\n",
            "pad= -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = sp.vocab_size()\n",
        "print(f\"vocab_size={vocab_size}\")\n",
        "vocab = {sp.IdToPiece(i): i for i in range(sp.GetPieceSize())}\n",
        "print(list(vocab.items())[:10])\n",
        "print(list(vocab.items())[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dee4f4f-397c-47fc-d8cc-86954705d015",
        "id": "jWslameucjfA"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab_size=8581\n",
            "[('<unk>', 0), ('▁to', 1), ('▁the', 2), ('▁a', 3), ('▁of', 4), ('▁and', 5), ('▁how', 6), ('▁in', 7), ('▁your', 8), ('▁for', 9)]\n",
            "[('▁youtuber', 8571), ('▁ytb', 8572), ('▁zalando', 8573), ('▁zealand', 8574), ('▁zillow', 8575), ('▁zip', 8576), ('▁zipline', 8577), ('▁zmodule', 8578), ('▁zone', 8579), ('▁zscores', 8580)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test Tokenizer"
      ],
      "metadata": {
        "id": "xZGrTX0TcjfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode as pieces\n",
        "print(sp.encode_as_pieces('THE CITY OF MONTREAL'))\n",
        "print(sp.encode_as_ids('THE CITY OF MONTREAL'))\n",
        "\n",
        "print(medium_data['title'][0])\n",
        "# Encode as ids\n",
        "print(sp.encode_as_pieces(medium_data['title'][0]))\n",
        "print(sp.encode_as_ids(medium_data['title'][0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd424395-edd1-474a-f727-adc8f27edd46",
        "id": "4j4UEsUdcjfB"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁THE▁CITY▁OF▁MONTREAL']\n",
            "[0]\n",
            "a beginners guide to word embedding with gensim word2vec model\n",
            "['▁a', '▁beginners', '▁guide', '▁to', '▁word', '▁embedding', '▁with', '▁gensim', '▁word2vec', '▁model']\n",
            "[3, 268, 63, 1, 461, 1565, 11, 2863, 8512, 96]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sp.decode_ids([244, 177, 3, 1, 97]))\n",
        "print(sp.encode_as_pieces(\"beginer's guide\"))\n",
        "# Decode from pieces\n",
        "print(sp.decode_pieces(['▁THIS', '▁IS', '▁A', '▁T', 'EST']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1fe5429-ce21-4122-97c0-0c06e8db0e54",
        "id": "XR4_zUOQcjfB"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "go start a to top\n",
            "[\"▁beginer's\", '▁guide']\n",
            "▁THIS▁IS▁A▁TEST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data: train val, test"
      ],
      "metadata": {
        "id": "YkBSEyLAcjfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "lines = medium_data['title'].values\n",
        "train_texts, test_texts = train_test_split(lines, test_size=0.2, shuffle=True )\n",
        "valid_texts, test_texts = train_test_split(test_texts, test_size=0.5 )\n",
        "#train_texts, val_texts, test_texts"
      ],
      "metadata": {
        "id": "RdP3AA8dcjfB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save train, val, test texts"
      ],
      "metadata": {
        "id": "C66BHdDfcjfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/speechbrain/templates/speech_recognition/LM/data/\"\n",
        "def write_text_lines(lines, file_name):\n",
        "    with open(file_name,'w') as f:\n",
        "        for line in lines:\n",
        "            f.write(line + '\\n')\n",
        "write_text_lines(train_texts, data_folder + \"train_01.txt\")\n",
        "write_text_lines(valid_texts, data_folder + \"valid_01.txt\")\n",
        "write_text_lines(test_texts, data_folder + \"test_01.txt\")"
      ],
      "metadata": {
        "id": "cSpmljlkcjfC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKA-RLRpzgS_"
      },
      "source": [
        "## **Step 3: Train a Language Model**\n",
        "A Language Model (LM) can be used within a speech recognizer in different ways. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v1 original\n",
        " https://github.com/speechbrain/speechbrain/blob/develop/recipes/LibriSpeech/LM/"
      ],
      "metadata": {
        "id": "skJMzfqYqG21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RNNLM.yaml\n",
        "https://github.com/speechbrain/speechbrain/blob/develop/recipes/LibriSpeech/LM/hparams/RNNLM.yaml"
      ],
      "metadata": {
        "id": "ydbRPEAkqMFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/speechbrain/templates/speech_recognition/LM/RNNLM_01.yaml\n",
        "# ############################################################################\n",
        "# Model: RNNLM of E2E ASR\n",
        "# Tokens: unigram\n",
        "# losses: NLL\n",
        "# Training: Librispeech 960h transcript + LM corpus\n",
        "# Authors:  Ju-Chieh Chou 2020, Jianyuan Zhong 2021\n",
        "# ############################################################################\n",
        "\n",
        "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
        "vocab_size = 8581\n",
        "seed: 2223\n",
        "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
        "output_folder: !ref results/RNN/<seed>\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "\n",
        "# Data files\n",
        "# The data_folder is needed because we train the LM on the training\n",
        "# transcriptions of LibriSpeech as well.\n",
        "data_folder: !PLACEHOLDER # e.g, /localscratch/LibriSpeech\n",
        "\n",
        "# path to the lm_corpus\n",
        "# if set to null, it will automatically download from the internet\n",
        "# in the case when there is no internet access, set this to your local file\n",
        "lm_corpus_path: null\n",
        "\n",
        "# Tokenizer model\n",
        "tokenizer_file: https://www.dropbox.com/s/o7gnouwdoqchotj/1000_unigram.model?dl=1\n",
        "\n",
        "# Training parameters\n",
        "number_of_epochs: 20\n",
        "batch_size: 80\n",
        "lr: 0.001\n",
        "accu_steps: 1 # Gradient accumulation to simulate large batch training\n",
        "ckpt_interval_minutes: 15 # save checkpoint every N min\n",
        "\n",
        "# Dataloader options\n",
        "train_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "    shuffle: True\n",
        "\n",
        "valid_dataloader_opts:\n",
        "    batch_size: 1\n",
        "\n",
        "test_dataloader_opts:\n",
        "    batch_size: 1\n",
        "\n",
        "# Model parameters\n",
        "emb_size: 128\n",
        "activation: !name:torch.nn.LeakyReLU\n",
        "dropout: 0.0\n",
        "rnn_layers: 2\n",
        "rnn_neurons: 2048\n",
        "dnn_blocks: 1\n",
        "dnn_neurons: 512\n",
        "\n",
        "# Outputs\n",
        "output_neurons: 1000 # index(blank/eos/bos) = 0\n",
        "# blank_index: 0\n",
        "bos_index: 0\n",
        "eos_index: 0\n",
        "\n",
        "\n",
        "# Functions\n",
        "model: !new:speechbrain.lobes.models.RNNLM.RNNLM\n",
        "    output_neurons: !ref <output_neurons>\n",
        "    embedding_dim: !ref <emb_size>\n",
        "    activation: !ref <activation>\n",
        "    dropout: !ref <dropout>\n",
        "    rnn_layers: !ref <rnn_layers>\n",
        "    rnn_neurons: !ref <rnn_neurons>\n",
        "    dnn_blocks: !ref <dnn_blocks>\n",
        "    dnn_neurons: !ref <dnn_neurons>\n",
        "\n",
        "modules:\n",
        "    model: !ref <model>\n",
        "\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        model: !ref <model>\n",
        "        scheduler: !ref <lr_annealing>\n",
        "        counter: !ref <epoch_counter>\n",
        "\n",
        "log_softmax: !new:speechbrain.nnet.activations.Softmax\n",
        "    apply_log: True\n",
        "\n",
        "optimizer: !name:torch.optim.Adam\n",
        "    lr: !ref <lr>\n",
        "    betas: (0.9, 0.98)\n",
        "    eps: 0.000000001\n",
        "\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.NewBobScheduler\n",
        "    initial_value: !ref <lr>\n",
        "    improvement_threshold: 0.0025\n",
        "    annealing_factor: 0.8\n",
        "    patient: 0\n",
        "\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <number_of_epochs>\n",
        "\n",
        "compute_cost: !name:speechbrain.nnet.losses.nll_loss\n",
        "\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "tokenizer: !new:sentencepiece.SentencePieceProcessor\n",
        "\n",
        "pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
        "    collect_in: !ref <save_folder>\n",
        "    loadables:\n",
        "        tokenizer: !ref <tokenizer>\n",
        "    paths:\n",
        "        tokenizer: !ref <tokenizer_file>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWBmNA95qMgP",
        "outputId": "cd6e2f48-e6a6-4e1f-cff2-96fbd704c2d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/speechbrain/templates/speech_recognition/LM/RNNLM_01.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LM/train_01.py\n"
      ],
      "metadata": {
        "id": "FrmKmiHPq6Qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/speechbrain/templates/speech_recognition/LM/train_01.py\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"Recipe for training a Language Model with librispeech train-960 transcript and lm_corpus.\n",
        "To run this recipe, do the following:\n",
        "> pip install datasets\n",
        "> python train.py hparams/<hparam_file>.yaml --data_folder <local_path_to_librispeech_dataset>\n",
        "Authors\n",
        " * Jianyuan Zhong 2021\n",
        " * Ju-Chieh Chou 2020\n",
        "\"\"\"\n",
        "import os\n",
        "import sys\n",
        "import logging\n",
        "import glob\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "import speechbrain as sb\n",
        "from speechbrain.utils.distributed import run_on_main\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# Define training procedure\n",
        "class LM(sb.core.Brain):\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Forward computations from the sentence batches to the output probabilities.\"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        tokens_bos, _ = batch.tokens_bos\n",
        "        logits = self.hparams.model(tokens_bos)\n",
        "        pred = self.hparams.log_softmax(logits)\n",
        "        return pred\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the loss given predictions and targets.\"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        tokens_eos, tokens_len = batch.tokens_eos\n",
        "        loss = self.hparams.compute_cost(\n",
        "            predictions, tokens_eos, length=tokens_len\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "    def fit_batch(self, batch):\n",
        "        \"\"\"Train the parameters given a single batch in input\"\"\"\n",
        "        predictions = self.compute_forward(batch, sb.Stage.TRAIN)\n",
        "        loss = self.compute_objectives(predictions, batch, sb.Stage.TRAIN)\n",
        "\n",
        "        (loss / self.hparams.accu_steps).backward()\n",
        "\n",
        "        if self.step % self.hparams.accu_steps == 0:\n",
        "            # gradient clipping & early stop if loss is not fini\n",
        "            self.check_gradients(loss)\n",
        "\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            if isinstance(\n",
        "                self.hparams.lr_annealing, sb.nnet.schedulers.NoamScheduler\n",
        "            ) or isinstance(\n",
        "                self.hparams.lr_annealing,\n",
        "                sb.nnet.schedulers.CyclicCosineScheduler,\n",
        "            ):\n",
        "                self.hparams.lr_annealing(self.optimizer)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
        "        stage_stats = {\"loss\": stage_loss}\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_stats = stage_stats\n",
        "\n",
        "        if stage == sb.Stage.VALID and sb.utils.distributed.if_main_process():\n",
        "            if not (\n",
        "                isinstance(\n",
        "                    self.hparams.lr_annealing, sb.nnet.schedulers.NoamScheduler\n",
        "                )\n",
        "                or isinstance(\n",
        "                    self.hparams.lr_annealing,\n",
        "                    sb.nnet.schedulers.CyclicCosineScheduler,\n",
        "                )\n",
        "            ):\n",
        "                old_lr, new_lr = self.hparams.lr_annealing(stage_loss)\n",
        "                sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
        "            else:\n",
        "                old_lr = self.hparams.lr_annealing.current_lr\n",
        "\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"epoch\": epoch, \"lr\": old_lr},\n",
        "                train_stats=self.train_stats,\n",
        "                valid_stats=stage_stats,\n",
        "            )\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta=stage_stats, min_keys=[\"loss\"],\n",
        "            )\n",
        "\n",
        "\n",
        "def dataio_prepare(hparams):\n",
        "    \"\"\"grap all the .txt files for transcripts\"\"\"\n",
        "    logging.info(\"generating datasets...\")\n",
        "    data_folder = hparams[\"data_folder\"]\n",
        "    train_transcripts = glob.glob(\n",
        "        os.path.join(data_folder, \"train*/**/*.trans.txt\"), recursive=True\n",
        "    )\n",
        "    dev_transcripts = glob.glob(\n",
        "        os.path.join(data_folder, \"dev*/**/*.trans.txt\"), recursive=True\n",
        "    )\n",
        "    test_transcripts = glob.glob(\n",
        "        os.path.join(data_folder, \"test*/**/*.trans.txt\"), recursive=True\n",
        "    )\n",
        "\n",
        "    \"\"\"prepare data and generate datasets\"\"\"\n",
        "    datasets = load_dataset(\n",
        "        \"dataset.py\",\n",
        "        lm_corpus_path=hparams[\"lm_corpus_path\"],\n",
        "        data_files={\n",
        "            \"train\": train_transcripts,\n",
        "            \"dev\": dev_transcripts,\n",
        "            \"test\": test_transcripts,\n",
        "        },\n",
        "    )\n",
        "\n",
        "    train_data, valid_data, test_data = (\n",
        "        datasets[\"train\"],\n",
        "        datasets[\"dev\"],\n",
        "        datasets[\"test\"],\n",
        "    )\n",
        "\n",
        "    \"\"\"convert huggingface's dataset to DynamicItemDataset via a magical function\"\"\"\n",
        "    train_data = sb.dataio.dataset.DynamicItemDataset.from_arrow_dataset(\n",
        "        train_data\n",
        "    )\n",
        "    valid_data = sb.dataio.dataset.DynamicItemDataset.from_arrow_dataset(\n",
        "        valid_data\n",
        "    )\n",
        "    test_data = sb.dataio.dataset.DynamicItemDataset.from_arrow_dataset(\n",
        "        test_data\n",
        "    )\n",
        "\n",
        "    datasets = [train_data, valid_data, test_data]\n",
        "\n",
        "    tokenizer = hparams[\"tokenizer\"]\n",
        "\n",
        "    \"\"\"Define text pipeline\"\"\"\n",
        "    # TODO: implement text augmentations pipelines\n",
        "    @sb.utils.data_pipeline.takes(\"text\")\n",
        "    @sb.utils.data_pipeline.provides(\"text\", \"tokens_bos\", \"tokens_eos\")\n",
        "    def text_pipeline(text):\n",
        "        yield text\n",
        "        tokens_list = tokenizer.encode_as_ids(text)\n",
        "        tokens_bos = torch.LongTensor([hparams[\"bos_index\"]] + (tokens_list))\n",
        "        yield tokens_bos\n",
        "        tokens_eos = torch.LongTensor(tokens_list + [hparams[\"eos_index\"]])\n",
        "        yield tokens_eos\n",
        "\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, text_pipeline)\n",
        "\n",
        "    # 4. Set output:\n",
        "    sb.dataio.dataset.set_output_keys(\n",
        "        datasets, [\"id\", \"text\", \"tokens_bos\", \"tokens_eos\"],\n",
        "    )\n",
        "    return train_data, valid_data, test_data\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # CLI:\n",
        "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
        "    with open(hparams_file) as fin:\n",
        "        hparams = load_hyperpyyaml(fin, overrides)\n",
        "\n",
        "    # If distributed_launch=True then\n",
        "    # create ddp_group with the right communication protocol\n",
        "    sb.utils.distributed.ddp_init_group(run_opts)\n",
        "\n",
        "    # Create experiment directory\n",
        "    sb.create_experiment_directory(\n",
        "        experiment_directory=hparams[\"output_folder\"],\n",
        "        hyperparams_to_save=hparams_file,\n",
        "        overrides=overrides,\n",
        "    )\n",
        "\n",
        "    # here we create the dataloader objects as well as tokenization and encoding\n",
        "    train_data, valid_data, test_data = dataio_prepare(hparams)\n",
        "\n",
        "    # We download the tokenizer from HuggingFace (or elsewhere depending on\n",
        "    # the path given in the YAML file).\n",
        "    run_on_main(hparams[\"pretrainer\"].collect_files)\n",
        "    hparams[\"pretrainer\"].load_collected(device=run_opts[\"device\"])\n",
        "\n",
        "    lm_brain = LM(\n",
        "        modules=hparams[\"modules\"],\n",
        "        opt_class=hparams[\"optimizer\"],\n",
        "        hparams=hparams,\n",
        "        run_opts=run_opts,\n",
        "        checkpointer=hparams[\"checkpointer\"],\n",
        "    )\n",
        "\n",
        "    lm_brain.fit(\n",
        "        lm_brain.hparams.epoch_counter,\n",
        "        train_data,\n",
        "        valid_data,\n",
        "        train_loader_kwargs=hparams[\"train_dataloader_opts\"],\n",
        "        valid_loader_kwargs=hparams[\"valid_dataloader_opts\"],\n",
        "    )\n",
        "\n",
        "    # evaluation\n",
        "    test_stats = lm_brain.evaluate(\n",
        "        test_data,\n",
        "        min_key=\"loss\",\n",
        "        test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
        "    )"
      ],
      "metadata": {
        "id": "hE4CzwhnrB46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7fc0757-0444-45f3-899a-bbbab9749cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/speechbrain/templates/speech_recognition/LM/train_01.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v2 modeified files"
      ],
      "metadata": {
        "id": "2E6KbR-Jqi2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RNNLM_02.yaml"
      ],
      "metadata": {
        "id": "ypXHh9R8cCyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/speechbrain/templates/speech_recognition/LM/RNNLM_02.yaml\n",
        "# ############################################################################\n",
        "# Training: RuDataset transcripts\n",
        "# by original:\n",
        "# Model: Language model with a recurrent neural network (RNNLM)\n",
        "# Training: mini-librispeech transcripts\n",
        "# Authors:  Ju-Chieh Chou 2020, Jianyuan Zhong 2021, Mirco Ravanelli 2021\n",
        "# ############################################################################\n",
        "\n",
        "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
        "seed: 2602\n",
        "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
        "output_folder: !ref results/RNNLM/\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "\n",
        "vocab_size: 8581\n",
        "\n",
        "# If you plan to train a system on an HPC cluster with a big dataset,\n",
        "# we strongly suggest doing the following:\n",
        "# 1- Compress the dataset in a single tar or zip file.\n",
        "# 2- Copy your dataset locally (i.e., the local disk of the computing node).\n",
        "# 3- Uncompress the dataset in the local folder.\n",
        "# 4- Set lm_{train,valid,test}_data with the local path.\n",
        "# Reading data from the local disk of the compute node (e.g. $SLURM_TMPDIR with SLURM-based clusters) is very important.\n",
        "# It allows you to read the data much faster without slowing down the shared filesystem.\n",
        "lm_train_data: data/train_01.txt\n",
        "lm_valid_data: data/valid_01.txt\n",
        "lm_test_data: data/test_01.txt\n",
        "\n",
        "# The train logger writes training statistics to a file, as well as stdout.\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "\n",
        "# Training parameters\n",
        "number_of_epochs: 20\n",
        "batch_size: 80\n",
        "lr: 0.001\n",
        "accu_steps: 1 # Gradient accumulation to simulate large batch training\n",
        "ckpt_interval_minutes: 15 # save checkpoint every N min\n",
        "\n",
        "# Dataloader options\n",
        "train_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "    shuffle: True\n",
        "\n",
        "valid_dataloader_opts:\n",
        "    batch_size: 1\n",
        "\n",
        "test_dataloader_opts:\n",
        "    batch_size: 1\n",
        "\n",
        "# Model parameters\n",
        "#emb_dim: 256 # dimension of the embeddings - дальше в ASR модели используется 128\n",
        "emb_dim: 128 # dimension of the embeddings\n",
        "rnn_size: 256 #512 # dimension of hidden layers\n",
        "layers: 2 # number of hidden layers\n",
        "\n",
        "# Outputs\n",
        "#output_neurons: 1000 # index(blank/eos/bos) = 0\n",
        "output_neurons: !ref <vocab_size>\n",
        "\n",
        "blank_index: 0\n",
        "unk_index: 1\n",
        "bos_index: 0 #2\n",
        "eos_index: 0 #3\n",
        "pad_index: 0\n",
        "\n",
        "\n",
        "# To design a custom model, either just edit the simple CustomModel\n",
        "# class that's listed here, or replace this `!new` call with a line\n",
        "# pointing to a different file you've defined..\n",
        "#model: !new:templates.speech_recognition.LM.custom_model.CustomModel # error not found custom_model.py\n",
        "#model: !new:custom_model.CustomModel_01\n",
        "    #embedding_dim: !ref <emb_dim>\n",
        "    #rnn_size: !ref <rnn_size>\n",
        "    #layers: !ref <layers>\n",
        "\n",
        "# from transformerLM\n",
        "#speechbrain.nnet.activations.GumbelSoftmax(tau, hard=False, apply_log=False)\n",
        "log_softmax: !new:speechbrain.nnet.activations.Softmax\n",
        "    apply_log: True\n",
        "# Model parameters\n",
        "emb_size: 128\n",
        "activation: !name:torch.nn.LeakyReLU\n",
        "dropout: 0.0\n",
        "rnn_layers: 2\n",
        "rnn_neurons: 512 #2048\n",
        "dnn_blocks: 1\n",
        "dnn_neurons: 512\n",
        "\n",
        "# Functions\n",
        "model: !new:speechbrain.lobes.models.RNNLM.RNNLM\n",
        "    output_neurons: !ref <output_neurons>\n",
        "    embedding_dim: !ref  <emb_size>\n",
        "    activation: !ref <activation>\n",
        "    dropout: !ref <dropout>\n",
        "    rnn_layers: !ref <rnn_layers>\n",
        "    rnn_neurons: !ref <rnn_neurons>\n",
        "    dnn_blocks: !ref <dnn_blocks>\n",
        "    dnn_neurons: !ref <dnn_neurons>\n",
        "\n",
        "#modules:\n",
        "#    model: !ref <model>\n",
        "\n",
        "# Cost function used for training the model\n",
        "compute_cost: !name:speechbrain.nnet.losses.nll_loss\n",
        "\n",
        "# This optimizer will be constructed by the Brain class after all parameters\n",
        "# are moved to the correct device. Then it will be added to the checkpointer.\n",
        "optimizer: !name:torch.optim.Adam\n",
        "    lr: !ref <lr>\n",
        "    betas: (0.9, 0.98)\n",
        "    eps: 0.000000001\n",
        "\n",
        "# This function manages learning rate annealing over the epochs.\n",
        "# We here use the NewBoB algorithm, that anneals the learning rate if\n",
        "# the improvements over two consecutive epochs is less than the defined\n",
        "# threshold.\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.NewBobScheduler\n",
        "    initial_value: !ref <lr>\n",
        "    improvement_threshold: 0.0025\n",
        "    annealing_factor: 0.8\n",
        "    patient: 0\n",
        "\n",
        "\n",
        "# The first object passed to the Brain class is this \"Epoch Counter\"\n",
        "# which is saved by the Checkpointer so that training can be resumed\n",
        "# if it gets interrupted at any point.\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <number_of_epochs>\n",
        "\n",
        "# Objects in \"modules\" dict will have their parameters moved to the correct\n",
        "# device, as well as having train()/eval() called on them by the Brain class.\n",
        "modules:\n",
        "    model: !ref <model>\n",
        "\n",
        "# Tokenizer initialization\n",
        "tokenizer: !new:sentencepiece.SentencePieceProcessor\n",
        "\n",
        "# Tokenizer model (you must use the same tokenizer for LM and ASR training)\n",
        "#tokenizer_file: ../Tokenizer/save/1000_unigram.model\n",
        "tokenizer_file: !ref /content/tokenizer_<vocab_size>_word.model\n",
        "\n",
        "# This object is used for saving the state of training both so that it\n",
        "# can be resumed if it gets interrupted, and also so that the best checkpoint\n",
        "# can be later loaded for evaluation or inference.\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        model: !ref <model>\n",
        "        scheduler: !ref <lr_annealing>\n",
        "        counter: !ref <epoch_counter>\n",
        "\n",
        "# Pretrain the tokenizer\n",
        "pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
        "    loadables:\n",
        "        tokenizer: !ref <tokenizer>\n",
        "    paths:\n",
        "        tokenizer: !ref <tokenizer_file>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJpFD1FoYcPA",
        "outputId": "6352db82-1055-4275-b35e-ff2cc0b1f35b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/speechbrain/templates/speech_recognition/LM/RNNLM_02.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### custom_model_01.py - not use"
      ],
      "metadata": {
        "id": "_n83Q3J-tN-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/speechbrain/templates/speech_recognition/LM/custom_model_01.py\n",
        "\"\"\"\n",
        "This file contains a very simple PyTorch module to use for language modeling.\n",
        "\n",
        "To replace this model, change the `!new:` tag in the hyperparameter file\n",
        "to refer to a built-in SpeechBrain model or another file containing\n",
        "a custom PyTorch module. Instead of this simple model, we suggest using one\n",
        "of the following built-in neural models:\n",
        "\n",
        "RNN-LM: speechbrain.lobes.models.RNNLM.RNNLM\n",
        "transformer: speechbrain.lobes.models.transformers.TransformerLM.TransformerLM\n",
        "\n",
        "Authors\n",
        " * Mirco Ravanelli 2021\n",
        "\n",
        "\"\"\"\n",
        "import torch\n",
        "import speechbrain as sb\n",
        "\n",
        "\n",
        "class CustomModel(torch.nn.Module):\n",
        "    \"\"\"Basic LSTM model for language modeling.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    embedding_dim : int\n",
        "        The dimension of the embeddings.The input indexes are transformed into\n",
        "        a latent space with this dimensionality.\n",
        "    rnn_size : int\n",
        "        Number of neurons to use in rnn (for each direction -> and <-).\n",
        "    layers : int\n",
        "        Number of RNN layers to use.\n",
        "    output_dim : int\n",
        "        Dimensionality of the output.\n",
        "    return_hidden : bool\n",
        "        If True, returns the hidden state of the RNN as well.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dim=128,\n",
        "        rnn_size=256,\n",
        "        layers=2,\n",
        "        output_dim=8583 #1000,\n",
        "        return_hidden=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.return_hidden = return_hidden\n",
        "        self.reshape = False\n",
        "\n",
        "        # Embedding model\n",
        "        self.embedding = sb.nnet.embedding.Embedding(\n",
        "            num_embeddings=output_dim, embedding_dim=embedding_dim\n",
        "        )\n",
        "\n",
        "        # LSTM\n",
        "        self.rnn = torch.nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=rnn_size,\n",
        "            bidirectional=False,\n",
        "            num_layers=layers,\n",
        "        )\n",
        "\n",
        "        # Final output transformation + softmax\n",
        "        self.out = sb.nnet.linear.Linear(\n",
        "            input_size=rnn_size, n_neurons=output_dim\n",
        "        )\n",
        "        self.log_softmax = sb.nnet.activations.Softmax(apply_log=True)\n",
        "\n",
        "    def forward(self, x, hx=None):\n",
        "        \"\"\"List of computations from input to output predictions\"\"\"\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # If 2d tensor, add a time-axis\n",
        "        # This is used for inference time (during beamforming)\n",
        "        if len(x.shape) == 2:\n",
        "            x = x.unsqueeze(dim=1)\n",
        "            self.reshape = True\n",
        "\n",
        "        x = x.transpose(0, 1)\n",
        "        x, hidden = self.rnn(x, hx)\n",
        "        x = x.transpose(0, 1)\n",
        "        x = self.out(x)\n",
        "        x = self.log_softmax(x)\n",
        "\n",
        "        if self.reshape:\n",
        "            x = x.squeeze(dim=1)\n",
        "\n",
        "        if self.return_hidden:\n",
        "            return x, hidden\n",
        "        else:\n",
        "            return x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr_ojKO1tTCd",
        "outputId": "4b7f2ca8-8d9a-4991-8ebe-e7edec6039dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/speechbrain/templates/speech_recognition/LM/custom_model_01.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LM/train_02.py"
      ],
      "metadata": {
        "id": "x6uDqb-2cHR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/speechbrain/templates/speech_recognition/LM/train_02.py\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "\n",
        "by original:\n",
        "Recipe for training a language model with a given text corpus.\n",
        "\n",
        "> python train.py RNNLM.yaml\n",
        "\n",
        "To run this recipe, you need to first install the Huggingface dataset:\n",
        "> pip install datasets\n",
        "\n",
        "\n",
        "Authors\n",
        " * Ju-Chieh Chou 2020\n",
        " * Jianyuan Zhong 2021\n",
        " * Mirco Ravanelli 2021\n",
        "\"\"\"\n",
        "import sys\n",
        "import logging\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "import speechbrain as sb\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# Brain class for language model training\n",
        "class LM(sb.core.Brain):\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Predicts the next word given the previous ones.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        batch : PaddedBatch\n",
        "            This batch object contains all the relevant tensors for computation.\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        predictions : torch.Tensor\n",
        "            A tensor containing the posterior probabilities (predictions).\n",
        "        \"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        #print(batch)\n",
        "        #tokens_bos, _ = batch.tokens_bos\n",
        "        tokens_bos, _ = batch[\"tokens_bos\"]\n",
        "        pred = self.hparams.model(tokens_bos)\n",
        "        return pred\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the loss given the predicted and targeted outputs.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        predictions : torch.Tensor\n",
        "            The posterior probabilities from `compute_forward`.\n",
        "        batch : PaddedBatch\n",
        "            This batch object contains all the relevant tensors for computation.\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : torch.Tensor\n",
        "            A one-element tensor used for backpropagating the gradient.\n",
        "        \"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        tokens_eos, tokens_len = batch.tokens_eos\n",
        "        loss = self.hparams.compute_cost(\n",
        "            predictions, tokens_eos, length=tokens_len\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "    def fit_batch(self, batch):\n",
        "        \"\"\"Runs all the steps needed to train the model on a single batch.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        batch : PaddedBatch\n",
        "            This batch object contains all the relevant tensors for computation.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Loss : torch.Tensor\n",
        "            A tensor containing the loss (single real number).\n",
        "        \"\"\"\n",
        "        print(\"batch\", batch)\n",
        "        predictions = self.compute_forward(batch, sb.Stage.TRAIN)\n",
        "        loss = self.compute_objectives(predictions, batch, sb.Stage.TRAIN)\n",
        "\n",
        "        # Loss backpropagation (gradient computation)\n",
        "        (loss / self.hparams.accu_steps).backward()\n",
        "\n",
        "        # Manage gradient accumulation\n",
        "        if self.step % self.hparams.accu_steps == 0:\n",
        "\n",
        "            # Gradient clipping & early stop if loss is not fini\n",
        "            self.check_gradients(loss)\n",
        "\n",
        "            # Update the parameters\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # Reset the gradient\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            if isinstance(\n",
        "                self.hparams.lr_annealing, sb.nnet.schedulers.NoamScheduler\n",
        "            ) or isinstance(\n",
        "                self.hparams.lr_annealing,\n",
        "                sb.nnet.schedulers.CyclicCosineScheduler,\n",
        "            ):\n",
        "                self.hparams.lr_annealing(self.optimizer)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of an epoch.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, sb.Stage.TEST\n",
        "        stage_loss : float\n",
        "            The average loss for all of the data processed in this stage.\n",
        "        epoch : int\n",
        "            The currently-starting epoch. This is passed\n",
        "            `None` during the test stage.\n",
        "        \"\"\"\n",
        "\n",
        "        # Store the train loss until the validation stage.\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_loss = stage_loss\n",
        "\n",
        "        # Summarize the statistics from the stage for record-keeping.\n",
        "        else:\n",
        "            stats = {\n",
        "                \"loss\": stage_loss,\n",
        "            }\n",
        "\n",
        "        # At the end of validation, we can wrote\n",
        "        if stage == sb.Stage.VALID:\n",
        "\n",
        "            # Update learning rate\n",
        "            old_lr, new_lr = self.hparams.lr_annealing(stage_loss)\n",
        "            sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
        "\n",
        "            # The train_logger writes a summary to stdout and to the logfile.\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                {\"Epoch\": epoch},\n",
        "                train_stats={\"loss\": self.train_loss},\n",
        "                valid_stats=stats,\n",
        "            )\n",
        "\n",
        "            # Save the current checkpoint and delete previous checkpoints.\n",
        "            self.checkpointer.save_and_keep_only(meta=stats, min_keys=[\"loss\"])\n",
        "\n",
        "        # We also write statistics about test data to stdout and to the logfile.\n",
        "        if stage == sb.Stage.TEST:\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                {\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
        "                test_stats=stats,\n",
        "            )\n",
        "\n",
        "class LM_origin(sb.core.Brain):\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Forward computations from the sentence batches to the output probabilities.\"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        tokens_bos, _ = batch.tokens_bos\n",
        "        logits = self.hparams.model(tokens_bos)\n",
        "        pred = self.hparams.log_softmax(logits)\n",
        "        return pred\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the loss given predictions and targets.\"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        tokens_eos, tokens_len = batch.tokens_eos\n",
        "        loss = self.hparams.compute_cost(\n",
        "            predictions, tokens_eos, length=tokens_len\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "    def fit_batch(self, batch):\n",
        "        \"\"\"Train the parameters given a single batch in input\"\"\"\n",
        "        predictions = self.compute_forward(batch, sb.Stage.TRAIN)\n",
        "        loss = self.compute_objectives(predictions, batch, sb.Stage.TRAIN)\n",
        "\n",
        "        (loss / self.hparams.accu_steps).backward()\n",
        "\n",
        "        if self.step % self.hparams.accu_steps == 0:\n",
        "            # gradient clipping & early stop if loss is not fini\n",
        "            self.check_gradients(loss)\n",
        "\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            if isinstance(\n",
        "                self.hparams.lr_annealing, sb.nnet.schedulers.NoamScheduler\n",
        "            ) or isinstance(\n",
        "                self.hparams.lr_annealing,\n",
        "                sb.nnet.schedulers.CyclicCosineScheduler,\n",
        "            ):\n",
        "                self.hparams.lr_annealing(self.optimizer)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
        "        stage_stats = {\"loss\": stage_loss}\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_stats = stage_stats\n",
        "\n",
        "        if stage == sb.Stage.VALID and sb.utils.distributed.if_main_process():\n",
        "            if not (\n",
        "                isinstance(\n",
        "                    self.hparams.lr_annealing, sb.nnet.schedulers.NoamScheduler\n",
        "                )\n",
        "                or isinstance(\n",
        "                    self.hparams.lr_annealing,\n",
        "                    sb.nnet.schedulers.CyclicCosineScheduler,\n",
        "                )\n",
        "            ):\n",
        "                old_lr, new_lr = self.hparams.lr_annealing(stage_loss)\n",
        "                sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
        "            else:\n",
        "                old_lr = self.hparams.lr_annealing.current_lr\n",
        "\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"epoch\": epoch, \"lr\": old_lr},\n",
        "                train_stats=self.train_stats,\n",
        "                valid_stats=stage_stats,\n",
        "            )\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta=stage_stats, min_keys=[\"loss\"],\n",
        "            )\n",
        "\n",
        "\n",
        "def dataio_prepare(hparams):\n",
        "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
        "    It also defines the data processing pipeline through user-defined functions.\n",
        "\n",
        "    The language model is trained with the text files specified by the user in\n",
        "    the hyperparameter file.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    hparams : dict\n",
        "        This dictionary is loaded from the `train.yaml` file, and it includes\n",
        "        all the hyperparameters needed for dataset construction and loading.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    datasets : list\n",
        "        List containing \"train\", \"valid\", and \"test\" sets that correspond\n",
        "        to the appropriate DynamicItemDataset object.\n",
        "    \"\"\"\n",
        "\n",
        "    logging.info(\"generating datasets...\")\n",
        "\n",
        "    # Prepare datasets\n",
        "    datasets = load_dataset(\n",
        "        \"text\",\n",
        "        data_files={\n",
        "            \"train\": hparams[\"lm_train_data\"],\n",
        "            \"valid\": hparams[\"lm_valid_data\"],\n",
        "            \"test\": hparams[\"lm_test_data\"],\n",
        "        },\n",
        "    )\n",
        "\n",
        "    # Convert huggingface's dataset to DynamicItemDataset via a magical function\n",
        "    train_data = sb.dataio.dataset.DynamicItemDataset.from_arrow_dataset(\n",
        "        datasets[\"train\"]\n",
        "    )\n",
        "    valid_data = sb.dataio.dataset.DynamicItemDataset.from_arrow_dataset(\n",
        "        datasets[\"valid\"]\n",
        "    )\n",
        "    test_data = sb.dataio.dataset.DynamicItemDataset.from_arrow_dataset(\n",
        "        datasets[\"test\"]\n",
        "    )\n",
        "\n",
        "    datasets = [train_data, valid_data, test_data]\n",
        "    tokenizer = hparams[\"tokenizer\"]\n",
        "    # for local file:\n",
        "    ####################################################\n",
        "    #!!!! skip in Tutorial\n",
        "    tokenizer.load(hparams[\"tokenizer_file\"])\n",
        "\n",
        "    # Define text processing pipeline. We start from the raw text and then\n",
        "    # encode it using the tokenizer. The tokens with bos are used for feeding\n",
        "    # the neural network, the tokens with eos for computing the cost function.\n",
        "    @sb.utils.data_pipeline.takes(\"text\")\n",
        "    @sb.utils.data_pipeline.provides(\"text\", \"tokens_bos\", \"tokens_eos\")\n",
        "    def text_pipeline(text):\n",
        "        yield text\n",
        "        tokens_list = tokenizer.encode_as_ids(text)\n",
        "        tokens_bos = torch.LongTensor([hparams[\"bos_index\"]] + (tokens_list))\n",
        "        yield tokens_bos\n",
        "        tokens_eos = torch.LongTensor(tokens_list + [hparams[\"eos_index\"]])\n",
        "        yield tokens_eos\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, text_pipeline)\n",
        "\n",
        "    # 4. Set outputs to add into the batch. The batch variable will contain\n",
        "    # all these fields (e.g, batch.id, batch.text, batch.tokens.bos,..)\n",
        "    sb.dataio.dataset.set_output_keys(\n",
        "        datasets, [\"id\", \"text\", \"tokens_bos\", \"tokens_eos\"],\n",
        "    )\n",
        "    return train_data, valid_data, test_data\n",
        "\n",
        "\n",
        "# Recipe begins!\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Reading command line arguments\n",
        "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
        "\n",
        "    # Initialize ddp (useful only for multi-GPU DDP training)\n",
        "    sb.utils.distributed.ddp_init_group(run_opts)\n",
        "\n",
        "    # Load hyperparameters file with command-line overrides\n",
        "    with open(hparams_file) as fin:\n",
        "        hparams = load_hyperpyyaml(fin, overrides)\n",
        "\n",
        "    # Create experiment directory\n",
        "    sb.create_experiment_directory(\n",
        "        experiment_directory=hparams[\"output_folder\"],\n",
        "        hyperparams_to_save=hparams_file,\n",
        "        overrides=overrides,\n",
        "    )\n",
        "\n",
        "    # Create dataset objects \"train\", \"valid\", and \"test\"\n",
        "    train_data, valid_data, test_data = dataio_prepare(hparams)\n",
        "    #a = iter(train_data)\n",
        "    #print(next(a),next(a))\n",
        "    # Initialize the Brain object to prepare for LM training.\n",
        "    lm_brain = LM_origin(\n",
        "        modules=hparams[\"modules\"],\n",
        "        opt_class=hparams[\"optimizer\"],\n",
        "        hparams=hparams,\n",
        "        run_opts=run_opts,\n",
        "        checkpointer=hparams[\"checkpointer\"],\n",
        "    )\n",
        "    #print(lm_brain )\n",
        "    #from torchinfo import summary\n",
        "    #print(summary(lm_brain))\n",
        "    # The `fit()` method iterates the training loop, calling the methods\n",
        "    # necessary to update the parameters of the model. Since all objects\n",
        "    # with changing state are managed by the Checkpointer, training can be\n",
        "    # stopped at any point, and will be resumed on next call.\n",
        "    lm_brain.fit(\n",
        "        lm_brain.hparams.epoch_counter,\n",
        "        train_data,\n",
        "        valid_data,\n",
        "        train_loader_kwargs=hparams[\"train_dataloader_opts\"],\n",
        "        valid_loader_kwargs=hparams[\"valid_dataloader_opts\"],\n",
        "    )\n",
        "\n",
        "    # Load best checkpoint for evaluation\n",
        "    test_stats = lm_brain.evaluate(\n",
        "        test_data,\n",
        "        min_key=\"loss\",\n",
        "        test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqzeAZcRZKas",
        "outputId": "c89dd626-9f68-4922-dfa1-3bb8185d5eaa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/speechbrain/templates/speech_recognition/LM/train_02.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -sh /content/speechbrain/templates/speech_recognition/LM/data/*_01.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik1PVfU8P21x",
        "outputId": "86d4bdd8-138e-4555-f91c-97c85045dbd2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32K\t/content/speechbrain/templates/speech_recognition/LM/data/test_01.txt\n",
            "256K\t/content/speechbrain/templates/speech_recognition/LM/data/train_01.txt\n",
            "32K\t/content/speechbrain/templates/speech_recognition/LM/data/valid_01.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torchinfo"
      ],
      "metadata": {
        "id": "vFfRq8AZmW03"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train LM - 20 epochs"
      ],
      "metadata": {
        "id": "alnYYIihcjFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/speechbrain/templates/speech_recognition/LM\n",
        "device ='cuda' if torch.cuda.is_available() else 'cpu' \n",
        "print(\"device =\", device)\n",
        "!python train_02.py RNNLM_02.yaml --device='$device' --number_of_epochs=20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ieps5ykyKV5I",
        "outputId": "3a5f9d36-35ca-4e6f-e86c-fa048e4e85e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/speechbrain/templates/speech_recognition/LM\n",
            "device = cpu\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/RNNLM/\n",
            "root - generating datasets...\n",
            "datasets.builder - Using custom data configuration default-98412a5464459f4a\n",
            "datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-98412a5464459f4a/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08)\n",
            "100% 3/3 [00:00<00:00, 737.96it/s]\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 9.2M trainable parameters in LM_origin\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=6.75]\n",
            "100% 651/651 [00:06<00:00, 99.64it/s]\n",
            "speechbrain.utils.train_logger - epoch: 1, lr: 1.00e-03 - train loss: 6.75 - valid loss: 6.38\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-17-27+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n",
            "100% 66/66 [01:25<00:00,  1.29s/it, train_loss=5.94]\n",
            "100% 651/651 [00:06<00:00, 101.78it/s]\n",
            "speechbrain.utils.train_logger - epoch: 2, lr: 1.00e-03 - train loss: 5.94 - valid loss: 6.25\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-18-59+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-17-27+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 3\n",
            "100% 66/66 [01:26<00:00,  1.30s/it, train_loss=5.38]\n",
            "100% 651/651 [00:06<00:00, 100.46it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.001 to 0.0008\n",
            "speechbrain.utils.train_logger - epoch: 3, lr: 1.00e-03 - train loss: 5.38 - valid loss: 6.37\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-20-32+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 4\n",
            "100% 66/66 [01:24<00:00,  1.27s/it, train_loss=4.79]\n",
            "100% 651/651 [00:06<00:00, 101.95it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.0008 to 0.00064\n",
            "speechbrain.utils.train_logger - epoch: 4, lr: 8.00e-04 - train loss: 4.79 - valid loss: 6.46\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-22-02+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-20-32+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 5\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=4.29]\n",
            "100% 651/651 [00:07<00:00, 88.13it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00064 to 0.00051\n",
            "speechbrain.utils.train_logger - epoch: 5, lr: 6.40e-04 - train loss: 4.29 - valid loss: 6.58\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-23-34+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-22-02+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 6\n",
            "100% 66/66 [01:23<00:00,  1.27s/it, train_loss=3.83]\n",
            "100% 651/651 [00:06<00:00, 101.86it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00051 to 0.00041\n",
            "speechbrain.utils.train_logger - epoch: 6, lr: 5.12e-04 - train loss: 3.83 - valid loss: 6.73\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-25-05+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-23-34+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 7\n",
            "100% 66/66 [01:23<00:00,  1.27s/it, train_loss=3.44]\n",
            "100% 651/651 [00:06<00:00, 100.02it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00041 to 0.00033\n",
            "speechbrain.utils.train_logger - epoch: 7, lr: 4.10e-04 - train loss: 3.44 - valid loss: 6.88\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-26-35+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-25-05+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 8\n",
            "100% 66/66 [01:25<00:00,  1.29s/it, train_loss=3.1]\n",
            "100% 651/651 [00:06<00:00, 95.91it/s] \n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00033 to 0.00026\n",
            "speechbrain.utils.train_logger - epoch: 8, lr: 3.28e-04 - train loss: 3.10 - valid loss: 7.03\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-28-08+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-26-35+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 9\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=2.83]\n",
            "100% 651/651 [00:06<00:00, 100.16it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00026 to 0.00021\n",
            "speechbrain.utils.train_logger - epoch: 9, lr: 2.62e-04 - train loss: 2.83 - valid loss: 7.17\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-29-39+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-28-08+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 10\n",
            "100% 66/66 [01:22<00:00,  1.26s/it, train_loss=2.62]\n",
            "100% 651/651 [00:06<00:00, 101.26it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00021 to 0.00017\n",
            "speechbrain.utils.train_logger - epoch: 10, lr: 2.10e-04 - train loss: 2.62 - valid loss: 7.29\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-31-08+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-29-39+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 11\n",
            "100% 66/66 [01:25<00:00,  1.29s/it, train_loss=2.46]\n",
            "100% 651/651 [00:06<00:00, 100.65it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00017 to 0.00013\n",
            "speechbrain.utils.train_logger - epoch: 11, lr: 1.68e-04 - train loss: 2.46 - valid loss: 7.40\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-32-41+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-31-08+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 12\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=2.33]\n",
            "100% 651/651 [00:06<00:00, 102.10it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00013 to 0.00011\n",
            "speechbrain.utils.train_logger - epoch: 12, lr: 1.34e-04 - train loss: 2.33 - valid loss: 7.50\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-34-12+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-32-41+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 13\n",
            "100% 66/66 [01:24<00:00,  1.27s/it, train_loss=2.23]\n",
            "100% 651/651 [00:06<00:00, 101.38it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00011 to 8.6e-05\n",
            "speechbrain.utils.train_logger - epoch: 13, lr: 1.07e-04 - train loss: 2.23 - valid loss: 7.59\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-35-43+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-34-12+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 14\n",
            "100% 66/66 [01:25<00:00,  1.29s/it, train_loss=2.16]\n",
            "100% 651/651 [00:06<00:00, 102.54it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 8.6e-05 to 6.9e-05\n",
            "speechbrain.utils.train_logger - epoch: 14, lr: 8.59e-05 - train loss: 2.16 - valid loss: 7.66\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-37-15+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-35-43+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 15\n",
            "100% 66/66 [01:24<00:00,  1.27s/it, train_loss=2.1]\n",
            "100% 651/651 [00:06<00:00, 101.67it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 6.9e-05 to 5.5e-05\n",
            "speechbrain.utils.train_logger - epoch: 15, lr: 6.87e-05 - train loss: 2.10 - valid loss: 7.71\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-38-46+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-37-15+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 16\n",
            "100% 66/66 [01:23<00:00,  1.26s/it, train_loss=2.05]\n",
            "100% 651/651 [00:06<00:00, 101.79it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.5e-05 to 4.4e-05\n",
            "speechbrain.utils.train_logger - epoch: 16, lr: 5.50e-05 - train loss: 2.05 - valid loss: 7.77\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-40-16+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-38-46+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 17\n",
            "100% 66/66 [01:25<00:00,  1.30s/it, train_loss=2.02]\n",
            "100% 651/651 [00:06<00:00, 100.54it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.4e-05 to 3.5e-05\n",
            "speechbrain.utils.train_logger - epoch: 17, lr: 4.40e-05 - train loss: 2.02 - valid loss: 7.82\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-41-48+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-40-16+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 18\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=1.98]\n",
            "100% 651/651 [00:06<00:00, 102.39it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.5e-05 to 2.8e-05\n",
            "speechbrain.utils.train_logger - epoch: 18, lr: 3.52e-05 - train loss: 1.98 - valid loss: 7.85\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-43-19+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-41-48+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 19\n",
            "100% 66/66 [01:23<00:00,  1.27s/it, train_loss=1.97]\n",
            "100% 651/651 [00:06<00:00, 102.04it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.8e-05 to 2.3e-05\n",
            "speechbrain.utils.train_logger - epoch: 19, lr: 2.81e-05 - train loss: 1.97 - valid loss: 7.87\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-44-50+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-43-19+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 20\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=1.94]\n",
            "100% 651/651 [00:06<00:00, 102.20it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.3e-05 to 1.8e-05\n",
            "speechbrain.utils.train_logger - epoch: 20, lr: 2.25e-05 - train loss: 1.94 - valid loss: 7.89\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-46-21+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-44-50+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/RNNLM/save/CKPT+2022-06-17+10-18-59+00\n",
            "100% 651/651 [00:06<00:00, 99.33it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save pretrained model"
      ],
      "metadata": {
        "id": "pe28kKMav7T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from_path_total = '/content/speechbrain/templates/speech_recognition/LM/results/RNNLM/save'\n",
        "from_path = glob.glob(from_path_total + '/CKPT*')[-1]\n",
        "!du -h '$from_path'/model.ckpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9639bc7b-ef9e-4096-9a92-a9a2a0cbd854",
        "id": "zB37kvIGv7T_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36M\t/content/speechbrain/templates/speech_recognition/LM/results/RNNLM/save/CKPT+2022-06-17+10-46-21+00/model.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '$from_path'/model.ckpt '/content/drive/MyDrive/Colab Notebooks/_My_Projects/Language_modeling/CRDNN_LM.ckpt'"
      ],
      "metadata": {
        "id": "IcygDneXv7UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Metrics"
      ],
      "metadata": {
        "id": "RifOcCPw_u4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Plot losses"
      ],
      "metadata": {
        "id": "pcz_My4_3svm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/speechbrain/templates/speech_recognition/LM/results/RNNLM/train_log.txt"
      ],
      "metadata": {
        "id": "FLLgbwt7ng0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbe4a456-e267-49b1-a3ae-6f1b4486ab31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, lr: 1.00e-03 - train loss: 6.75 - valid loss: 6.38\n",
            "epoch: 2, lr: 1.00e-03 - train loss: 5.94 - valid loss: 6.25\n",
            "epoch: 3, lr: 1.00e-03 - train loss: 5.38 - valid loss: 6.37\n",
            "epoch: 4, lr: 8.00e-04 - train loss: 4.79 - valid loss: 6.46\n",
            "epoch: 5, lr: 6.40e-04 - train loss: 4.29 - valid loss: 6.58\n",
            "epoch: 6, lr: 5.12e-04 - train loss: 3.83 - valid loss: 6.73\n",
            "epoch: 7, lr: 4.10e-04 - train loss: 3.44 - valid loss: 6.88\n",
            "epoch: 8, lr: 3.28e-04 - train loss: 3.10 - valid loss: 7.03\n",
            "epoch: 9, lr: 2.62e-04 - train loss: 2.83 - valid loss: 7.17\n",
            "epoch: 10, lr: 2.10e-04 - train loss: 2.62 - valid loss: 7.29\n",
            "epoch: 11, lr: 1.68e-04 - train loss: 2.46 - valid loss: 7.40\n",
            "epoch: 12, lr: 1.34e-04 - train loss: 2.33 - valid loss: 7.50\n",
            "epoch: 13, lr: 1.07e-04 - train loss: 2.23 - valid loss: 7.59\n",
            "epoch: 14, lr: 8.59e-05 - train loss: 2.16 - valid loss: 7.66\n",
            "epoch: 15, lr: 6.87e-05 - train loss: 2.10 - valid loss: 7.71\n",
            "epoch: 16, lr: 5.50e-05 - train loss: 2.05 - valid loss: 7.77\n",
            "epoch: 17, lr: 4.40e-05 - train loss: 2.02 - valid loss: 7.82\n",
            "epoch: 18, lr: 3.52e-05 - train loss: 1.98 - valid loss: 7.85\n",
            "epoch: 19, lr: 2.81e-05 - train loss: 1.97 - valid loss: 7.87\n",
            "epoch: 20, lr: 2.25e-05 - train loss: 1.94 - valid loss: 7.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_pattern = r\"[Ee]poch: \\d+\"\n",
        "train_loss_pattern = \"train loss: \\d*\\.\\d+|train loss: [+-]?\\d+\\.\\d+[+-]?[Ee][+-]?\\d+\"\n",
        "valid_loss_pattern = \"valid loss: \\d*\\.\\d+|valid loss: [+-]?\\d+\\.\\d+[+-]?[Ee][+-]?\\d+\"\n",
        "history = {}\n",
        "with open('/content/speechbrain/templates/speech_recognition/LM/results/RNNLM/train_log.txt', 'r') as f:\n",
        "  lines = f.readlines()\n",
        "  for line in lines:\n",
        "    epoch = int(re.findall(epoch_pattern, line)[0].split(':')[-1].strip())\n",
        "    history[epoch]={}\n",
        "    train_loss = float(re.findall(train_loss_pattern, line)[0].split(':')[-1].strip())\n",
        "    valid_loss = float(re.findall(valid_loss_pattern, line)[0].split(':')[-1].strip())\n",
        "    history[epoch][\"train_loss\"]= train_loss\n",
        "    history[epoch][\"valid_loss\"]= valid_loss\n",
        "print(history)    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD14NkY9cY-0",
        "outputId": "8e70611a-caf1-49b4-ac8b-d214c8e57966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: {'train_loss': 6.75, 'valid_loss': 6.38}, 2: {'train_loss': 5.94, 'valid_loss': 6.25}, 3: {'train_loss': 5.38, 'valid_loss': 6.37}, 4: {'train_loss': 4.79, 'valid_loss': 6.46}, 5: {'train_loss': 4.29, 'valid_loss': 6.58}, 6: {'train_loss': 3.83, 'valid_loss': 6.73}, 7: {'train_loss': 3.44, 'valid_loss': 6.88}, 8: {'train_loss': 3.1, 'valid_loss': 7.03}, 9: {'train_loss': 2.83, 'valid_loss': 7.17}, 10: {'train_loss': 2.62, 'valid_loss': 7.29}, 11: {'train_loss': 2.46, 'valid_loss': 7.4}, 12: {'train_loss': 2.33, 'valid_loss': 7.5}, 13: {'train_loss': 2.23, 'valid_loss': 7.59}, 14: {'train_loss': 2.16, 'valid_loss': 7.66}, 15: {'train_loss': 2.1, 'valid_loss': 7.71}, 16: {'train_loss': 2.05, 'valid_loss': 7.77}, 17: {'train_loss': 2.02, 'valid_loss': 7.82}, 18: {'train_loss': 1.98, 'valid_loss': 7.85}, 19: {'train_loss': 1.97, 'valid_loss': 7.87}, 20: {'train_loss': 1.94, 'valid_loss': 7.89}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(list(history.keys()), [value[\"train_loss\"]for value in history.values()], label=\"train_loss\")\n",
        "plt.plot(list(history.keys()), [value[\"valid_loss\"]for value in history.values()], label=\"valid_loss\")\n",
        "plt.title(\"Losses\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPDifmoF1MSu",
        "outputId": "953ad660-5577-4f62-fd4b-607b2b0bc091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Calculate & Plot Perplexity"
      ],
      "metadata": {
        "id": "oc7vcNpPdRgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "for key, values in history.items():\n",
        "  history[key][\"perplexity_train\"] = round(math.exp(values[\"train_loss\"]),2)\n",
        "  history[key][\"perplexity_valid\"] = round(math.exp(values[\"valid_loss\"]),2)\n",
        "print(history)  \n",
        "print(\"Perplexity_train:\",[value[\"perplexity_train\"]for value in history.values()])\n",
        "print(\"Perplexity_valid:\",[value[\"perplexity_valid\"]for value in history.values()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKhVkvozky_Q",
        "outputId": "9e5b0e48-f469-4813-f566-b9f39485f5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: {'train_loss': 6.75, 'valid_loss': 6.38, 'perplexity_train': 854.06, 'perplexity_valid': 589.93}, 2: {'train_loss': 5.94, 'valid_loss': 6.25, 'perplexity_train': 379.93, 'perplexity_valid': 518.01}, 3: {'train_loss': 5.38, 'valid_loss': 6.37, 'perplexity_train': 217.02, 'perplexity_valid': 584.06}, 4: {'train_loss': 4.79, 'valid_loss': 6.46, 'perplexity_train': 120.3, 'perplexity_valid': 639.06}, 5: {'train_loss': 4.29, 'valid_loss': 6.58, 'perplexity_train': 72.97, 'perplexity_valid': 720.54}, 6: {'train_loss': 3.83, 'valid_loss': 6.73, 'perplexity_train': 46.06, 'perplexity_valid': 837.15}, 7: {'train_loss': 3.44, 'valid_loss': 6.88, 'perplexity_train': 31.19, 'perplexity_valid': 972.63}, 8: {'train_loss': 3.1, 'valid_loss': 7.03, 'perplexity_train': 22.2, 'perplexity_valid': 1130.03}, 9: {'train_loss': 2.83, 'valid_loss': 7.17, 'perplexity_train': 16.95, 'perplexity_valid': 1299.84}, 10: {'train_loss': 2.62, 'valid_loss': 7.29, 'perplexity_train': 13.74, 'perplexity_valid': 1465.57}, 11: {'train_loss': 2.46, 'valid_loss': 7.4, 'perplexity_train': 11.7, 'perplexity_valid': 1635.98}, 12: {'train_loss': 2.33, 'valid_loss': 7.5, 'perplexity_train': 10.28, 'perplexity_valid': 1808.04}, 13: {'train_loss': 2.23, 'valid_loss': 7.59, 'perplexity_train': 9.3, 'perplexity_valid': 1978.31}, 14: {'train_loss': 2.16, 'valid_loss': 7.66, 'perplexity_train': 8.67, 'perplexity_valid': 2121.76}, 15: {'train_loss': 2.1, 'valid_loss': 7.71, 'perplexity_train': 8.17, 'perplexity_valid': 2230.54}, 16: {'train_loss': 2.05, 'valid_loss': 7.77, 'perplexity_train': 7.77, 'perplexity_valid': 2368.47}, 17: {'train_loss': 2.02, 'valid_loss': 7.82, 'perplexity_train': 7.54, 'perplexity_valid': 2489.91}, 18: {'train_loss': 1.98, 'valid_loss': 7.85, 'perplexity_train': 7.24, 'perplexity_valid': 2565.73}, 19: {'train_loss': 1.97, 'valid_loss': 7.87, 'perplexity_train': 7.17, 'perplexity_valid': 2617.57}, 20: {'train_loss': 1.94, 'valid_loss': 7.89, 'perplexity_train': 6.96, 'perplexity_valid': 2670.44}}\n",
            "Perplexity_train: [854.06, 379.93, 217.02, 120.3, 72.97, 46.06, 31.19, 22.2, 16.95, 13.74, 11.7, 10.28, 9.3, 8.67, 8.17, 7.77, 7.54, 7.24, 7.17, 6.96]\n",
            "Perplexity_valid: [589.93, 518.01, 584.06, 639.06, 720.54, 837.15, 972.63, 1130.03, 1299.84, 1465.57, 1635.98, 1808.04, 1978.31, 2121.76, 2230.54, 2368.47, 2489.91, 2565.73, 2617.57, 2670.44]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(list(history.keys()), [value[\"perplexity_train\"]for value in history.values()], label=\"by train_loss\") #, marker=\"o\", visible=True)\n",
        "plt.plot(list(history.keys()), [value[\"perplexity_valid\"]for value in history.values()], label=\"by valid_loss\") \n",
        "plt.title(\"Perplexity\")\n",
        "#grath.annotate(\"Test 1\", xy=(0.5, 0.5), xycoords=\"data\",va=\"center\", ha=\"center\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NAHt63P48Fn",
        "outputId": "cc1e7603-8365-491b-c4b5-19004e3c8403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train LM: + 40 epochs"
      ],
      "metadata": {
        "id": "BaJJlOaMwN6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/speechbrain/templates/speech_recognition/LM\n",
        "device ='cuda' if torch.cuda.is_available() else 'cpu' \n",
        "print(\"device =\", device)\n",
        "!python train_02.py RNNLM_02.yaml --device='$device' --number_of_epochs=60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDCYEIVhvceG",
        "outputId": "53ff2d56-490d-4999-f593-e192d5bde1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/speechbrain/templates/speech_recognition/LM\n",
            "device = cpu\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/RNNLM/\n",
            "root - generating datasets...\n",
            "datasets.builder - Using custom data configuration default-98412a5464459f4a\n",
            "datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-98412a5464459f4a/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08)\n",
            "100% 3/3 [00:00<00:00, 715.87it/s]\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 9.2M trainable parameters in LM_origin\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/RNNLM/save/CKPT+2022-06-17+10-46-21+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 21\n",
            "100% 66/66 [01:27<00:00,  1.33s/it, train_loss=1.92]\n",
            "100% 651/651 [00:06<00:00, 101.45it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.8e-05 to 1.4e-05\n",
            "speechbrain.utils.train_logger - epoch: 21, lr: 1.80e-05 - train loss: 1.92 - valid loss: 7.90\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+12-59-48+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+10-46-21+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 22\n",
            "100% 66/66 [01:31<00:00,  1.38s/it, train_loss=1.91]\n",
            "100% 651/651 [00:06<00:00, 102.86it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.4e-05 to 1.2e-05\n",
            "speechbrain.utils.train_logger - epoch: 22, lr: 1.44e-05 - train loss: 1.91 - valid loss: 7.92\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-01-26+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+12-59-48+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 23\n",
            "100% 66/66 [01:36<00:00,  1.46s/it, train_loss=1.91]\n",
            "100% 651/651 [00:06<00:00, 102.66it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.2e-05 to 9.2e-06\n",
            "speechbrain.utils.train_logger - epoch: 23, lr: 1.15e-05 - train loss: 1.91 - valid loss: 7.93\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-03-09+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-01-26+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 24\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=1.89]\n",
            "100% 651/651 [00:06<00:00, 101.59it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 9.2e-06 to 7.4e-06\n",
            "speechbrain.utils.train_logger - epoch: 24, lr: 9.22e-06 - train loss: 1.89 - valid loss: 7.93\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-04-40+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-03-09+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 25\n",
            "100% 66/66 [01:24<00:00,  1.27s/it, train_loss=1.89]\n",
            "100% 651/651 [00:06<00:00, 103.25it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.4e-06 to 5.9e-06\n",
            "speechbrain.utils.train_logger - epoch: 25, lr: 7.38e-06 - train loss: 1.89 - valid loss: 7.94\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-06-10+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-04-40+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 26\n",
            "100% 66/66 [01:25<00:00,  1.30s/it, train_loss=1.88]\n",
            "100% 651/651 [00:06<00:00, 103.74it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.9e-06 to 4.7e-06\n",
            "speechbrain.utils.train_logger - epoch: 26, lr: 5.90e-06 - train loss: 1.88 - valid loss: 7.95\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-07-42+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-06-10+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 27\n",
            "100% 66/66 [01:24<00:00,  1.27s/it, train_loss=1.87]\n",
            "100% 651/651 [00:06<00:00, 103.53it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.7e-06 to 3.8e-06\n",
            "speechbrain.utils.train_logger - epoch: 27, lr: 4.72e-06 - train loss: 1.87 - valid loss: 7.95\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-09-13+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-07-42+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 28\n",
            "100% 66/66 [01:25<00:00,  1.30s/it, train_loss=1.87]\n",
            "100% 651/651 [00:06<00:00, 102.74it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.8e-06 to 3e-06\n",
            "speechbrain.utils.train_logger - epoch: 28, lr: 3.78e-06 - train loss: 1.87 - valid loss: 7.95\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-10-45+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-09-13+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 29\n",
            "100% 66/66 [01:24<00:00,  1.27s/it, train_loss=1.87]\n",
            "100% 651/651 [00:06<00:00, 101.97it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 3e-06 to 2.4e-06\n",
            "speechbrain.utils.train_logger - epoch: 29, lr: 3.02e-06 - train loss: 1.87 - valid loss: 7.96\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-12-16+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-10-45+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 30\n",
            "100% 66/66 [01:25<00:00,  1.30s/it, train_loss=1.88]\n",
            "100% 651/651 [00:06<00:00, 102.41it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.4e-06 to 1.9e-06\n",
            "speechbrain.utils.train_logger - epoch: 30, lr: 2.42e-06 - train loss: 1.88 - valid loss: 7.96\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-13-48+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-12-16+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 31\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=1.87]\n",
            "100% 651/651 [00:06<00:00, 102.40it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.9e-06 to 1.5e-06\n",
            "speechbrain.utils.train_logger - epoch: 31, lr: 1.93e-06 - train loss: 1.87 - valid loss: 7.96\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-15-20+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-13-48+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 32\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=1.87]\n",
            "100% 651/651 [00:06<00:00, 103.12it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.5e-06 to 1.2e-06\n",
            "speechbrain.utils.train_logger - epoch: 32, lr: 1.55e-06 - train loss: 1.87 - valid loss: 7.96\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-16-51+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-15-20+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 33\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=1.87]\n",
            "100% 651/651 [00:06<00:00, 102.05it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.2e-06 to 9.9e-07\n",
            "speechbrain.utils.train_logger - epoch: 33, lr: 1.24e-06 - train loss: 1.87 - valid loss: 7.96\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-18-22+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-16-51+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 34\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=1.87]\n",
            "100% 651/651 [00:06<00:00, 102.00it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 9.9e-07 to 7.9e-07\n",
            "speechbrain.utils.train_logger - epoch: 34, lr: 9.90e-07 - train loss: 1.87 - valid loss: 7.96\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-19-53+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-18-22+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 35\n",
            "100% 66/66 [01:25<00:00,  1.29s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 102.64it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.9e-07 to 6.3e-07\n",
            "speechbrain.utils.train_logger - epoch: 35, lr: 7.92e-07 - train loss: 1.86 - valid loss: 7.96\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-21-25+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-19-53+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 36\n",
            "100% 66/66 [01:25<00:00,  1.30s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 102.29it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 6.3e-07 to 5.1e-07\n",
            "speechbrain.utils.train_logger - epoch: 36, lr: 6.34e-07 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-22-57+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-21-25+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 37\n",
            "100% 66/66 [01:24<00:00,  1.27s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 103.41it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.1e-07 to 4.1e-07\n",
            "speechbrain.utils.train_logger - epoch: 37, lr: 5.07e-07 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-24-28+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-22-57+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 38\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 103.13it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.1e-07 to 3.2e-07\n",
            "speechbrain.utils.train_logger - epoch: 38, lr: 4.06e-07 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-25-59+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-24-28+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 39\n",
            "100% 66/66 [01:23<00:00,  1.27s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 102.47it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.2e-07 to 2.6e-07\n",
            "speechbrain.utils.train_logger - epoch: 39, lr: 3.25e-07 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-27-30+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-25-59+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 40\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=1.87]\n",
            "100% 651/651 [00:06<00:00, 103.60it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.6e-07 to 2.1e-07\n",
            "speechbrain.utils.train_logger - epoch: 40, lr: 2.60e-07 - train loss: 1.87 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-29-01+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-27-30+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 41\n",
            "100% 66/66 [01:26<00:00,  1.30s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 100.61it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.1e-07 to 1.7e-07\n",
            "speechbrain.utils.train_logger - epoch: 41, lr: 2.08e-07 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-30-34+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-29-01+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 42\n",
            "100% 66/66 [01:23<00:00,  1.27s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 102.28it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.7e-07 to 1.3e-07\n",
            "speechbrain.utils.train_logger - epoch: 42, lr: 1.66e-07 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-32-04+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-30-34+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 43\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 101.81it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.3e-07 to 1.1e-07\n",
            "speechbrain.utils.train_logger - epoch: 43, lr: 1.33e-07 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-33-36+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-32-04+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 44\n",
            "100% 66/66 [01:25<00:00,  1.30s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 103.52it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.1e-07 to 8.5e-08\n",
            "speechbrain.utils.train_logger - epoch: 44, lr: 1.06e-07 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-35-08+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-33-36+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 45\n",
            "100% 66/66 [01:24<00:00,  1.27s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 101.37it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 8.5e-08 to 6.8e-08\n",
            "speechbrain.utils.train_logger - epoch: 45, lr: 8.51e-08 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-36-39+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-35-08+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 46\n",
            "100% 66/66 [01:24<00:00,  1.27s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 102.97it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 6.8e-08 to 5.4e-08\n",
            "speechbrain.utils.train_logger - epoch: 46, lr: 6.81e-08 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-38-10+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-36-39+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 47\n",
            "100% 66/66 [01:25<00:00,  1.29s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 103.59it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.4e-08 to 4.4e-08\n",
            "speechbrain.utils.train_logger - epoch: 47, lr: 5.44e-08 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-39-42+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-38-10+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 48\n",
            "100% 66/66 [01:24<00:00,  1.27s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 102.63it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.4e-08 to 3.5e-08\n",
            "speechbrain.utils.train_logger - epoch: 48, lr: 4.36e-08 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-41-13+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-39-42+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 49\n",
            "100% 66/66 [01:23<00:00,  1.27s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 102.00it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.5e-08 to 2.8e-08\n",
            "speechbrain.utils.train_logger - epoch: 49, lr: 3.48e-08 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-42-43+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-41-13+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 50\n",
            "100% 66/66 [01:25<00:00,  1.30s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 103.26it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.8e-08 to 2.2e-08\n",
            "speechbrain.utils.train_logger - epoch: 50, lr: 2.79e-08 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-44-16+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-42-43+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 51\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 102.39it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.2e-08 to 1.8e-08\n",
            "speechbrain.utils.train_logger - epoch: 51, lr: 2.23e-08 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-45-46+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-44-16+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 52\n",
            "100% 66/66 [01:23<00:00,  1.27s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 103.71it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.8e-08 to 1.4e-08\n",
            "speechbrain.utils.train_logger - epoch: 52, lr: 1.78e-08 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-47-17+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-45-46+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 53\n",
            "100% 66/66 [01:25<00:00,  1.30s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 103.31it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.4e-08 to 1.1e-08\n",
            "speechbrain.utils.train_logger - epoch: 53, lr: 1.43e-08 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-48-49+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-47-17+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 54\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 102.31it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.1e-08 to 9.1e-09\n",
            "speechbrain.utils.train_logger - epoch: 54, lr: 1.14e-08 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-50-20+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-48-49+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 55\n",
            "100% 66/66 [01:25<00:00,  1.30s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 103.13it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 9.1e-09 to 7.3e-09\n",
            "speechbrain.utils.train_logger - epoch: 55, lr: 9.13e-09 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-51-53+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-50-20+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 56\n",
            "100% 66/66 [01:24<00:00,  1.27s/it, train_loss=1.87]\n",
            "100% 651/651 [00:06<00:00, 104.06it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.3e-09 to 5.8e-09\n",
            "speechbrain.utils.train_logger - epoch: 56, lr: 7.31e-09 - train loss: 1.87 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-53-24+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-51-53+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 57\n",
            "100% 66/66 [01:26<00:00,  1.30s/it, train_loss=1.87]\n",
            "100% 651/651 [00:06<00:00, 104.19it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.8e-09 to 4.7e-09\n",
            "speechbrain.utils.train_logger - epoch: 57, lr: 5.85e-09 - train loss: 1.87 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-54-56+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-53-24+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 58\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 103.87it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.7e-09 to 3.7e-09\n",
            "speechbrain.utils.train_logger - epoch: 58, lr: 4.68e-09 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-56-28+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-54-56+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 59\n",
            "100% 66/66 [01:25<00:00,  1.30s/it, train_loss=1.87]\n",
            "100% 651/651 [00:06<00:00, 103.94it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.7e-09 to 3e-09\n",
            "speechbrain.utils.train_logger - epoch: 59, lr: 3.74e-09 - train loss: 1.87 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-58-00+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-56-28+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 60\n",
            "100% 66/66 [01:24<00:00,  1.28s/it, train_loss=1.86]\n",
            "100% 651/651 [00:06<00:00, 103.35it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 3e-09 to 2.4e-09\n",
            "speechbrain.utils.train_logger - epoch: 60, lr: 2.99e-09 - train loss: 1.86 - valid loss: 7.97\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-59-32+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-17+13-58-00+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/RNNLM/save/CKPT+2022-06-17+10-18-59+00\n",
            "100% 651/651 [00:06<00:00, 99.63it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save pretrained models"
      ],
      "metadata": {
        "id": "x6GO6Gl3UOB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from_path_total = '/content/speechbrain/templates/speech_recognition/LM/results/RNNLM/save'\n",
        "from_path = glob.glob(from_path_total + '/CKPT*')[-1]\n",
        "!du -h '$from_path'/model.ckpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfAJsMT--V05",
        "outputId": "dcb2672c-63c4-4705-a997-5308e95ff9f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36M\t/content/speechbrain/templates/speech_recognition/LM/results/RNNLM/save/CKPT+2022-06-17+13-59-32+00/model.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '$from_path'/model.ckpt '/content/drive/MyDrive/Colab Notebooks/_My_Projects/Language_modeling/CRDNN_LM_60_epochs.ckpt'"
      ],
      "metadata": {
        "id": "EoI2uQys_KWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train LM - variance temperature GumbeSoftmax"
      ],
      "metadata": {
        "id": "Btayr2TcAiFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RNNLM_03.yaml"
      ],
      "metadata": {
        "id": "T2r2JvN7Ai2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/speechbrain/templates/speech_recognition/LM/RNNLM_03.yaml\n",
        "# ############################################################################\n",
        "# Training: RuDataset transcripts\n",
        "# by original:\n",
        "# Model: Language model with a recurrent neural network (RNNLM)\n",
        "# Training: mini-librispeech transcripts\n",
        "# Authors:  Ju-Chieh Chou 2020, Jianyuan Zhong 2021, Mirco Ravanelli 2021\n",
        "# ############################################################################\n",
        "\n",
        "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
        "seed: 2602\n",
        "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
        "output_folder: !ref results/RNNLM/\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "\n",
        "vocab_size: 8581\n",
        "\n",
        "# If you plan to train a system on an HPC cluster with a big dataset,\n",
        "# we strongly suggest doing the following:\n",
        "# 1- Compress the dataset in a single tar or zip file.\n",
        "# 2- Copy your dataset locally (i.e., the local disk of the computing node).\n",
        "# 3- Uncompress the dataset in the local folder.\n",
        "# 4- Set lm_{train,valid,test}_data with the local path.\n",
        "# Reading data from the local disk of the compute node (e.g. $SLURM_TMPDIR with SLURM-based clusters) is very important.\n",
        "# It allows you to read the data much faster without slowing down the shared filesystem.\n",
        "lm_train_data: data/train_01.txt\n",
        "lm_valid_data: data/valid_01.txt\n",
        "lm_test_data: data/test_01.txt\n",
        "\n",
        "# The train logger writes training statistics to a file, as well as stdout.\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "\n",
        "# Training parameters\n",
        "number_of_epochs: 20\n",
        "batch_size: 80\n",
        "lr: 0.001\n",
        "accu_steps: 1 # Gradient accumulation to simulate large batch training\n",
        "ckpt_interval_minutes: 15 # save checkpoint every N min\n",
        "\n",
        "# Dataloader options\n",
        "train_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "    shuffle: True\n",
        "\n",
        "valid_dataloader_opts:\n",
        "    batch_size: 1\n",
        "\n",
        "test_dataloader_opts:\n",
        "    batch_size: 1\n",
        "\n",
        "# Model parameters\n",
        "#emb_dim: 256 # dimension of the embeddings - дальше в ASR модели используется 128\n",
        "emb_dim: 128 # dimension of the embeddings\n",
        "rnn_size: 256 #512 # dimension of hidden layers\n",
        "layers: 2 # number of hidden layers\n",
        "\n",
        "# Outputs\n",
        "#output_neurons: 1000 # index(blank/eos/bos) = 0\n",
        "output_neurons: !ref <vocab_size>\n",
        "\n",
        "blank_index: 0\n",
        "unk_index: 1\n",
        "bos_index: 0 #2\n",
        "eos_index: 0 #3\n",
        "pad_index: 0\n",
        "\n",
        "\n",
        "# To design a custom model, either just edit the simple CustomModel\n",
        "# class that's listed here, or replace this `!new` call with a line\n",
        "# pointing to a different file you've defined..\n",
        "#model: !new:templates.speech_recognition.LM.custom_model.CustomModel # error not found custom_model.py\n",
        "#model: !new:custom_model.CustomModel_01\n",
        "    #embedding_dim: !ref <emb_dim>\n",
        "    #rnn_size: !ref <rnn_size>\n",
        "    #layers: !ref <layers>\n",
        "\n",
        "# from transformerLM\n",
        "#log_softmax: !new:speechbrain.nnet.activations.Softmax\n",
        "#speechbrain.nnet.activations.GumbelSoftmax(tau, hard=False, apply_log=False)\n",
        "log_softmax: !new:speechbrain.nnet.activations.GumbelSoftmax\n",
        "    tau: 0.7\n",
        "    apply_log: True\n",
        "# Model parameters\n",
        "emb_size: 128\n",
        "activation: !name:torch.nn.LeakyReLU\n",
        "dropout: 0.0\n",
        "rnn_layers: 2\n",
        "rnn_neurons: 512 #2048\n",
        "dnn_blocks: 1\n",
        "dnn_neurons: 512\n",
        "\n",
        "# Functions\n",
        "model: !new:speechbrain.lobes.models.RNNLM.RNNLM\n",
        "    output_neurons: !ref <output_neurons>\n",
        "    embedding_dim: !ref  <emb_size>\n",
        "    activation: !ref <activation>\n",
        "    dropout: !ref <dropout>\n",
        "    rnn_layers: !ref <rnn_layers>\n",
        "    rnn_neurons: !ref <rnn_neurons>\n",
        "    dnn_blocks: !ref <dnn_blocks>\n",
        "    dnn_neurons: !ref <dnn_neurons>\n",
        "\n",
        "#modules:\n",
        "#    model: !ref <model>\n",
        "\n",
        "# Cost function used for training the model\n",
        "compute_cost: !name:speechbrain.nnet.losses.nll_loss\n",
        "\n",
        "# This optimizer will be constructed by the Brain class after all parameters\n",
        "# are moved to the correct device. Then it will be added to the checkpointer.\n",
        "optimizer: !name:torch.optim.Adam\n",
        "    lr: !ref <lr>\n",
        "    betas: (0.9, 0.98)\n",
        "    eps: 0.000000001\n",
        "\n",
        "# This function manages learning rate annealing over the epochs.\n",
        "# We here use the NewBoB algorithm, that anneals the learning rate if\n",
        "# the improvements over two consecutive epochs is less than the defined\n",
        "# threshold.\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.NewBobScheduler\n",
        "    initial_value: !ref <lr>\n",
        "    improvement_threshold: 0.0025\n",
        "    annealing_factor: 0.8\n",
        "    patient: 0\n",
        "\n",
        "\n",
        "# The first object passed to the Brain class is this \"Epoch Counter\"\n",
        "# which is saved by the Checkpointer so that training can be resumed\n",
        "# if it gets interrupted at any point.\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <number_of_epochs>\n",
        "\n",
        "# Objects in \"modules\" dict will have their parameters moved to the correct\n",
        "# device, as well as having train()/eval() called on them by the Brain class.\n",
        "modules:\n",
        "    model: !ref <model>\n",
        "\n",
        "# Tokenizer initialization\n",
        "tokenizer: !new:sentencepiece.SentencePieceProcessor\n",
        "\n",
        "# Tokenizer model (you must use the same tokenizer for LM and ASR training)\n",
        "#tokenizer_file: ../Tokenizer/save/1000_unigram.model\n",
        "tokenizer_file: !ref /content/tokenizer_<vocab_size>_word.model\n",
        "\n",
        "# This object is used for saving the state of training both so that it\n",
        "# can be resumed if it gets interrupted, and also so that the best checkpoint\n",
        "# can be later loaded for evaluation or inference.\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        model: !ref <model>\n",
        "        scheduler: !ref <lr_annealing>\n",
        "        counter: !ref <epoch_counter>\n",
        "\n",
        "# Pretrain the tokenizer\n",
        "pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
        "    loadables:\n",
        "        tokenizer: !ref <tokenizer>\n",
        "    paths:\n",
        "        tokenizer: !ref <tokenizer_file>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd3ab8c-160c-45c7-b819-c792940d194e",
        "id": "NJCt2xiKAi2P"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/speechbrain/templates/speech_recognition/LM/RNNLM_03.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train LM"
      ],
      "metadata": {
        "id": "Rlyizge_BRP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/speechbrain/templates/speech_recognition/LM\n",
        "device ='cuda' if torch.cuda.is_available() else 'cpu' \n",
        "print(\"device =\", device)\n",
        "!python train_02.py RNNLM_03.yaml --device='$device' --number_of_epochs=20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oGN-DLRA-sk",
        "outputId": "1641993b-bd98-43f6-e648-048e95e39145"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/speechbrain/templates/speech_recognition/LM\n",
            "device = cpu\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/RNNLM/\n",
            "root - generating datasets...\n",
            "datasets.builder - Using custom data configuration default-e4f16cf89ac9a7c3\n",
            "datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-e4f16cf89ac9a7c3/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08)\n",
            "100% 3/3 [00:00<00:00, 811.75it/s]\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 9.2M trainable parameters in LM_origin\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/RNNLM/save/CKPT+2022-06-19+12-54-05+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n",
            "100% 66/66 [02:27<00:00,  2.23s/it, train_loss=9.34]\n",
            "100% 651/651 [00:11<00:00, 55.86it/s]\n",
            "speechbrain.utils.train_logger - epoch: 2, lr: 1.00e-03 - train loss: 9.34 - valid loss: 9.71\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-00-06+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+12-54-05+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 3\n",
            "100% 66/66 [02:27<00:00,  2.24s/it, train_loss=8.65]\n",
            "100% 651/651 [00:11<00:00, 55.86it/s]\n",
            "speechbrain.utils.train_logger - epoch: 3, lr: 1.00e-03 - train loss: 8.65 - valid loss: 9.67\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-02-46+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-00-06+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 4\n",
            "100% 66/66 [02:25<00:00,  2.20s/it, train_loss=7.99]\n",
            "100% 651/651 [00:11<00:00, 54.82it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.001 to 0.0008\n",
            "speechbrain.utils.train_logger - epoch: 4, lr: 1.00e-03 - train loss: 7.99 - valid loss: 9.73\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-05-23+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 5\n",
            "100% 66/66 [02:23<00:00,  2.18s/it, train_loss=7.3]\n",
            "100% 651/651 [00:11<00:00, 56.02it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.0008 to 0.00064\n",
            "speechbrain.utils.train_logger - epoch: 5, lr: 8.00e-04 - train loss: 7.30 - valid loss: 9.78\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-07-59+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-05-23+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 6\n",
            "100% 66/66 [02:27<00:00,  2.24s/it, train_loss=6.71]\n",
            "100% 651/651 [00:11<00:00, 56.64it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00064 to 0.00051\n",
            "speechbrain.utils.train_logger - epoch: 6, lr: 6.40e-04 - train loss: 6.71 - valid loss: 9.81\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-10-39+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-07-59+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 7\n",
            "100% 66/66 [02:28<00:00,  2.24s/it, train_loss=6.16]\n",
            "100% 651/651 [00:11<00:00, 56.36it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00051 to 0.00041\n",
            "speechbrain.utils.train_logger - epoch: 7, lr: 5.12e-04 - train loss: 6.16 - valid loss: 9.95\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-13-19+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-10-39+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 8\n",
            "100% 66/66 [02:26<00:00,  2.22s/it, train_loss=5.69]\n",
            "100% 651/651 [00:11<00:00, 54.98it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00041 to 0.00033\n",
            "speechbrain.utils.train_logger - epoch: 8, lr: 4.10e-04 - train loss: 5.69 - valid loss: 10.06\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-15-57+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-13-19+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 9\n",
            "100% 66/66 [02:27<00:00,  2.24s/it, train_loss=5.29]\n",
            "100% 651/651 [00:11<00:00, 56.33it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00033 to 0.00026\n",
            "speechbrain.utils.train_logger - epoch: 9, lr: 3.28e-04 - train loss: 5.29 - valid loss: 10.18\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-18-37+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-15-57+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 10\n",
            "100% 66/66 [02:28<00:00,  2.25s/it, train_loss=4.97]\n",
            "100% 651/651 [00:11<00:00, 55.75it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00026 to 0.00021\n",
            "speechbrain.utils.train_logger - epoch: 10, lr: 2.62e-04 - train loss: 4.97 - valid loss: 10.34\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-21-18+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-18-37+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 11\n",
            "100% 66/66 [02:27<00:00,  2.23s/it, train_loss=4.71]\n",
            "100% 651/651 [00:11<00:00, 55.15it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00021 to 0.00017\n",
            "speechbrain.utils.train_logger - epoch: 11, lr: 2.10e-04 - train loss: 4.71 - valid loss: 10.41\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-23-57+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-21-18+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 12\n",
            "100% 66/66 [02:27<00:00,  2.23s/it, train_loss=4.46]\n",
            "100% 651/651 [00:11<00:00, 56.18it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00017 to 0.00013\n",
            "speechbrain.utils.train_logger - epoch: 12, lr: 1.68e-04 - train loss: 4.46 - valid loss: 10.45\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-26-36+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-23-57+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 13\n",
            "100% 66/66 [02:27<00:00,  2.24s/it, train_loss=4.31]\n",
            "100% 651/651 [00:11<00:00, 54.55it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00013 to 0.00011\n",
            "speechbrain.utils.train_logger - epoch: 13, lr: 1.34e-04 - train loss: 4.31 - valid loss: 10.52\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-29-16+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-26-36+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 14\n",
            "100% 66/66 [02:27<00:00,  2.24s/it, train_loss=4.18]\n",
            "100% 651/651 [00:11<00:00, 55.37it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00011 to 8.6e-05\n",
            "speechbrain.utils.train_logger - epoch: 14, lr: 1.07e-04 - train loss: 4.18 - valid loss: 10.60\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-31-56+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-29-16+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 15\n",
            "100% 66/66 [02:27<00:00,  2.23s/it, train_loss=4.06]\n",
            "100% 651/651 [00:11<00:00, 55.87it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 8.6e-05 to 6.9e-05\n",
            "speechbrain.utils.train_logger - epoch: 15, lr: 8.59e-05 - train loss: 4.06 - valid loss: 10.64\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-34-35+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-31-56+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 16\n",
            "100% 66/66 [02:28<00:00,  2.25s/it, train_loss=3.98]\n",
            "100% 651/651 [00:11<00:00, 54.60it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 6.9e-05 to 5.5e-05\n",
            "speechbrain.utils.train_logger - epoch: 16, lr: 6.87e-05 - train loss: 3.98 - valid loss: 10.72\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-37-16+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-34-35+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 17\n",
            "100% 66/66 [02:27<00:00,  2.23s/it, train_loss=3.91]\n",
            "100% 651/651 [00:11<00:00, 55.03it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.5e-05 to 4.4e-05\n",
            "speechbrain.utils.train_logger - epoch: 17, lr: 5.50e-05 - train loss: 3.91 - valid loss: 10.74\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-39-56+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-37-16+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 18\n",
            "100% 66/66 [02:28<00:00,  2.25s/it, train_loss=3.84]\n",
            "100% 651/651 [00:11<00:00, 55.16it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.4e-05 to 3.5e-05\n",
            "speechbrain.utils.train_logger - epoch: 18, lr: 4.40e-05 - train loss: 3.84 - valid loss: 10.77\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-42-36+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-39-56+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 19\n",
            "100% 66/66 [02:27<00:00,  2.24s/it, train_loss=3.8]\n",
            "100% 651/651 [00:11<00:00, 55.82it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.5e-05 to 2.8e-05\n",
            "speechbrain.utils.train_logger - epoch: 19, lr: 3.52e-05 - train loss: 3.80 - valid loss: 10.80\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-45-16+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-42-36+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 20\n",
            "100% 66/66 [02:25<00:00,  2.20s/it, train_loss=3.76]\n",
            "100% 651/651 [00:12<00:00, 51.59it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.8e-05 to 2.3e-05\n",
            "speechbrain.utils.train_logger - epoch: 20, lr: 2.81e-05 - train loss: 3.76 - valid loss: 10.80\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-47-55+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/RNNLM/save/CKPT+2022-06-19+13-45-16+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/RNNLM/save/CKPT+2022-06-19+13-02-46+00\n",
            "100% 651/651 [00:11<00:00, 55.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save pretrained models"
      ],
      "metadata": {
        "id": "K4mNIWG4BU9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from_path_total = '/content/speechbrain/templates/speech_recognition/LM/results/RNNLM/save'\n",
        "from_path = glob.glob(from_path_total + '/CKPT*')[-1]\n",
        "!du -h '$from_path'/model.ckpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c64b5f-5661-4c54-8e44-6312e637c2ca",
        "id": "Ai8o7c3pBU9-"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36M\t/content/speechbrain/templates/speech_recognition/LM/results/RNNLM/save/CKPT+2022-06-19+13-47-55+00/model.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '$from_path'/model.ckpt '/content/drive/MyDrive/Colab Notebooks/_My_Projects/Language_modeling/CRDNN_LM_GumbelSoftmax_0.7_20_epochs.ckpt'"
      ],
      "metadata": {
        "id": "Bt036YwVBU9-"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Inference"
      ],
      "metadata": {
        "id": "SjmC_a7UAAK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load models"
      ],
      "metadata": {
        "id": "1y6xVpkCQxNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### RNNLM_02_inference.yaml"
      ],
      "metadata": {
        "id": "q3S-CuCJd78l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/speechbrain/templates/speech_recognition/LM/RNNLM_02_inference.yaml\n",
        "# ############################################################################\n",
        "# Training: RuDataset transcripts\n",
        "# by original:\n",
        "# Model: Language model with a recurrent neural network (RNNLM)\n",
        "# Training: mini-librispeech transcripts\n",
        "# Authors:  Ju-Chieh Chou 2020, Jianyuan Zhong 2021, Mirco Ravanelli 2021\n",
        "# ############################################################################\n",
        "\n",
        "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
        "seed: 2602\n",
        "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
        "output_folder: !ref results/RNNLM/\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "\n",
        "vocab_size: 8581\n",
        "\n",
        "# If you plan to train a system on an HPC cluster with a big dataset,\n",
        "# we strongly suggest doing the following:\n",
        "# 1- Compress the dataset in a single tar or zip file.\n",
        "# 2- Copy your dataset locally (i.e., the local disk of the computing node).\n",
        "# 3- Uncompress the dataset in the local folder.\n",
        "# 4- Set lm_{train,valid,test}_data with the local path.\n",
        "# Reading data from the local disk of the compute node (e.g. $SLURM_TMPDIR with SLURM-based clusters) is very important.\n",
        "# It allows you to read the data much faster without slowing down the shared filesystem.\n",
        "lm_train_data: data/train_01.txt\n",
        "lm_valid_data: data/valid_01.txt\n",
        "lm_test_data: data/test_01.txt\n",
        "\n",
        "# The train logger writes training statistics to a file, as well as stdout.\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "\n",
        "# Training parameters\n",
        "number_of_epochs: 20\n",
        "batch_size: 80\n",
        "lr: 0.001\n",
        "accu_steps: 1 # Gradient accumulation to simulate large batch training\n",
        "ckpt_interval_minutes: 15 # save checkpoint every N min\n",
        "\n",
        "# Dataloader options\n",
        "train_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "    shuffle: True\n",
        "\n",
        "valid_dataloader_opts:\n",
        "    batch_size: 1\n",
        "\n",
        "test_dataloader_opts:\n",
        "    batch_size: 1\n",
        "\n",
        "# Model parameters\n",
        "#emb_dim: 256 # dimension of the embeddings - дальше в ASR модели используется 128\n",
        "emb_dim: 128 # dimension of the embeddings\n",
        "rnn_size: 256 #512 # dimension of hidden layers\n",
        "layers: 2 # number of hidden layers\n",
        "\n",
        "# Outputs\n",
        "#output_neurons: 1000 # index(blank/eos/bos) = 0\n",
        "output_neurons: !ref <vocab_size>\n",
        "\n",
        "blank_index: 0\n",
        "unk_index: 1\n",
        "bos_index: 0 #2\n",
        "eos_index: 0 #3\n",
        "pad_index: 0\n",
        "\n",
        "\n",
        "# To design a custom model, either just edit the simple CustomModel\n",
        "# class that's listed here, or replace this `!new` call with a line\n",
        "# pointing to a different file you've defined..\n",
        "#model: !new:templates.speech_recognition.LM.custom_model.CustomModel # error not found custom_model.py\n",
        "#model: !new:custom_model.CustomModel_01\n",
        "    #embedding_dim: !ref <emb_dim>\n",
        "    #rnn_size: !ref <rnn_size>\n",
        "    #layers: !ref <layers>\n",
        "\n",
        "# from transformerLM\n",
        "log_softmax: !new:speechbrain.nnet.activations.Softmax\n",
        "    apply_log: True\n",
        "# Model parameters\n",
        "emb_size: 128\n",
        "activation: !name:torch.nn.LeakyReLU\n",
        "dropout: 0.0\n",
        "rnn_layers: 2\n",
        "rnn_neurons: 512 #2048\n",
        "dnn_blocks: 1\n",
        "dnn_neurons: 512\n",
        "\n",
        "# Functions\n",
        "model: !new:speechbrain.lobes.models.RNNLM.RNNLM\n",
        "    output_neurons: !ref <output_neurons>\n",
        "    embedding_dim: !ref  <emb_size>\n",
        "    activation: !ref <activation>\n",
        "    dropout: !ref <dropout>\n",
        "    rnn_layers: !ref <rnn_layers>\n",
        "    rnn_neurons: !ref <rnn_neurons>\n",
        "    dnn_blocks: !ref <dnn_blocks>\n",
        "    dnn_neurons: !ref <dnn_neurons>\n",
        "\n",
        "#modules:\n",
        "#    model: !ref <model>\n",
        "\n",
        "# Cost function used for training the model\n",
        "compute_cost: !name:speechbrain.nnet.losses.nll_loss\n",
        "\n",
        "# This optimizer will be constructed by the Brain class after all parameters\n",
        "# are moved to the correct device. Then it will be added to the checkpointer.\n",
        "optimizer: !name:torch.optim.Adam\n",
        "    lr: !ref <lr>\n",
        "    betas: (0.9, 0.98)\n",
        "    eps: 0.000000001\n",
        "\n",
        "# This function manages learning rate annealing over the epochs.\n",
        "# We here use the NewBoB algorithm, that anneals the learning rate if\n",
        "# the improvements over two consecutive epochs is less than the defined\n",
        "# threshold.\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.NewBobScheduler\n",
        "    initial_value: !ref <lr>\n",
        "    improvement_threshold: 0.0025\n",
        "    annealing_factor: 0.8\n",
        "    patient: 0\n",
        "\n",
        "\n",
        "# The first object passed to the Brain class is this \"Epoch Counter\"\n",
        "# which is saved by the Checkpointer so that training can be resumed\n",
        "# if it gets interrupted at any point.\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <number_of_epochs>\n",
        "\n",
        "# Objects in \"modules\" dict will have their parameters moved to the correct\n",
        "# device, as well as having train()/eval() called on them by the Brain class.\n",
        "modules:\n",
        "    model: !ref <model>\n",
        "\n",
        "# Tokenizer initialization\n",
        "tokenizer: !new:sentencepiece.SentencePieceProcessor\n",
        "\n",
        "# Tokenizer model (you must use the same tokenizer for LM and ASR training)\n",
        "#tokenizer_file: ../Tokenizer/save/1000_unigram.model\n",
        "\n",
        "\n",
        "# This object is used for saving the state of training both so that it\n",
        "# can be resumed if it gets interrupted, and also so that the best checkpoint\n",
        "# can be later loaded for evaluation or inference.\n",
        "#checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "#    checkpoints_dir: !ref <save_folder>\n",
        "#    recoverables:\n",
        "#        model: !ref <model>\n",
        "#        scheduler: !ref <lr_annealing>\n",
        "#        counter: !ref <epoch_counter>\n",
        "\n",
        "tokenizer_file: !ref /content/tokenizer_<vocab_size>_word.model\n",
        "lm_file: /content/model.ckpt\n",
        "\n",
        "# Pretrain models\n",
        "pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
        "    loadables:\n",
        "        #tokenizer: !ref <tokenizer> # уже есть в yaml-параметрах\n",
        "        lm: !ref <model>  # добавляем Language model\n",
        "    paths:\n",
        "        #tokenizer: !ref <tokenizer_file> # уже есть в yaml-параметрах\n",
        "        lm: !ref <lm_file>  # добавляем Language model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0975d7fd-e5e7-4a9a-ebf3-5ca68378aa1f",
        "id": "DnPDG8Xld78m"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/speechbrain/templates/speech_recognition/LM/RNNLM_02_inference.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Restore Language Model"
      ],
      "metadata": {
        "id": "SM8nf_y-Wbbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/MyDrive/Colab Notebooks/_My_Projects/Language_modeling/CRDNN_LM_60_epochs.ckpt' /content/model.ckpt"
      ],
      "metadata": {
        "id": "dDH4yUhdSltk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gumbe Softmax\n",
        "!cp '/content/drive/MyDrive/Colab Notebooks/_My_Projects/Language_modeling/CRDNN_LM_GumbelSoftmax_0.7_20_epochs.ckpt' /content/model2.ckpt"
      ],
      "metadata": {
        "id": "BUxNS_KHPoXg"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for checkpointer\n",
        "#!cp /content/model.ckpt '/content/speechbrain/templates/speech_recognition/LM/results/RNNLM/save/model.ckpt'"
      ],
      "metadata": {
        "id": "QcCkBkDry21U"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/speechbrain/templates/speech_recognition/LM/\n",
        "from train_02 import LM_origin, dataio_prepare\n",
        "import sys\n",
        "import logging\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "import speechbrain as sb\n",
        "\n",
        "# Инициализация модели -через загрузку pretrained model\n",
        "# v01 - через отдельный yaml для Inference\n",
        "#hparams_file = '/content/speechbrain/templates/speech_recognition/LM/RNNLM_02_inference.yaml'\n",
        "\n",
        "# v02 - через train yaml и  overrides\n",
        "hparams_file = '/content/speechbrain/templates/speech_recognition/LM/RNNLM_02.yaml'\n",
        "overrides=\"\"\"\n",
        "checkpointer: ~ # or null # https://stackoverflow.com/questions/34089496/empty-field-in-yaml\n",
        "#lm_file: /content/model.ckpt # Не подходит потому как его не было в train.yaml\n",
        "\n",
        "pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
        "    loadables:\n",
        "        tokenizer: !ref <tokenizer> # уже есть в yaml-параметрах\n",
        "        model: !ref <model>  # добавляем Language model\n",
        "    paths:\n",
        "        tokenizer: !ref <tokenizer_file> # уже есть в yaml-параметрах\n",
        "        model: !ref /content/model.ckpt  # добавляем Language model\n",
        "\"\"\"        \n",
        "\n",
        "# v03 - через train yaml и  overrides + GumbelSoftmax\n",
        "hparams_file = '/content/speechbrain/templates/speech_recognition/LM/RNNLM_03.yaml'\n",
        "overrides=\"\"\"\n",
        "checkpointer: ~ # or null # https://stackoverflow.com/questions/34089496/empty-field-in-yaml\n",
        "#lm_file: /content/model.ckpt # Не подходит потому как его не было в train.yaml\n",
        "log_softmax: !new:speechbrain.nnet.activations.GumbelSoftmax\n",
        "    tau: 0.7\n",
        "    apply_log: True\n",
        "\n",
        "pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
        "    loadables:\n",
        "        tokenizer: !ref <tokenizer> # уже есть в yaml-параметрах\n",
        "        model: !ref <model>  # добавляем Language model\n",
        "    paths:\n",
        "        tokenizer: !ref <tokenizer_file> # уже есть в yaml-параметрах\n",
        "        model: !ref /content/model2.ckpt  # добавляем Language model\n",
        "\"\"\"        \n",
        "device ='cuda' if torch.cuda.is_available() else 'cpu' \n",
        "#run_opts = f'device:{device}'\n",
        "run_opts = {\"device\":device}\n",
        "with open(hparams_file) as fin:\n",
        "        hparams = load_hyperpyyaml(fin, overrides)\n",
        "lm_brain = LM_origin(\n",
        "        modules=hparams[\"modules\"],\n",
        "        opt_class=hparams[\"optimizer\"],\n",
        "        #pretrainer= hparams[\"pretrainer\"],\n",
        "        hparams=hparams,\n",
        "        run_opts=run_opts,\n",
        "        #checkpointer=hparams[\"checkpointer\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW540yziAE62",
        "outputId": "df0ab703-857a-4cfe-defa-f3660a7568b3"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/speechbrain/templates/speech_recognition/LM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(hparams.pretrainer)\n",
        "#print(hparams)\n",
        "print(hparams[\"pretrainer\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5rQvD0szs6M",
        "outputId": "6b2c820f-3aad-46a9-8d69-79d832e2b714"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<speechbrain.utils.parameter_transfer.Pretrainer object at 0x7f9897b90d50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "run_opts = {\"device\":device}\n",
        "from speechbrain.utils.distributed import run_on_main\n",
        "run_on_main(hparams[\"pretrainer\"].collect_files)\n",
        "#hparams[\"pretrainer\"].load_collected(device=device)\n",
        "hparams[\"pretrainer\"].load_collected(device=run_opts[\"device\"])"
      ],
      "metadata": {
        "id": "4KyL3cxX1rfk"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/speechbrain/templates/speech_recognition/LM/\n",
        "train_data, valid_data, test_data = dataio_prepare(hparams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124,
          "referenced_widgets": [
            "872fb3ed20674a3a9c409d077542cab7",
            "5e09fbc16dae4d18a84d50317d8799ca",
            "170bb14e5be14b1a8e4e46d89485f5d4",
            "54731b5252ef4af4aed3edde975df8a9",
            "5a7624be2c5148028a688a6795074116",
            "5060962daabc40e09fa3176b608d15d3",
            "ad809b8f352d4e26a9d7a2ec7ec04006",
            "56e5326fbbbc416cb77af46e53d8bad7",
            "9960aeca74c846b7a80aa7d0aafaa3d9",
            "180ea5cbae1d4509b3b282155173df8f",
            "7043c6acf064449ab5ef5b70357804da"
          ]
        },
        "id": "eqwWngKnTQzF",
        "outputId": "f1574577-0caa-4b96-b3d5-9d06f4627c3c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/speechbrain/templates/speech_recognition/LM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default-e4f16cf89ac9a7c3\n",
            "WARNING:datasets.builder:Reusing dataset text (/root/.cache/huggingface/datasets/text/default-e4f16cf89ac9a7c3/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "872fb3ed20674a3a9c409d077542cab7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lm_brain.hparams.model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS07PAbIf2gs",
        "outputId": "08307c09-ad31-43dd-9c70-a932023172b2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNNLM(\n",
            "  (embedding): Embedding(\n",
            "    (Embedding): Embedding(8581, 128)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            "  (rnn): LSTM(\n",
            "    (rnn): LSTM(128, 512, num_layers=2, batch_first=True)\n",
            "  )\n",
            "  (dnn): Sequential(\n",
            "    (linear): Linear(\n",
            "      (w): Linear(in_features=512, out_features=512, bias=True)\n",
            "    )\n",
            "    (norm): LayerNorm(\n",
            "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (act): LeakyReLU(negative_slope=0.01)\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (out): Linear(\n",
            "    (w): Linear(in_features=512, out_features=8581, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    test_stats = lm_brain.evaluate(\n",
        "        test_data,\n",
        "        min_key=\"loss\",\n",
        "        test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
        "    )\n",
        "    print(test_stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wFH12pYa_VD",
        "outputId": "ddddd375-0475-4b2c-fae5-62ca0bc951aa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 651/651 [00:08<00:00, 74.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # v02 Initializate model (by checkpoint - after training in this session)\n",
        " lm_brain.fit(\n",
        "        lm_brain.hparams.epoch_counter,\n",
        "        train_data,\n",
        "        valid_data,\n",
        "        train_loader_kwargs=hparams[\"train_dataloader_opts\"],\n",
        "        valid_loader_kwargs=hparams[\"valid_dataloader_opts\"],\n",
        "    )"
      ],
      "metadata": {
        "id": "GHcITC0jRM_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Restore Tokenizer"
      ],
      "metadata": {
        "id": "fArboImTWW91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# v01 - initialization Tokenizer - from yaml parameters\n",
        "#sp = hparams[\"tokenizer\"]\n",
        "tokens_list = sp.encode_as_ids(medium_data[\"title\"][0])\n",
        "tokens_bos = torch.LongTensor([hparams[\"bos_index\"]] + (tokens_list))\n",
        "print(medium_data[\"title\"][0])\n",
        "print(tokens_bos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p41jqsjFUsO5",
        "outputId": "34f63209-133b-44d8-a101-89479ea7e29f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a beginners guide to word embedding with gensim word2vec model\n",
            "tensor([   0,    3,  268,   63,    1,  461, 1565,   11, 2863, 8512,   96])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# v02 - initialization Tokenizer - without checkpoint\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('/content/tokenizer_8581_word.model')\n",
        "tokens_list = sp.encode_as_ids(medium_data[\"title\"][0])\n",
        "tokens_bos = torch.LongTensor([hparams[\"bos_index\"]] + (tokens_list))\n",
        "print(medium_data[\"title\"][0])\n",
        "print(tokens_bos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TWDL98mUpTA",
        "outputId": "e4648929-c620-41e3-8983-e3d5193c1e7b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a beginners guide to word embedding with gensim word2vec model\n",
            "tensor([   0,    3,  268,   63,    1,  461, 1565,   11, 2863, 8512,   96])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lm_brain.hparams.model(tokens_bos.to(device)).size())\n",
        "output = lm_brain.hparams.model(tokens_bos.to(device))\n",
        "print(output[0].size())\n",
        "print(output[0][:10])\n",
        "print(max(output[0]), torch.argmax(output[0]) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C71xQgSiGEaI",
        "outputId": "12795a78-4eeb-49ad-8559-d121fb65c35f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([11, 8581])\n",
            "torch.Size([8581])\n",
            "tensor([ 0.0935,  0.4670, -0.7049,  0.2428, -0.6527,  0.2568,  0.2491, -0.2509,\n",
            "         0.0093,  0.0530], grad_fn=<SliceBackward0>)\n",
            "tensor(1.6542, grad_fn=<UnbindBackward0>) tensor(7950)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LM_decoders"
      ],
      "metadata": {
        "id": "iYl7Bg01Zvc-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Simple Decoder"
      ],
      "metadata": {
        "id": "84zQ4vBFZz26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Softmax simple"
      ],
      "metadata": {
        "id": "gPBVpBQjPK6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LM_decoder_simple(model, sp, bos_id, text):\n",
        "    print(\"source:\", text)\n",
        "    tokens_list = sp.encode_as_ids(text)\n",
        "    print(\"tokens_list\", tokens_list)\n",
        "    tokens_bos = torch.LongTensor([bos_id] + (tokens_list))\n",
        "    predictions = model(tokens_bos)\n",
        "    #print(predictions.size())\n",
        "    pred_ids = [int(np.argmax(s,axis=-1)) for s in predictions.detach().numpy()]\n",
        "    print(\"pred_ids\", pred_ids)\n",
        "    pred_text = sp.decode_ids(pred_ids)\n",
        "    print(\"predict:\", pred_text)\n",
        "    return pred_text\n",
        "#pred_text = LM_decoder_simple(lm_brain.hparams.model, sp, hparams[\"bos_index\"], medium_data[\"title\"][1])  \n",
        "pred_text = LM_decoder_simple(lm_brain.hparams.model, sp, hparams[\"bos_index\"], medium_data[\"title\"][1])  \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HVtJCH6hBAf",
        "outputId": "ff99e69b-7648-4047-f04b-8fb151d24eb0"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source: handson graph neural networks with pytorch  pytorch geometric\n",
            "tokens_list [5559, 735, 78, 99, 11, 337, 337, 2047]\n",
            "pred_ids [6, 7, 2, 99, 0, 2, 11, 11, 7]\n",
            "predict: how in the networks ⁇  the with with in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/speechbrain/templates/speech_recognition/LM/data/train_01.txt'\n",
        "with open(file_name, 'r') as f:\n",
        "  txts = f.readlines()\n"
      ],
      "metadata": {
        "id": "lWv6J2OfqyRT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line = txts[np.random.randint(len(txts))]\n",
        "pred_text = LM_decoder_simple(lm_brain.hparams.model, sp, hparams[\"bos_index\"], line)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3idUTXQorC8B",
        "outputId": "61406f61-b475-4b22-911d-fd5b76da91f7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source: how to live in the present and make your time count\n",
            "\n",
            "tokens_list [6, 1, 370, 7, 2, 2230, 5, 44, 8, 58, 1268]\n",
            "pred_ids [6, 1, 2, 7, 2, 83, 1, 6, 2, 450, 0, 0]\n",
            "predict: how to the in the future to how the phone ⁇  ⁇ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Softmax Gumbe"
      ],
      "metadata": {
        "id": "4Y2KOfp1PVcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LM_decoder_simple(model, sp, bos_id, text):\n",
        "    print(\"source:\", text)\n",
        "    tokens_list = sp.encode_as_ids(text)\n",
        "    print(\"tokens_list\", tokens_list)\n",
        "    tokens_bos = torch.LongTensor([bos_id] + (tokens_list))\n",
        "    predictions = model(tokens_bos)\n",
        "    #print(predictions.size())\n",
        "    pred_ids = [int(np.argmax(s,axis=-1)) for s in predictions.detach().numpy()]\n",
        "    print(\"pred_ids\", pred_ids)\n",
        "    pred_text = sp.decode_ids(pred_ids)\n",
        "    print(\"predict:\", pred_text)\n",
        "    return pred_text\n",
        "#pred_text = LM_decoder_simple(lm_brain.hparams.model, sp, hparams[\"bos_index\"], medium_data[\"title\"][1])  \n",
        "pred_text = LM_decoder_simple(lm_brain.hparams.model, sp, hparams[\"bos_index\"], medium_data[\"title\"][1])  \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e6fb7c-adc0-496f-d3d3-592da987a7c2",
        "id": "802HwACUPVcX"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source: handson graph neural networks with pytorch  pytorch geometric\n",
            "tokens_list [5559, 735, 78, 99, 11, 337, 337, 2047]\n",
            "pred_ids [6, 7, 2, 99, 0, 2, 11, 11, 7]\n",
            "predict: how in the networks ⁇  the with with in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/speechbrain/templates/speech_recognition/LM/data/train_01.txt'\n",
        "with open(file_name, 'r') as f:\n",
        "  txts = f.readlines()\n"
      ],
      "metadata": {
        "id": "XJLX-G3hPVcX"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line = txts[np.random.randint(len(txts))]\n",
        "pred_text = LM_decoder_simple(lm_brain.hparams.model, sp, hparams[\"bos_index\"], line)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7923b1c6-781b-4ea0-a58b-1d19e138080d",
        "id": "JUQOQi14PVcX"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source: deeppicar  part 3 make picar see and think\n",
            "\n",
            "tokens_list [1960, 55, 52, 44, 3244, 769, 5, 238]\n",
            "pred_ids [6, 0, 90, 144, 2, 3, 3, 6, 2]\n",
            "predict: how ⁇  1 reasons the a a how the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Greedy Search Decoder"
      ],
      "metadata": {
        "id": "kQjVnVyebUpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Softmax Simple"
      ],
      "metadata": {
        "id": "vEzTRzxCQ0zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LM_decoder_greedy_search(model, sp, bos_id, text):\n",
        "    tokens_list = sp.encode_as_ids(text)\n",
        "    tokens_bos = torch.LongTensor([bos_id] + (tokens_list))\n",
        "    pred_text = ''\n",
        "    for i in range(len(tokens_bos)):\n",
        "        predictions = model(tokens_bos[i:i+2])\n",
        "        #print(predictions.size())\n",
        "        pred_ids = [int(np.argmax(s,axis=-1)) for s in predictions.detach().numpy()]\n",
        "        #print(pred_ids)\n",
        "        pred_text += \" \" + sp.decode_ids([pred_ids[-1]])\n",
        "        #print(pred_text)\n",
        "    return pred_text\n",
        "line = txts[np.random.randint(len(txts))]\n",
        "pred_text = LM_decoder_greedy_search(lm_brain.hparams.model, sp, hparams[\"bos_index\"], line)  \n",
        "print(\"source:\", line)\n",
        "print(\"predict:\", pred_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaKFLBWdm4MY",
        "outputId": "700baf1e-fdef-4dd4-8a56-8eaec035ca6a"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source: using ant colony and genetic evolution to optimize ridesharing trip duration\n",
            "\n",
            "predict:  python  ⁇  a how how in the the in about in in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Softmax Gumbe"
      ],
      "metadata": {
        "id": "xx_IjtcbQ5D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LM_decoder_greedy_search(model, sp, bos_id, text):\n",
        "    tokens_list = sp.encode_as_ids(text)\n",
        "    tokens_bos = torch.LongTensor([bos_id] + (tokens_list))\n",
        "    pred_text = ''\n",
        "    for i in range(len(tokens_bos)):\n",
        "        predictions = model(tokens_bos[i:i+2])\n",
        "        #print(predictions.size())\n",
        "        pred_ids = [int(np.argmax(s,axis=-1)) for s in predictions.detach().numpy()]\n",
        "        #print(pred_ids)\n",
        "        pred_text += \" \" + sp.decode_ids([pred_ids[-1]])\n",
        "        #print(pred_text)\n",
        "    return pred_text\n",
        "line = txts[np.random.randint(len(txts))]\n",
        "pred_text = LM_decoder_greedy_search(lm_brain.hparams.model, sp, hparams[\"bos_index\"], line)  \n",
        "print(\"source:\", line)\n",
        "print(\"predict:\", pred_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2ba57ca-7fd4-4e3d-8551-f46d5c77bda5",
        "id": "SfjJD72TQ5EA"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source: the counterintuitive perils and promises of the digital world\n",
            "\n",
            "predict:  future a  ⁇  how with the future transformation  ⁇   ⁇ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### BeamSearch Decoder\n",
        "by https://towardsdatascience.com/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24\n",
        "\n",
        "https://huggingface.co/blog/how-to-generate"
      ],
      "metadata": {
        "id": "c_xHpW3LQNBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "line = txts[np.random.randint(len(txts))]\n",
        "pred_text = LM_decoder_beam_search(lm_brain.hparams.model, line, tokenizer=sp, bos_id=hparams[\"bos_index\"], eos_id=hparams[\"eos_index\"])  \n",
        "print(\"source:\", line)\n",
        "print(\"predict:\", pred_text)"
      ],
      "metadata": {
        "id": "KsKQbmPMiWjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(tokens_bos).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co4EPAW_6yWJ",
        "outputId": "0d43ad83-10d6-44af-e4b2-0807f2823591"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9, 8581])"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def LM_decoder_beam_search( text_line, \n",
        "                           model=lm_brain.hparams.model,\n",
        "                           max_next_words = 3,\n",
        "                           width__num_beams = 2,\n",
        "                           tokenizer=sp, \n",
        "                           bos_id=hparams[\"bos_index\"], \n",
        "                           eos_id=hparams[\"eos_index\"],\n",
        "                           debug=True):\n",
        "    \n",
        "    \n",
        "    tokens_list = tokenizer.encode_as_ids(text_line)\n",
        "    if debug: print(\"tokens_list\", tokens_list) \n",
        "    tokens_bos = torch.LongTensor([bos_id] + (tokens_list))\n",
        "    beams = torch.tensor([[], [0.0]])\n",
        "    start = 2\n",
        "    \n",
        "    # step 1\n",
        "    if debug: print(\"step 1\")  \n",
        "    #print(tokens_bos)\n",
        "    output = model(tokens_bos)\n",
        "    if debug: print(output.size())\n",
        "\n",
        "    probs_indices = torch.topk(output[:,:], width__num_beams, dim=-1)\n",
        "    probs, indices = probs_indices[0][0],probs_indices[1][0]\n",
        "    if debug: print(probs, indices)\n",
        "\n",
        "    #tracks = torch.asarray([[[], 0.0],[[],0.0]])\n",
        "    tracks = {}\n",
        "    \n",
        "    for beam in range(width__num_beams):\n",
        "        tracks[beam] = {}\n",
        "        tracks[beam][\"probs\"] = [probs[beam].detach()]\n",
        "        tracks[beam][\"total_prob\"] = probs[beam].detach()\n",
        "        tracks[beam][\"indices\"] = [indices[beam]]\n",
        "        tracks[beam][\"ids\"] = torch.cat((torch.tensor(tokens_list), torch.tensor(tracks[beam][\"indices\"])) )\n",
        "        tracks[beam][\"text\"]= \" \".join([tokenizer.decode_ids([int(item)]) for item in tracks[beam][\"ids\"] ])\n",
        "    if debug: print(\"tracks\", tracks)                        \n",
        "    if debug: print()\n",
        "    \n",
        "    # step 2..end\n",
        "    for step in range(2,max_next_words+1,1):\n",
        "      if debug: print(\"step\", step)\n",
        "      t_tracks = {}\n",
        "      t_total_probs = {}\n",
        "      max_probs_beams = width__num_beams*[width__num_beams*[-1]]\n",
        "      #print(\"max_probs_beams\", max_probs_beams)\n",
        "      max_probs = torch.tensor(width__num_beams*[-torch.inf])\n",
        "      for beam in range(width__num_beams):\n",
        "          #seed_ids_ds = batchify(torch.cat((seed_ids,tracks[beam][\"ids\"])), batch_size)\n",
        "          #seed_ids_ds = batchify(tracks[beam][\"ids\"], batch_size)\n",
        "          #output = model(seed_ids_ds, src_mask)\n",
        "          tokens_bos = torch.LongTensor(torch.tensor([bos_id]) + (tracks[beam][\"ids\"]))\n",
        "          output = model(tokens_bos)\n",
        "          #if debug: print(\"output.size\", output.size())\n",
        "          probs_indices = torch.topk(output[-1,:], width__num_beams, dim=-1)\n",
        "          #probs, indices = probs_indices[0][0],probs_indices[1][0]\n",
        "          probs, indices = probs_indices[0],probs_indices[1]\n",
        "          t_tracks[beam] = {}\n",
        "          t_total_probs[beam] = {}\n",
        "          \n",
        "          #t_total_probs[beam] = tracks[beam][\"total_prob\"]\n",
        "          for beam2 in range(width__num_beams):\n",
        "              t_tracks[beam][beam2] = {}\n",
        "              t_tracks[beam][beam2][\"probs\"] = probs[beam2].detach()\n",
        "              t_total_probs[beam][beam2]=tracks[beam][\"total_prob\"] + probs[beam2].detach() # для более простой проверки\n",
        "              #t_total_probs[beam][beam2]=tracks[beam][\"total_prob\"] * probs[beam2].detach()\n",
        "              t_tracks[beam][beam2][\"indices\"] = [indices[beam2]]\n",
        "              t_tracks[beam][beam2][\"ids\"] = torch.cat((torch.tensor(tracks[beam][\"ids\"]), torch.tensor(t_tracks[beam][beam2][\"indices\"])) )\n",
        "              t_tracks[beam][beam2][\"text\"]= \" \".join([tokenizer.decode_ids([int(item)]) for item in t_tracks[beam][beam2][\"ids\"]])\n",
        "              #t_tracks[beam][beam2][\"text\"]= \" \".join([tokenizer.id_to_piece(int(item)) for item in t_tracks[beam][beam2][\"ids\"]])\n",
        "              # id_to_piece возвращает ▁magic\n",
        "          \n",
        "      if debug: print(\"t_tracks\",t_tracks)        \n",
        "      if debug: print(\"t_total_probs\", t_total_probs)   \n",
        "      # t_total_probs_t = [ vv for v in t_total_probs.values() for vv in v.values()]\n",
        "      #torch.topk(torch.tensor(t_total_probs.values().numpy()), width, dim=-1)             \n",
        "\n",
        "      for beam in range(width__num_beams):\n",
        "          for beam2 in range(width__num_beams):\n",
        "              if t_total_probs[beam][beam2]> max_probs[beam]:\n",
        "                  max_probs[beam] = t_total_probs[beam][beam2]\n",
        "                  max_probs_beams[beam] = [beam,beam2]\n",
        "      if debug: print(\"max_probs_beams\", max_probs_beams)\n",
        "      if debug: print(\"max_probs\", max_probs)\n",
        "      \n",
        "      for beam in range(width__num_beams):\n",
        "          tracks[beam][\"ids\"] = t_tracks[beam][max_probs_beams[beam][1]][\"ids\"] # полная запись\n",
        "          tracks[beam][\"indices\"] += t_tracks[beam][max_probs_beams[beam][1]][\"indices\"]\n",
        "          tracks[beam][\"probs\"] += [t_tracks[beam][max_probs_beams[beam][1]][\"probs\"]]\n",
        "          #tracks[beam][\"total_prob\"] += t_tracks[beam][max_probs_beams[beam][1]][\"probs\"]\n",
        "          tracks[beam][\"total_prob\"] = t_total_probs[beam][max_probs_beams[beam][1]]\n",
        "          tracks[beam][\"text\"]= \" \".join([tokenizer.decode_ids([int(item)]) for item in tracks[beam][\"ids\"]])\n",
        "      if debug: print(\"tracks\",tracks)\n",
        "      if debug: print()\n",
        "    max_prob = -torch.inf\n",
        "    for beam in range(width__num_beams):\n",
        "        if tracks[beam][\"total_prob\"] > max_prob:\n",
        "            max_prob = tracks[beam][\"total_prob\"]\n",
        "            pred_text = tracks[beam][\"text\"]\n",
        "    \n",
        "    print(\"seed_text:\", text_line)\n",
        "    print(\"pred_text:\", pred_text)\n",
        "    print(\"max_prob:\", max_prob.detach().numpy())\n",
        "    \n",
        "    return pred_text"
      ],
      "metadata": {
        "id": "O1MXvXEtr46b"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Softmax Simple"
      ],
      "metadata": {
        "id": "uGAXwSqBQU59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#text_line = txts[np.random.randint(len(txts))]\n",
        "text_line = \"review hypercolumn instance segmentatio\"\n",
        "print(len(text_line.split()), text_line)\n",
        "LM_decoder_beam_search( text_line, model=lm_brain.hparams.model,tokenizer=sp, \n",
        "                        max_next_words = 3,width__num_beams = 2,\n",
        "                        bos_id=hparams[\"bos_index\"], eos_id=hparams[\"eos_index\"],\n",
        "                       debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "nlyfMCWPqWw9",
        "outputId": "69ac4b31-53f5-4495-ce75-5d632d69aaee"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 review hypercolumn instance segmentatio\n",
            "tokens_list [275, 5693, 836, 0]\n",
            "step 1\n",
            "torch.Size([5, 8581])\n",
            "tensor([1.8079, 1.6254], grad_fn=<SelectBackward0>) tensor([6, 2])\n",
            "tracks {0: {'probs': [tensor(1.8079)], 'total_prob': tensor(1.8079), 'indices': [tensor(6)], 'ids': tensor([ 275, 5693,  836,    0,    6]), 'text': 'review hypercolumn instance  ⁇  how'}, 1: {'probs': [tensor(1.6254)], 'total_prob': tensor(1.6254), 'indices': [tensor(2)], 'ids': tensor([ 275, 5693,  836,    0,    2]), 'text': 'review hypercolumn instance  ⁇  the'}}\n",
            "\n",
            "step 2\n",
            "t_tracks {0: {0: {'probs': tensor(-0.2148), 'indices': [tensor(1)], 'ids': tensor([ 275, 5693,  836,    0,    6,    1]), 'text': 'review hypercolumn instance  ⁇  how to'}, 1: {'probs': tensor(-2.7876), 'indices': [tensor(18)], 'ids': tensor([ 275, 5693,  836,    0,    6,   18]), 'text': 'review hypercolumn instance  ⁇  how i'}}, 1: {0: {'probs': tensor(-4.9376), 'indices': [tensor(83)], 'ids': tensor([ 275, 5693,  836,    0,    2,   83]), 'text': 'review hypercolumn instance  ⁇  the future'}, 1: {'probs': tensor(-4.9472), 'indices': [tensor(69)], 'ids': tensor([ 275, 5693,  836,    0,    2,   69]), 'text': 'review hypercolumn instance  ⁇  the best'}}}\n",
            "t_total_probs {0: {0: tensor(1.5931), 1: tensor(-0.9796)}, 1: {0: tensor(-3.3122), 1: tensor(-3.3218)}}\n",
            "max_probs_beams [[0, 0], [1, 0]]\n",
            "max_probs tensor([ 1.5931, -3.3122])\n",
            "tracks {0: {'probs': [tensor(1.8079), tensor(-0.2148)], 'total_prob': tensor(1.5931), 'indices': [tensor(6), tensor(1)], 'ids': tensor([ 275, 5693,  836,    0,    6,    1]), 'text': 'review hypercolumn instance  ⁇  how to'}, 1: {'probs': [tensor(1.6254), tensor(-4.9376)], 'total_prob': tensor(-3.3122), 'indices': [tensor(2), tensor(83)], 'ids': tensor([ 275, 5693,  836,    0,    2,   83]), 'text': 'review hypercolumn instance  ⁇  the future'}}\n",
            "\n",
            "step 3\n",
            "t_tracks {0: {0: {'probs': tensor(-4.0519), 'indices': [tensor(2)], 'ids': tensor([ 275, 5693,  836,    0,    6,    1,    2]), 'text': 'review hypercolumn instance  ⁇  how to the'}, 1: {'probs': tensor(-5.5371), 'indices': [tensor(23)], 'ids': tensor([ 275, 5693,  836,    0,    6,    1,   23]), 'text': 'review hypercolumn instance  ⁇  how to be'}}, 1: {0: {'probs': tensor(0.5954), 'indices': [tensor(4)], 'ids': tensor([ 275, 5693,  836,    0,    2,   83,    4]), 'text': 'review hypercolumn instance  ⁇  the future of'}, 1: {'probs': tensor(-1.3051), 'indices': [tensor(9)], 'ids': tensor([ 275, 5693,  836,    0,    2,   83,    9]), 'text': 'review hypercolumn instance  ⁇  the future for'}}}\n",
            "t_total_probs {0: {0: tensor(-2.4588), 1: tensor(-3.9440)}, 1: {0: tensor(-2.7168), 1: tensor(-4.6173)}}\n",
            "max_probs_beams [[0, 0], [1, 0]]\n",
            "max_probs tensor([-2.4588, -2.7168])\n",
            "tracks {0: {'probs': [tensor(1.8079), tensor(-0.2148), tensor(-4.0519)], 'total_prob': tensor(-2.4588), 'indices': [tensor(6), tensor(1), tensor(2)], 'ids': tensor([ 275, 5693,  836,    0,    6,    1,    2]), 'text': 'review hypercolumn instance  ⁇  how to the'}, 1: {'probs': [tensor(1.6254), tensor(-4.9376), tensor(0.5954)], 'total_prob': tensor(-2.7168), 'indices': [tensor(2), tensor(83), tensor(4)], 'ids': tensor([ 275, 5693,  836,    0,    2,   83,    4]), 'text': 'review hypercolumn instance  ⁇  the future of'}}\n",
            "\n",
            "seed_text: review hypercolumn instance segmentatio\n",
            "pred_text: review hypercolumn instance  ⁇  how to the\n",
            "max_prob: -2.458801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'review hypercolumn instance  ⁇  how to the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Softmax Gumbe tau=0.7"
      ],
      "metadata": {
        "id": "xxVMlAXlQZeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#text_line = txts[np.random.randint(len(txts))]\n",
        "text_line = \"review hypercolumn instance segmentation\"\n",
        "print(len(text_line.split()), text_line)\n",
        "LM_decoder_beam_search( text_line, model=lm_brain.hparams.model,tokenizer=sp, \n",
        "                        max_next_words = 5,width__num_beams = 2,\n",
        "                        bos_id=hparams[\"bos_index\"], eos_id=hparams[\"eos_index\"],\n",
        "                       debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "520c9938-206a-4abd-f9fa-6c7389c716aa",
        "id": "A-IIObTQQZeH"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 review hypercolumn instance segmentation\n",
            "tokens_list [275, 5693, 836, 401]\n",
            "step 1\n",
            "torch.Size([5, 8581])\n",
            "tensor([1.8079, 1.6254], grad_fn=<SelectBackward0>) tensor([6, 2])\n",
            "tracks {0: {'probs': [tensor(1.8079)], 'total_prob': tensor(1.8079), 'indices': [tensor(6)], 'ids': tensor([ 275, 5693,  836,  401,    6]), 'text': 'review hypercolumn instance segmentation how'}, 1: {'probs': [tensor(1.6254)], 'total_prob': tensor(1.6254), 'indices': [tensor(2)], 'ids': tensor([ 275, 5693,  836,  401,    2]), 'text': 'review hypercolumn instance segmentation the'}}\n",
            "\n",
            "step 2\n",
            "t_tracks {0: {0: {'probs': tensor(-0.2148), 'indices': [tensor(1)], 'ids': tensor([ 275, 5693,  836,  401,    6,    1]), 'text': 'review hypercolumn instance segmentation how to'}, 1: {'probs': tensor(-2.7876), 'indices': [tensor(18)], 'ids': tensor([ 275, 5693,  836,  401,    6,   18]), 'text': 'review hypercolumn instance segmentation how i'}}, 1: {0: {'probs': tensor(-4.9376), 'indices': [tensor(83)], 'ids': tensor([ 275, 5693,  836,  401,    2,   83]), 'text': 'review hypercolumn instance segmentation the future'}, 1: {'probs': tensor(-4.9472), 'indices': [tensor(69)], 'ids': tensor([ 275, 5693,  836,  401,    2,   69]), 'text': 'review hypercolumn instance segmentation the best'}}}\n",
            "t_total_probs {0: {0: tensor(1.5931), 1: tensor(-0.9796)}, 1: {0: tensor(-3.3122), 1: tensor(-3.3218)}}\n",
            "max_probs_beams [[0, 0], [1, 0]]\n",
            "max_probs tensor([ 1.5931, -3.3122])\n",
            "tracks {0: {'probs': [tensor(1.8079), tensor(-0.2148)], 'total_prob': tensor(1.5931), 'indices': [tensor(6), tensor(1)], 'ids': tensor([ 275, 5693,  836,  401,    6,    1]), 'text': 'review hypercolumn instance segmentation how to'}, 1: {'probs': [tensor(1.6254), tensor(-4.9376)], 'total_prob': tensor(-3.3122), 'indices': [tensor(2), tensor(83)], 'ids': tensor([ 275, 5693,  836,  401,    2,   83]), 'text': 'review hypercolumn instance segmentation the future'}}\n",
            "\n",
            "step 3\n",
            "t_tracks {0: {0: {'probs': tensor(-4.0519), 'indices': [tensor(2)], 'ids': tensor([ 275, 5693,  836,  401,    6,    1,    2]), 'text': 'review hypercolumn instance segmentation how to the'}, 1: {'probs': tensor(-5.5371), 'indices': [tensor(23)], 'ids': tensor([ 275, 5693,  836,  401,    6,    1,   23]), 'text': 'review hypercolumn instance segmentation how to be'}}, 1: {0: {'probs': tensor(0.5954), 'indices': [tensor(4)], 'ids': tensor([ 275, 5693,  836,  401,    2,   83,    4]), 'text': 'review hypercolumn instance segmentation the future of'}, 1: {'probs': tensor(-1.3051), 'indices': [tensor(9)], 'ids': tensor([ 275, 5693,  836,  401,    2,   83,    9]), 'text': 'review hypercolumn instance segmentation the future for'}}}\n",
            "t_total_probs {0: {0: tensor(-2.4588), 1: tensor(-3.9440)}, 1: {0: tensor(-2.7168), 1: tensor(-4.6173)}}\n",
            "max_probs_beams [[0, 0], [1, 0]]\n",
            "max_probs tensor([-2.4588, -2.7168])\n",
            "tracks {0: {'probs': [tensor(1.8079), tensor(-0.2148), tensor(-4.0519)], 'total_prob': tensor(-2.4588), 'indices': [tensor(6), tensor(1), tensor(2)], 'ids': tensor([ 275, 5693,  836,  401,    6,    1,    2]), 'text': 'review hypercolumn instance segmentation how to the'}, 1: {'probs': [tensor(1.6254), tensor(-4.9376), tensor(0.5954)], 'total_prob': tensor(-2.7168), 'indices': [tensor(2), tensor(83), tensor(4)], 'ids': tensor([ 275, 5693,  836,  401,    2,   83,    4]), 'text': 'review hypercolumn instance segmentation the future of'}}\n",
            "\n",
            "step 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t_tracks {0: {0: {'probs': tensor(-4.9376), 'indices': [tensor(83)], 'ids': tensor([ 275, 5693,  836,  401,    6,    1,    2,   83]), 'text': 'review hypercolumn instance segmentation how to the future'}, 1: {'probs': tensor(-4.9472), 'indices': [tensor(69)], 'ids': tensor([ 275, 5693,  836,  401,    6,    1,    2,   69]), 'text': 'review hypercolumn instance segmentation how to the best'}}, 1: {0: {'probs': tensor(-2.2263), 'indices': [tensor(2)], 'ids': tensor([ 275, 5693,  836,  401,    2,   83,    4,    2]), 'text': 'review hypercolumn instance segmentation the future of the'}, 1: {'probs': tensor(-3.2193), 'indices': [tensor(8)], 'ids': tensor([ 275, 5693,  836,  401,    2,   83,    4,    8]), 'text': 'review hypercolumn instance segmentation the future of your'}}}\n",
            "t_total_probs {0: {0: tensor(-7.3964), 1: tensor(-7.4060)}, 1: {0: tensor(-4.9430), 1: tensor(-5.9361)}}\n",
            "max_probs_beams [[0, 0], [1, 0]]\n",
            "max_probs tensor([-7.3964, -4.9430])\n",
            "tracks {0: {'probs': [tensor(1.8079), tensor(-0.2148), tensor(-4.0519), tensor(-4.9376)], 'total_prob': tensor(-7.3964), 'indices': [tensor(6), tensor(1), tensor(2), tensor(83)], 'ids': tensor([ 275, 5693,  836,  401,    6,    1,    2,   83]), 'text': 'review hypercolumn instance segmentation how to the future'}, 1: {'probs': [tensor(1.6254), tensor(-4.9376), tensor(0.5954), tensor(-2.2263)], 'total_prob': tensor(-4.9430), 'indices': [tensor(2), tensor(83), tensor(4), tensor(2)], 'ids': tensor([ 275, 5693,  836,  401,    2,   83,    4,    2]), 'text': 'review hypercolumn instance segmentation the future of the'}}\n",
            "\n",
            "step 5\n",
            "t_tracks {0: {0: {'probs': tensor(0.5954), 'indices': [tensor(4)], 'ids': tensor([ 275, 5693,  836,  401,    6,    1,    2,   83,    4]), 'text': 'review hypercolumn instance segmentation how to the future of'}, 1: {'probs': tensor(-1.3051), 'indices': [tensor(9)], 'ids': tensor([ 275, 5693,  836,  401,    6,    1,    2,   83,    9]), 'text': 'review hypercolumn instance segmentation how to the future for'}}, 1: {0: {'probs': tensor(-4.9376), 'indices': [tensor(83)], 'ids': tensor([ 275, 5693,  836,  401,    2,   83,    4,    2,   83]), 'text': 'review hypercolumn instance segmentation the future of the future'}, 1: {'probs': tensor(-4.9472), 'indices': [tensor(69)], 'ids': tensor([ 275, 5693,  836,  401,    2,   83,    4,    2,   69]), 'text': 'review hypercolumn instance segmentation the future of the best'}}}\n",
            "t_total_probs {0: {0: tensor(-6.8009), 1: tensor(-8.7015)}, 1: {0: tensor(-9.8806), 1: tensor(-9.8902)}}\n",
            "max_probs_beams [[0, 0], [1, 0]]\n",
            "max_probs tensor([-6.8009, -9.8806])\n",
            "tracks {0: {'probs': [tensor(1.8079), tensor(-0.2148), tensor(-4.0519), tensor(-4.9376), tensor(0.5954)], 'total_prob': tensor(-6.8009), 'indices': [tensor(6), tensor(1), tensor(2), tensor(83), tensor(4)], 'ids': tensor([ 275, 5693,  836,  401,    6,    1,    2,   83,    4]), 'text': 'review hypercolumn instance segmentation how to the future of'}, 1: {'probs': [tensor(1.6254), tensor(-4.9376), tensor(0.5954), tensor(-2.2263), tensor(-4.9376)], 'total_prob': tensor(-9.8806), 'indices': [tensor(2), tensor(83), tensor(4), tensor(2), tensor(83)], 'ids': tensor([ 275, 5693,  836,  401,    2,   83,    4,    2,   83]), 'text': 'review hypercolumn instance segmentation the future of the future'}}\n",
            "\n",
            "seed_text: review hypercolumn instance segmentation\n",
            "pred_text: review hypercolumn instance segmentation how to the future of\n",
            "max_prob: -6.800945\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'review hypercolumn instance segmentation how to the future of'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Top-K, Top-P Sampling - under development\n",
        "by https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277\n",
        "https://colab.research.google.com/drive/1BBJPKYsgheHcCH0JAqLZ49UXHDk4XzX7#scrollTo=I_hU9ytugB57"
      ],
      "metadata": {
        "id": "5Wiq6FPXSda5"
      }
    }
  ]
}